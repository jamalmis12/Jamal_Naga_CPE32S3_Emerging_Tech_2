{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Technological Institute of the Philippines | Quezon City - Computer Engineering\n",
        "--- | ---\n",
        "Course Code: | CPE 019\n",
        "Code Title: | Emerging Technologies in CpE 2\n",
        "2nd Semester | AY 2023-2024\n",
        "<hr> | <hr>\n",
        "**Activity**:|Activity 1.2 : Training Neural Networks**\n",
        "<hr> | <hr>\n",
        "**Name**         | Naga, Jamal\n",
        "**Section** | CPE32S3\n",
        "**Date Performed**: |March 31, 2024\n",
        "**Date Submitted**: |April 02, 2024\n",
        "**Instructor**: | Engr. Roman Richard\n",
        "<hr> | <hr>\n"
      ],
      "metadata": {
        "id": "dkpcgyriaxu5"
      },
      "id": "dkpcgyriaxu5"
    },
    {
      "cell_type": "markdown",
      "id": "union-alcohol",
      "metadata": {
        "id": "union-alcohol"
      },
      "source": [
        "# Activity 1.2 : Training Neural Networks\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "floppy-teens",
      "metadata": {
        "id": "floppy-teens"
      },
      "source": [
        "#### Objective(s):\n",
        "\n",
        "This activity aims to demonstrate how to train neural networks using keras"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "engaged-modem",
      "metadata": {
        "id": "engaged-modem"
      },
      "source": [
        "#### Intended Learning Outcomes (ILOs):\n",
        "* Demonstrate how to build and train neural networks\n",
        "* Demonstrate how to evaluate and plot the model using training and validation loss\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "structured-april",
      "metadata": {
        "id": "structured-april"
      },
      "source": [
        "#### Resources:\n",
        "* Jupyter Notebook\n",
        "\n",
        "CI Pima Diabetes Dataset\n",
        "\n",
        "* pima-indians-diabetes.csv\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cutting-fountain",
      "metadata": {
        "id": "cutting-fountain"
      },
      "source": [
        "#### Procedures"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "entertaining-therapist",
      "metadata": {
        "id": "entertaining-therapist"
      },
      "source": [
        "Load the necessary libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "id": "differential-native",
      "metadata": {
        "id": "differential-native"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import confusion_matrix, precision_recall_curve, roc_auc_score, roc_curve, accuracy_score\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "import seaborn as sns\n",
        "\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "id": "other-married",
      "metadata": {
        "id": "other-married"
      },
      "outputs": [],
      "source": [
        "## Import Keras objects for Deep Learning\n",
        "\n",
        "from keras.models  import Sequential\n",
        "from keras.layers import Input, Dense, Flatten, Dropout, BatchNormalization\n",
        "from keras.optimizers import Adam, SGD, RMSprop"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "mexican-newsletter",
      "metadata": {
        "id": "mexican-newsletter"
      },
      "source": [
        "Load the dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "id": "studied-twelve",
      "metadata": {
        "id": "studied-twelve"
      },
      "outputs": [],
      "source": [
        "\n",
        "filepath = \"pima-indians-diabetes.csv\"\n",
        "names = [\"times_pregnant\", \"glucose_tolerance_test\", \"blood_pressure\", \"skin_thickness\", \"insulin\",\n",
        "         \"bmi\", \"pedigree_function\", \"age\", \"has_diabetes\"]\n",
        "diabetes_df = pd.read_csv(filepath, names=names)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "photographic-carnival",
      "metadata": {
        "id": "photographic-carnival"
      },
      "source": [
        "Check the top 5 samples of the data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "undefined-inventory",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        },
        "id": "undefined-inventory",
        "outputId": "207a27ac-ef19-4629-a641-46ef4ccce543"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(768, 9)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     times_pregnant  glucose_tolerance_test  blood_pressure  skin_thickness  \\\n",
              "38                2                      90              68              42   \n",
              "167               4                     120              68               0   \n",
              "591               2                     112              78              50   \n",
              "729               2                      92              52               0   \n",
              "427               1                     181              64              30   \n",
              "\n",
              "     insulin   bmi  pedigree_function  age  has_diabetes  \n",
              "38         0  38.2              0.503   27             1  \n",
              "167        0  29.6              0.709   34             0  \n",
              "591      140  39.4              0.175   24             0  \n",
              "729        0  30.1              0.141   22             0  \n",
              "427      180  34.1              0.328   38             1  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-1c16e59a-1046-4511-8a4c-6928bba4170e\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>times_pregnant</th>\n",
              "      <th>glucose_tolerance_test</th>\n",
              "      <th>blood_pressure</th>\n",
              "      <th>skin_thickness</th>\n",
              "      <th>insulin</th>\n",
              "      <th>bmi</th>\n",
              "      <th>pedigree_function</th>\n",
              "      <th>age</th>\n",
              "      <th>has_diabetes</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>38</th>\n",
              "      <td>2</td>\n",
              "      <td>90</td>\n",
              "      <td>68</td>\n",
              "      <td>42</td>\n",
              "      <td>0</td>\n",
              "      <td>38.2</td>\n",
              "      <td>0.503</td>\n",
              "      <td>27</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>167</th>\n",
              "      <td>4</td>\n",
              "      <td>120</td>\n",
              "      <td>68</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>29.6</td>\n",
              "      <td>0.709</td>\n",
              "      <td>34</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>591</th>\n",
              "      <td>2</td>\n",
              "      <td>112</td>\n",
              "      <td>78</td>\n",
              "      <td>50</td>\n",
              "      <td>140</td>\n",
              "      <td>39.4</td>\n",
              "      <td>0.175</td>\n",
              "      <td>24</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>729</th>\n",
              "      <td>2</td>\n",
              "      <td>92</td>\n",
              "      <td>52</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>30.1</td>\n",
              "      <td>0.141</td>\n",
              "      <td>22</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>427</th>\n",
              "      <td>1</td>\n",
              "      <td>181</td>\n",
              "      <td>64</td>\n",
              "      <td>30</td>\n",
              "      <td>180</td>\n",
              "      <td>34.1</td>\n",
              "      <td>0.328</td>\n",
              "      <td>38</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-1c16e59a-1046-4511-8a4c-6928bba4170e')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-1c16e59a-1046-4511-8a4c-6928bba4170e button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-1c16e59a-1046-4511-8a4c-6928bba4170e');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-15b31dac-c788-403e-8f9c-ec02442c5825\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-15b31dac-c788-403e-8f9c-ec02442c5825')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-15b31dac-c788-403e-8f9c-ec02442c5825 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"diabetes_df\",\n  \"rows\": 5,\n  \"fields\": [\n    {\n      \"column\": \"times_pregnant\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1,\n        \"min\": 1,\n        \"max\": 4,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          2,\n          4,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"glucose_tolerance_test\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 36,\n        \"min\": 90,\n        \"max\": 181,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          120,\n          181,\n          112\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"blood_pressure\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 9,\n        \"min\": 52,\n        \"max\": 78,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          78,\n          64,\n          68\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"skin_thickness\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 23,\n        \"min\": 0,\n        \"max\": 50,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          0,\n          30,\n          42\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"insulin\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 88,\n        \"min\": 0,\n        \"max\": 180,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          0,\n          140,\n          180\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"bmi\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 4.499666654320072,\n        \"min\": 29.6,\n        \"max\": 39.4,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          29.6,\n          34.1,\n          39.4\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"pedigree_function\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.2370826859979446,\n        \"min\": 0.141,\n        \"max\": 0.709,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          0.709,\n          0.328,\n          0.175\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"age\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 6,\n        \"min\": 22,\n        \"max\": 38,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          34,\n          38,\n          24\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"has_diabetes\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "\n",
        "print(diabetes_df.shape)\n",
        "diabetes_df.sample(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "systematic-motorcycle",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "systematic-motorcycle",
        "outputId": "12bd828d-000c-4516-9894-fb56bf1d0d56"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "times_pregnant              int64\n",
              "glucose_tolerance_test      int64\n",
              "blood_pressure              int64\n",
              "skin_thickness              int64\n",
              "insulin                     int64\n",
              "bmi                       float64\n",
              "pedigree_function         float64\n",
              "age                         int64\n",
              "has_diabetes                int64\n",
              "dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "diabetes_df.dtypes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "id": "collected-lafayette",
      "metadata": {
        "id": "collected-lafayette"
      },
      "outputs": [],
      "source": [
        "X = diabetes_df.iloc[:, :-1].values\n",
        "y = diabetes_df[\"has_diabetes\"].values"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "acquired-parallel",
      "metadata": {
        "id": "acquired-parallel"
      },
      "source": [
        "Split the data to Train, and Test (75%, 25%)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "id": "rational-hollow",
      "metadata": {
        "id": "rational-hollow"
      },
      "outputs": [],
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=11111)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "acceptable-equity",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "acceptable-equity",
        "outputId": "4640df2e-6d37-4553-ae8f-cbd94282a3e9"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.3489583333333333, 0.6510416666666666)"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "np.mean(y), np.mean(1-y)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "thick-reconstruction",
      "metadata": {
        "id": "thick-reconstruction"
      },
      "source": [
        "Build a single hidden layer neural network using 12 nodes.\n",
        "Use the sequential model with single layer network and input shape to 8.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dramatic-zealand",
      "metadata": {
        "id": "dramatic-zealand"
      },
      "source": [
        "Normalize the data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "id": "painted-mathematics",
      "metadata": {
        "id": "painted-mathematics"
      },
      "outputs": [],
      "source": [
        "normalizer = StandardScaler()\n",
        "X_train_norm = normalizer.fit_transform(X_train)\n",
        "X_test_norm = normalizer.transform(X_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "previous-electricity",
      "metadata": {
        "id": "previous-electricity"
      },
      "source": [
        "Define the model:\n",
        "* Input size is 8-dimensional\n",
        "* 1 hidden layer, 12 hidden nodes, sigmoid activation\n",
        "* Final layer with one node and sigmoid activation (standard for binary classification)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "id": "found-bowling",
      "metadata": {
        "id": "found-bowling"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "model  = Sequential([\n",
        "    Dense(12, input_shape=(8,), activation=\"relu\"),\n",
        "    Dense(1, activation=\"sigmoid\")\n",
        "])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "level-terminal",
      "metadata": {
        "id": "level-terminal"
      },
      "source": [
        "View the model summary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "correct-kingdom",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "correct-kingdom",
        "outputId": "419bb367-1f03-4e66-cf2a-bbdebce18c14"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense (Dense)               (None, 12)                108       \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 1)                 13        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 121 (484.00 Byte)\n",
            "Trainable params: 121 (484.00 Byte)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "herbal-anderson",
      "metadata": {
        "id": "herbal-anderson"
      },
      "source": [
        "Train the model\n",
        "* Compile the model with optimizer, loss function and metrics\n",
        "* Use the fit function to return the run history.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "id": "happy-prompt",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "happy-prompt",
        "outputId": "bae5d558-6bd1-4dab-d9f1-ab8451e5efcd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.SGD.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "18/18 [==============================] - 1s 12ms/step - loss: 0.8192 - accuracy: 0.4306 - val_loss: 0.8030 - val_accuracy: 0.4062\n",
            "Epoch 2/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.7797 - accuracy: 0.4514 - val_loss: 0.7702 - val_accuracy: 0.4375\n",
            "Epoch 3/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.7480 - accuracy: 0.4931 - val_loss: 0.7435 - val_accuracy: 0.4948\n",
            "Epoch 4/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.7221 - accuracy: 0.5330 - val_loss: 0.7213 - val_accuracy: 0.5104\n",
            "Epoch 5/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.7006 - accuracy: 0.5608 - val_loss: 0.7027 - val_accuracy: 0.5365\n",
            "Epoch 6/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.6826 - accuracy: 0.6024 - val_loss: 0.6868 - val_accuracy: 0.5729\n",
            "Epoch 7/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6671 - accuracy: 0.6233 - val_loss: 0.6731 - val_accuracy: 0.6042\n",
            "Epoch 8/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.6537 - accuracy: 0.6406 - val_loss: 0.6608 - val_accuracy: 0.6406\n",
            "Epoch 9/200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.6416 - accuracy: 0.6684 - val_loss: 0.6499 - val_accuracy: 0.6510\n",
            "Epoch 10/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.6310 - accuracy: 0.6771 - val_loss: 0.6400 - val_accuracy: 0.6562\n",
            "Epoch 11/200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.6214 - accuracy: 0.6806 - val_loss: 0.6310 - val_accuracy: 0.6719\n",
            "Epoch 12/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.6126 - accuracy: 0.6840 - val_loss: 0.6228 - val_accuracy: 0.6823\n",
            "Epoch 13/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.6045 - accuracy: 0.6892 - val_loss: 0.6153 - val_accuracy: 0.6823\n",
            "Epoch 14/200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.5971 - accuracy: 0.6962 - val_loss: 0.6083 - val_accuracy: 0.6979\n",
            "Epoch 15/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5902 - accuracy: 0.6997 - val_loss: 0.6018 - val_accuracy: 0.6927\n",
            "Epoch 16/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5837 - accuracy: 0.7014 - val_loss: 0.5958 - val_accuracy: 0.7031\n",
            "Epoch 17/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5776 - accuracy: 0.7049 - val_loss: 0.5901 - val_accuracy: 0.6979\n",
            "Epoch 18/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5719 - accuracy: 0.7031 - val_loss: 0.5848 - val_accuracy: 0.7031\n",
            "Epoch 19/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5664 - accuracy: 0.7066 - val_loss: 0.5798 - val_accuracy: 0.7188\n",
            "Epoch 20/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5613 - accuracy: 0.7014 - val_loss: 0.5750 - val_accuracy: 0.7188\n",
            "Epoch 21/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5564 - accuracy: 0.7049 - val_loss: 0.5705 - val_accuracy: 0.7135\n",
            "Epoch 22/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5518 - accuracy: 0.7031 - val_loss: 0.5663 - val_accuracy: 0.7135\n",
            "Epoch 23/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5475 - accuracy: 0.7014 - val_loss: 0.5622 - val_accuracy: 0.7188\n",
            "Epoch 24/200\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.5433 - accuracy: 0.7049 - val_loss: 0.5584 - val_accuracy: 0.7188\n",
            "Epoch 25/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5393 - accuracy: 0.7101 - val_loss: 0.5549 - val_accuracy: 0.7135\n",
            "Epoch 26/200\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.5356 - accuracy: 0.7083 - val_loss: 0.5515 - val_accuracy: 0.7135\n",
            "Epoch 27/200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.5319 - accuracy: 0.7101 - val_loss: 0.5483 - val_accuracy: 0.7188\n",
            "Epoch 28/200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.5285 - accuracy: 0.7118 - val_loss: 0.5453 - val_accuracy: 0.7240\n",
            "Epoch 29/200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.5251 - accuracy: 0.7170 - val_loss: 0.5423 - val_accuracy: 0.7292\n",
            "Epoch 30/200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.5220 - accuracy: 0.7205 - val_loss: 0.5396 - val_accuracy: 0.7292\n",
            "Epoch 31/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5189 - accuracy: 0.7170 - val_loss: 0.5370 - val_accuracy: 0.7344\n",
            "Epoch 32/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5162 - accuracy: 0.7170 - val_loss: 0.5345 - val_accuracy: 0.7344\n",
            "Epoch 33/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5133 - accuracy: 0.7205 - val_loss: 0.5321 - val_accuracy: 0.7292\n",
            "Epoch 34/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5107 - accuracy: 0.7222 - val_loss: 0.5299 - val_accuracy: 0.7344\n",
            "Epoch 35/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5082 - accuracy: 0.7257 - val_loss: 0.5278 - val_accuracy: 0.7448\n",
            "Epoch 36/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5057 - accuracy: 0.7274 - val_loss: 0.5258 - val_accuracy: 0.7500\n",
            "Epoch 37/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5034 - accuracy: 0.7274 - val_loss: 0.5240 - val_accuracy: 0.7500\n",
            "Epoch 38/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5012 - accuracy: 0.7309 - val_loss: 0.5222 - val_accuracy: 0.7552\n",
            "Epoch 39/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4992 - accuracy: 0.7344 - val_loss: 0.5205 - val_accuracy: 0.7604\n",
            "Epoch 40/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4970 - accuracy: 0.7344 - val_loss: 0.5188 - val_accuracy: 0.7604\n",
            "Epoch 41/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4951 - accuracy: 0.7344 - val_loss: 0.5173 - val_accuracy: 0.7656\n",
            "Epoch 42/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4933 - accuracy: 0.7344 - val_loss: 0.5159 - val_accuracy: 0.7656\n",
            "Epoch 43/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4916 - accuracy: 0.7378 - val_loss: 0.5144 - val_accuracy: 0.7656\n",
            "Epoch 44/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4897 - accuracy: 0.7413 - val_loss: 0.5131 - val_accuracy: 0.7656\n",
            "Epoch 45/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4881 - accuracy: 0.7413 - val_loss: 0.5119 - val_accuracy: 0.7656\n",
            "Epoch 46/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4865 - accuracy: 0.7396 - val_loss: 0.5107 - val_accuracy: 0.7708\n",
            "Epoch 47/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4849 - accuracy: 0.7431 - val_loss: 0.5095 - val_accuracy: 0.7760\n",
            "Epoch 48/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4835 - accuracy: 0.7448 - val_loss: 0.5084 - val_accuracy: 0.7760\n",
            "Epoch 49/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4820 - accuracy: 0.7500 - val_loss: 0.5074 - val_accuracy: 0.7760\n",
            "Epoch 50/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4807 - accuracy: 0.7517 - val_loss: 0.5064 - val_accuracy: 0.7760\n",
            "Epoch 51/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4795 - accuracy: 0.7535 - val_loss: 0.5055 - val_accuracy: 0.7708\n",
            "Epoch 52/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4782 - accuracy: 0.7552 - val_loss: 0.5046 - val_accuracy: 0.7708\n",
            "Epoch 53/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4770 - accuracy: 0.7552 - val_loss: 0.5037 - val_accuracy: 0.7708\n",
            "Epoch 54/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4759 - accuracy: 0.7587 - val_loss: 0.5029 - val_accuracy: 0.7708\n",
            "Epoch 55/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4747 - accuracy: 0.7569 - val_loss: 0.5021 - val_accuracy: 0.7708\n",
            "Epoch 56/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4736 - accuracy: 0.7587 - val_loss: 0.5014 - val_accuracy: 0.7708\n",
            "Epoch 57/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4726 - accuracy: 0.7604 - val_loss: 0.5007 - val_accuracy: 0.7656\n",
            "Epoch 58/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4716 - accuracy: 0.7604 - val_loss: 0.5000 - val_accuracy: 0.7604\n",
            "Epoch 59/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4706 - accuracy: 0.7622 - val_loss: 0.4993 - val_accuracy: 0.7552\n",
            "Epoch 60/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4696 - accuracy: 0.7622 - val_loss: 0.4987 - val_accuracy: 0.7552\n",
            "Epoch 61/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4687 - accuracy: 0.7604 - val_loss: 0.4980 - val_accuracy: 0.7552\n",
            "Epoch 62/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4678 - accuracy: 0.7604 - val_loss: 0.4974 - val_accuracy: 0.7604\n",
            "Epoch 63/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4671 - accuracy: 0.7622 - val_loss: 0.4969 - val_accuracy: 0.7604\n",
            "Epoch 64/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4661 - accuracy: 0.7656 - val_loss: 0.4963 - val_accuracy: 0.7604\n",
            "Epoch 65/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4653 - accuracy: 0.7674 - val_loss: 0.4958 - val_accuracy: 0.7604\n",
            "Epoch 66/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4646 - accuracy: 0.7691 - val_loss: 0.4953 - val_accuracy: 0.7604\n",
            "Epoch 67/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4638 - accuracy: 0.7708 - val_loss: 0.4948 - val_accuracy: 0.7552\n",
            "Epoch 68/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4631 - accuracy: 0.7708 - val_loss: 0.4943 - val_accuracy: 0.7552\n",
            "Epoch 69/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4623 - accuracy: 0.7691 - val_loss: 0.4939 - val_accuracy: 0.7552\n",
            "Epoch 70/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4617 - accuracy: 0.7708 - val_loss: 0.4934 - val_accuracy: 0.7500\n",
            "Epoch 71/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4610 - accuracy: 0.7743 - val_loss: 0.4930 - val_accuracy: 0.7500\n",
            "Epoch 72/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4603 - accuracy: 0.7726 - val_loss: 0.4926 - val_accuracy: 0.7500\n",
            "Epoch 73/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4597 - accuracy: 0.7743 - val_loss: 0.4922 - val_accuracy: 0.7500\n",
            "Epoch 74/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4592 - accuracy: 0.7760 - val_loss: 0.4919 - val_accuracy: 0.7552\n",
            "Epoch 75/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4585 - accuracy: 0.7708 - val_loss: 0.4915 - val_accuracy: 0.7552\n",
            "Epoch 76/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4579 - accuracy: 0.7760 - val_loss: 0.4912 - val_accuracy: 0.7552\n",
            "Epoch 77/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4573 - accuracy: 0.7760 - val_loss: 0.4909 - val_accuracy: 0.7552\n",
            "Epoch 78/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4568 - accuracy: 0.7760 - val_loss: 0.4906 - val_accuracy: 0.7552\n",
            "Epoch 79/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4563 - accuracy: 0.7760 - val_loss: 0.4903 - val_accuracy: 0.7552\n",
            "Epoch 80/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4558 - accuracy: 0.7760 - val_loss: 0.4899 - val_accuracy: 0.7552\n",
            "Epoch 81/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4553 - accuracy: 0.7760 - val_loss: 0.4897 - val_accuracy: 0.7552\n",
            "Epoch 82/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4547 - accuracy: 0.7760 - val_loss: 0.4894 - val_accuracy: 0.7552\n",
            "Epoch 83/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4543 - accuracy: 0.7812 - val_loss: 0.4891 - val_accuracy: 0.7552\n",
            "Epoch 84/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4539 - accuracy: 0.7812 - val_loss: 0.4888 - val_accuracy: 0.7552\n",
            "Epoch 85/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4534 - accuracy: 0.7795 - val_loss: 0.4886 - val_accuracy: 0.7500\n",
            "Epoch 86/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4529 - accuracy: 0.7795 - val_loss: 0.4884 - val_accuracy: 0.7500\n",
            "Epoch 87/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4526 - accuracy: 0.7812 - val_loss: 0.4882 - val_accuracy: 0.7500\n",
            "Epoch 88/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4522 - accuracy: 0.7812 - val_loss: 0.4880 - val_accuracy: 0.7500\n",
            "Epoch 89/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4517 - accuracy: 0.7830 - val_loss: 0.4878 - val_accuracy: 0.7500\n",
            "Epoch 90/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4513 - accuracy: 0.7865 - val_loss: 0.4876 - val_accuracy: 0.7500\n",
            "Epoch 91/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4509 - accuracy: 0.7847 - val_loss: 0.4874 - val_accuracy: 0.7500\n",
            "Epoch 92/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4505 - accuracy: 0.7865 - val_loss: 0.4873 - val_accuracy: 0.7500\n",
            "Epoch 93/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4503 - accuracy: 0.7847 - val_loss: 0.4872 - val_accuracy: 0.7552\n",
            "Epoch 94/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4497 - accuracy: 0.7882 - val_loss: 0.4870 - val_accuracy: 0.7552\n",
            "Epoch 95/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4493 - accuracy: 0.7865 - val_loss: 0.4868 - val_accuracy: 0.7552\n",
            "Epoch 96/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4490 - accuracy: 0.7882 - val_loss: 0.4867 - val_accuracy: 0.7552\n",
            "Epoch 97/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4486 - accuracy: 0.7882 - val_loss: 0.4866 - val_accuracy: 0.7552\n",
            "Epoch 98/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4483 - accuracy: 0.7899 - val_loss: 0.4865 - val_accuracy: 0.7552\n",
            "Epoch 99/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4480 - accuracy: 0.7899 - val_loss: 0.4864 - val_accuracy: 0.7552\n",
            "Epoch 100/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4478 - accuracy: 0.7899 - val_loss: 0.4863 - val_accuracy: 0.7552\n",
            "Epoch 101/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4475 - accuracy: 0.7917 - val_loss: 0.4862 - val_accuracy: 0.7552\n",
            "Epoch 102/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4471 - accuracy: 0.7917 - val_loss: 0.4861 - val_accuracy: 0.7552\n",
            "Epoch 103/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4468 - accuracy: 0.7917 - val_loss: 0.4860 - val_accuracy: 0.7552\n",
            "Epoch 104/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4467 - accuracy: 0.7934 - val_loss: 0.4860 - val_accuracy: 0.7552\n",
            "Epoch 105/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4463 - accuracy: 0.7899 - val_loss: 0.4859 - val_accuracy: 0.7500\n",
            "Epoch 106/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4460 - accuracy: 0.7951 - val_loss: 0.4858 - val_accuracy: 0.7500\n",
            "Epoch 107/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4457 - accuracy: 0.7917 - val_loss: 0.4857 - val_accuracy: 0.7500\n",
            "Epoch 108/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4455 - accuracy: 0.7917 - val_loss: 0.4856 - val_accuracy: 0.7500\n",
            "Epoch 109/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4452 - accuracy: 0.7934 - val_loss: 0.4856 - val_accuracy: 0.7500\n",
            "Epoch 110/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4450 - accuracy: 0.7951 - val_loss: 0.4855 - val_accuracy: 0.7500\n",
            "Epoch 111/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4448 - accuracy: 0.7934 - val_loss: 0.4854 - val_accuracy: 0.7500\n",
            "Epoch 112/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4445 - accuracy: 0.7934 - val_loss: 0.4853 - val_accuracy: 0.7500\n",
            "Epoch 113/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4442 - accuracy: 0.7934 - val_loss: 0.4852 - val_accuracy: 0.7500\n",
            "Epoch 114/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4441 - accuracy: 0.7934 - val_loss: 0.4851 - val_accuracy: 0.7500\n",
            "Epoch 115/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4437 - accuracy: 0.7934 - val_loss: 0.4850 - val_accuracy: 0.7500\n",
            "Epoch 116/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4436 - accuracy: 0.7934 - val_loss: 0.4850 - val_accuracy: 0.7500\n",
            "Epoch 117/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4433 - accuracy: 0.7951 - val_loss: 0.4849 - val_accuracy: 0.7500\n",
            "Epoch 118/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4432 - accuracy: 0.7934 - val_loss: 0.4848 - val_accuracy: 0.7500\n",
            "Epoch 119/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4430 - accuracy: 0.7934 - val_loss: 0.4847 - val_accuracy: 0.7500\n",
            "Epoch 120/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4428 - accuracy: 0.7951 - val_loss: 0.4847 - val_accuracy: 0.7500\n",
            "Epoch 121/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4425 - accuracy: 0.7951 - val_loss: 0.4847 - val_accuracy: 0.7500\n",
            "Epoch 122/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4423 - accuracy: 0.7969 - val_loss: 0.4846 - val_accuracy: 0.7500\n",
            "Epoch 123/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4422 - accuracy: 0.7951 - val_loss: 0.4845 - val_accuracy: 0.7500\n",
            "Epoch 124/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4419 - accuracy: 0.7969 - val_loss: 0.4845 - val_accuracy: 0.7500\n",
            "Epoch 125/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4417 - accuracy: 0.7969 - val_loss: 0.4844 - val_accuracy: 0.7552\n",
            "Epoch 126/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4414 - accuracy: 0.7951 - val_loss: 0.4843 - val_accuracy: 0.7552\n",
            "Epoch 127/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4413 - accuracy: 0.7969 - val_loss: 0.4843 - val_accuracy: 0.7552\n",
            "Epoch 128/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4412 - accuracy: 0.7969 - val_loss: 0.4843 - val_accuracy: 0.7552\n",
            "Epoch 129/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4409 - accuracy: 0.7969 - val_loss: 0.4843 - val_accuracy: 0.7552\n",
            "Epoch 130/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4408 - accuracy: 0.7951 - val_loss: 0.4843 - val_accuracy: 0.7552\n",
            "Epoch 131/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4406 - accuracy: 0.7969 - val_loss: 0.4842 - val_accuracy: 0.7552\n",
            "Epoch 132/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4405 - accuracy: 0.7969 - val_loss: 0.4842 - val_accuracy: 0.7604\n",
            "Epoch 133/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4403 - accuracy: 0.7951 - val_loss: 0.4842 - val_accuracy: 0.7552\n",
            "Epoch 134/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4401 - accuracy: 0.7951 - val_loss: 0.4842 - val_accuracy: 0.7552\n",
            "Epoch 135/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4399 - accuracy: 0.7951 - val_loss: 0.4841 - val_accuracy: 0.7552\n",
            "Epoch 136/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4398 - accuracy: 0.7934 - val_loss: 0.4841 - val_accuracy: 0.7552\n",
            "Epoch 137/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4395 - accuracy: 0.7951 - val_loss: 0.4840 - val_accuracy: 0.7552\n",
            "Epoch 138/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4394 - accuracy: 0.7969 - val_loss: 0.4840 - val_accuracy: 0.7604\n",
            "Epoch 139/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4391 - accuracy: 0.7951 - val_loss: 0.4839 - val_accuracy: 0.7604\n",
            "Epoch 140/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4390 - accuracy: 0.7951 - val_loss: 0.4839 - val_accuracy: 0.7604\n",
            "Epoch 141/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4388 - accuracy: 0.7917 - val_loss: 0.4838 - val_accuracy: 0.7552\n",
            "Epoch 142/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4386 - accuracy: 0.7934 - val_loss: 0.4838 - val_accuracy: 0.7552\n",
            "Epoch 143/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4384 - accuracy: 0.7951 - val_loss: 0.4838 - val_accuracy: 0.7552\n",
            "Epoch 144/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4381 - accuracy: 0.7951 - val_loss: 0.4837 - val_accuracy: 0.7552\n",
            "Epoch 145/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4381 - accuracy: 0.7951 - val_loss: 0.4837 - val_accuracy: 0.7552\n",
            "Epoch 146/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4380 - accuracy: 0.7934 - val_loss: 0.4837 - val_accuracy: 0.7604\n",
            "Epoch 147/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4377 - accuracy: 0.7951 - val_loss: 0.4836 - val_accuracy: 0.7604\n",
            "Epoch 148/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4376 - accuracy: 0.7951 - val_loss: 0.4836 - val_accuracy: 0.7604\n",
            "Epoch 149/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4374 - accuracy: 0.7951 - val_loss: 0.4836 - val_accuracy: 0.7604\n",
            "Epoch 150/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4373 - accuracy: 0.7934 - val_loss: 0.4836 - val_accuracy: 0.7604\n",
            "Epoch 151/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4371 - accuracy: 0.7934 - val_loss: 0.4836 - val_accuracy: 0.7656\n",
            "Epoch 152/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4370 - accuracy: 0.7969 - val_loss: 0.4836 - val_accuracy: 0.7708\n",
            "Epoch 153/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4368 - accuracy: 0.7934 - val_loss: 0.4835 - val_accuracy: 0.7708\n",
            "Epoch 154/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4367 - accuracy: 0.7969 - val_loss: 0.4835 - val_accuracy: 0.7708\n",
            "Epoch 155/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4367 - accuracy: 0.7951 - val_loss: 0.4835 - val_accuracy: 0.7760\n",
            "Epoch 156/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4363 - accuracy: 0.7951 - val_loss: 0.4835 - val_accuracy: 0.7760\n",
            "Epoch 157/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4362 - accuracy: 0.7951 - val_loss: 0.4835 - val_accuracy: 0.7760\n",
            "Epoch 158/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4362 - accuracy: 0.7951 - val_loss: 0.4835 - val_accuracy: 0.7760\n",
            "Epoch 159/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4360 - accuracy: 0.7951 - val_loss: 0.4835 - val_accuracy: 0.7760\n",
            "Epoch 160/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4358 - accuracy: 0.7951 - val_loss: 0.4835 - val_accuracy: 0.7760\n",
            "Epoch 161/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4357 - accuracy: 0.7951 - val_loss: 0.4835 - val_accuracy: 0.7760\n",
            "Epoch 162/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4356 - accuracy: 0.7934 - val_loss: 0.4835 - val_accuracy: 0.7812\n",
            "Epoch 163/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4355 - accuracy: 0.7951 - val_loss: 0.4835 - val_accuracy: 0.7812\n",
            "Epoch 164/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4353 - accuracy: 0.7951 - val_loss: 0.4835 - val_accuracy: 0.7812\n",
            "Epoch 165/200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4351 - accuracy: 0.7951 - val_loss: 0.4835 - val_accuracy: 0.7812\n",
            "Epoch 166/200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4351 - accuracy: 0.7934 - val_loss: 0.4835 - val_accuracy: 0.7812\n",
            "Epoch 167/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4350 - accuracy: 0.7951 - val_loss: 0.4836 - val_accuracy: 0.7812\n",
            "Epoch 168/200\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4349 - accuracy: 0.7951 - val_loss: 0.4836 - val_accuracy: 0.7812\n",
            "Epoch 169/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4347 - accuracy: 0.7934 - val_loss: 0.4836 - val_accuracy: 0.7812\n",
            "Epoch 170/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4345 - accuracy: 0.7951 - val_loss: 0.4837 - val_accuracy: 0.7812\n",
            "Epoch 171/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4344 - accuracy: 0.7917 - val_loss: 0.4837 - val_accuracy: 0.7812\n",
            "Epoch 172/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4343 - accuracy: 0.7934 - val_loss: 0.4837 - val_accuracy: 0.7812\n",
            "Epoch 173/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4342 - accuracy: 0.7951 - val_loss: 0.4837 - val_accuracy: 0.7812\n",
            "Epoch 174/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4340 - accuracy: 0.7951 - val_loss: 0.4837 - val_accuracy: 0.7812\n",
            "Epoch 175/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4339 - accuracy: 0.7951 - val_loss: 0.4837 - val_accuracy: 0.7812\n",
            "Epoch 176/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4337 - accuracy: 0.7951 - val_loss: 0.4837 - val_accuracy: 0.7812\n",
            "Epoch 177/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4336 - accuracy: 0.7951 - val_loss: 0.4838 - val_accuracy: 0.7812\n",
            "Epoch 178/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4335 - accuracy: 0.7951 - val_loss: 0.4838 - val_accuracy: 0.7812\n",
            "Epoch 179/200\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4335 - accuracy: 0.7951 - val_loss: 0.4837 - val_accuracy: 0.7760\n",
            "Epoch 180/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4333 - accuracy: 0.7951 - val_loss: 0.4837 - val_accuracy: 0.7760\n",
            "Epoch 181/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4331 - accuracy: 0.7951 - val_loss: 0.4838 - val_accuracy: 0.7760\n",
            "Epoch 182/200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4330 - accuracy: 0.7969 - val_loss: 0.4838 - val_accuracy: 0.7760\n",
            "Epoch 183/200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4329 - accuracy: 0.7969 - val_loss: 0.4838 - val_accuracy: 0.7760\n",
            "Epoch 184/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4327 - accuracy: 0.7951 - val_loss: 0.4839 - val_accuracy: 0.7760\n",
            "Epoch 185/200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4326 - accuracy: 0.7969 - val_loss: 0.4839 - val_accuracy: 0.7760\n",
            "Epoch 186/200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4325 - accuracy: 0.7934 - val_loss: 0.4839 - val_accuracy: 0.7760\n",
            "Epoch 187/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4323 - accuracy: 0.7951 - val_loss: 0.4839 - val_accuracy: 0.7760\n",
            "Epoch 188/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4321 - accuracy: 0.7951 - val_loss: 0.4839 - val_accuracy: 0.7760\n",
            "Epoch 189/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4322 - accuracy: 0.7951 - val_loss: 0.4839 - val_accuracy: 0.7760\n",
            "Epoch 190/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4319 - accuracy: 0.7951 - val_loss: 0.4839 - val_accuracy: 0.7760\n",
            "Epoch 191/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4318 - accuracy: 0.7951 - val_loss: 0.4839 - val_accuracy: 0.7760\n",
            "Epoch 192/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4317 - accuracy: 0.7934 - val_loss: 0.4840 - val_accuracy: 0.7708\n",
            "Epoch 193/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4316 - accuracy: 0.7951 - val_loss: 0.4840 - val_accuracy: 0.7708\n",
            "Epoch 194/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4314 - accuracy: 0.7934 - val_loss: 0.4840 - val_accuracy: 0.7656\n",
            "Epoch 195/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4313 - accuracy: 0.7951 - val_loss: 0.4841 - val_accuracy: 0.7656\n",
            "Epoch 196/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4312 - accuracy: 0.7917 - val_loss: 0.4841 - val_accuracy: 0.7656\n",
            "Epoch 197/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4311 - accuracy: 0.7951 - val_loss: 0.4842 - val_accuracy: 0.7656\n",
            "Epoch 198/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4310 - accuracy: 0.7934 - val_loss: 0.4842 - val_accuracy: 0.7656\n",
            "Epoch 199/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4308 - accuracy: 0.7951 - val_loss: 0.4842 - val_accuracy: 0.7656\n",
            "Epoch 200/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4306 - accuracy: 0.7934 - val_loss: 0.4843 - val_accuracy: 0.7656\n"
          ]
        }
      ],
      "source": [
        "\n",
        "model.compile(SGD(lr = .003), \"binary_crossentropy\", metrics=[\"accuracy\"])\n",
        "run_hist_1 = model.fit(X_train_norm, y_train, validation_data=(X_test_norm, y_test), epochs=200)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "id": "unsigned-nevada",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "unsigned-nevada",
        "outputId": "bd82744d-0859-48eb-c088-28fe47d8d2db"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "6/6 [==============================] - 0s 6ms/step\n"
          ]
        }
      ],
      "source": [
        "## Like we did for the Random Forest, we generate two kinds of predictions\n",
        "#  One is a hard decision, the other is a probabilitistic score.\n",
        "\n",
        "y_pred_prob_nn_1 = model.predict(X_test_norm)\n",
        "y_pred_class_nn_1 = (y_pred_prob_nn_1 > 0.5).astype(int)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Observation:** Here I change the model_1 into model since it is the one used above. Also, I removed the predict_classes and then I apply a threshold of 0.5 to these probabilities using (y_pred_prob_nn_1 > 0.5). This converts the probabilities to binary class predictions where 1 indicates the positive class and 0 indicates the negative class.\n",
        "And then I apply also the .astype(int) converts the boolean array into integers."
      ],
      "metadata": {
        "id": "wP7MUFB9v8lI"
      },
      "id": "wP7MUFB9v8lI"
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "2luZeHx1v8jS"
      },
      "id": "2luZeHx1v8jS"
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "id": "tough-catering",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tough-catering",
        "outputId": "873b77e8-82c5-4f17-91e5-a3094797fef5"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1],\n",
              "       [1],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [1],\n",
              "       [0]])"
            ]
          },
          "metadata": {},
          "execution_count": 72
        }
      ],
      "source": [
        "# Let's check out the outputs to get a feel for how keras apis work.\n",
        "y_pred_class_nn_1[:10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "id": "combined-zimbabwe",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "combined-zimbabwe",
        "outputId": "f10ef338-4b8a-4333-816f-32d8da7f7af6"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.50279754],\n",
              "       [0.8243923 ],\n",
              "       [0.32496753],\n",
              "       [0.14357883],\n",
              "       [0.18206406],\n",
              "       [0.41763648],\n",
              "       [0.02936498],\n",
              "       [0.44273308],\n",
              "       [0.83079094],\n",
              "       [0.20161708]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 73
        }
      ],
      "source": [
        "y_pred_prob_nn_1[:10]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "going-estonia",
      "metadata": {
        "id": "going-estonia"
      },
      "source": [
        "Create the plot_roc function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "id": "supposed-moderator",
      "metadata": {
        "id": "supposed-moderator"
      },
      "outputs": [],
      "source": [
        "def plot_roc(y_test, y_pred, model_name):\n",
        "    fpr, tpr, thr = roc_curve(y_test, y_pred)\n",
        "    fig, ax = plt.subplots(figsize=(8, 8))\n",
        "    ax.plot(fpr, tpr, 'k-')\n",
        "    ax.plot([0, 1], [0, 1], 'k--', linewidth=.5)  # roc curve for random model\n",
        "    ax.grid(True)\n",
        "    ax.set(title='ROC Curve for {} on PIMA diabetes problem'.format(model_name),\n",
        "           xlim=[-0.01, 1.01], ylim=[-0.01, 1.01])\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "second-festival",
      "metadata": {
        "id": "second-festival"
      },
      "source": [
        "Evaluate the model performance and plot the ROC CURVE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "id": "eleven-nebraska",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 734
        },
        "id": "eleven-nebraska",
        "outputId": "bb57e17d-77c9-44ce-b598-a79f34defe4e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "accuracy is 0.766\n",
            "roc-auc is 0.834\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x800 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "\n",
        "print('accuracy is {:.3f}'.format(accuracy_score(y_test,y_pred_class_nn_1)))\n",
        "print('roc-auc is {:.3f}'.format(roc_auc_score(y_test,y_pred_prob_nn_1)))\n",
        "\n",
        "plot_roc(y_test, y_pred_prob_nn_1, 'NN')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Interpretation:** The model's performance is relatively good, with an accuracy of 0.641 and a ROC-AUC of 0.815, indicating its solid discriminatory ability in distinguishing between positive and negative classes. The ROC curve of the model shows a strong performance as it bends towards the top-left corner. This indicates that the model achieves a high true positive rate while maintaining a low false positive rate across different threshold values.\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "ZvzF3g2C3DvP"
      },
      "id": "ZvzF3g2C3DvP"
    },
    {
      "cell_type": "markdown",
      "id": "invalid-nevada",
      "metadata": {
        "id": "invalid-nevada"
      },
      "source": [
        " Plot the training loss and the validation loss over the different epochs and see how it looks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "hidden-physics",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hidden-physics",
        "outputId": "be22eaf0-da1c-492e-9293-c8716825e35c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ],
      "source": [
        "run_hist_1.history.keys()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Epoch = 200"
      ],
      "metadata": {
        "id": "nQpLz9Z1zreE"
      },
      "id": "nQpLz9Z1zreE"
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "id": "banned-spider",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 447
        },
        "id": "banned-spider",
        "outputId": "dcc8b3b0-2f6d-4736-d63f-5223254d5d0a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x78daed7f5360>"
            ]
          },
          "metadata": {},
          "execution_count": 43
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "fig, ax = plt.subplots()\n",
        "ax.plot(run_hist_1.history[\"loss\"],'r', marker='.', label=\"Train Loss\")\n",
        "ax.plot(run_hist_1.history[\"val_loss\"],'b', marker='.', label=\"Validation Loss\")\n",
        "ax.legend()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Epoch = 400"
      ],
      "metadata": {
        "id": "EpmDr_VNztbK"
      },
      "id": "EpmDr_VNztbK"
    },
    {
      "cell_type": "code",
      "source": [
        "fig, ax = plt.subplots()\n",
        "ax.plot(run_hist_1.history[\"loss\"],'r', marker='.', label=\"Train Loss\")\n",
        "ax.plot(run_hist_1.history[\"val_loss\"],'b', marker='.', label=\"Validation Loss\")\n",
        "ax.legend()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 447
        },
        "id": "ODeXaPdh0Aaf",
        "outputId": "4bbe73a1-36e6-45b8-d92e-99a5a0dcb58e"
      },
      "id": "ODeXaPdh0Aaf",
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x78daed7a70d0>"
            ]
          },
          "metadata": {},
          "execution_count": 52
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Epoch = 900"
      ],
      "metadata": {
        "id": "ENzeYLzk02Ix"
      },
      "id": "ENzeYLzk02Ix"
    },
    {
      "cell_type": "code",
      "source": [
        "fig, ax = plt.subplots()\n",
        "ax.plot(run_hist_1.history[\"loss\"],'r', marker='.', label=\"Train Loss\")\n",
        "ax.plot(run_hist_1.history[\"val_loss\"],'b', marker='.', label=\"Validation Loss\")\n",
        "ax.legend()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 447
        },
        "id": "BrDS0CHD0vsh",
        "outputId": "f55f0611-3692-4a73-dc05-944268ac30bb"
      },
      "id": "BrDS0CHD0vsh",
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x78dae40e1d20>"
            ]
          },
          "metadata": {},
          "execution_count": 62
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "superb-circus",
      "metadata": {
        "id": "superb-circus"
      },
      "source": [
        "What is your interpretation about the result of the train and validation loss?\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "german-cherry",
      "metadata": {
        "id": "german-cherry"
      },
      "source": [
        "**Interpretation:** Upon changing the value of epochs the train loss gradually decreases where it means that model's ability to make predictions on the training data is improving. In contrast the validation loss is getting higher in higher than the train loss which means that the model was initially learning to generalize well to unseen data, but at a certain point, it started to overfit the validation set or encountered difficulties in further improving its performance."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "involved-slovak",
      "metadata": {
        "id": "involved-slovak"
      },
      "source": [
        "#### Supplementary Activity"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "pending-publisher",
      "metadata": {
        "id": "pending-publisher"
      },
      "source": [
        "* Build a model with two hidden layers, each with 6 nodes\n",
        "* Use the \"relu\" activation function for the hidden layers, and \"sigmoid\" for the final layer\n",
        "* Use a learning rate of .003 and train for 1500 epochs\n",
        "* Graph the trajectory of the loss functions, accuracy on both train and test set\n",
        "* Plot the roc curve for the predictions\n",
        "* Use different learning rates, numbers of epochs, and network structures.\n",
        "* Plot the results of training and validation loss using different learning rates, number of epocgs and network structures\n",
        "* Interpret your result"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import confusion_matrix, precision_recall_curve, roc_auc_score, roc_curve, accuracy_score\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "import seaborn as sns\n",
        "\n",
        "%matplotlib inline\n",
        "\n",
        "## Import Keras objects for Deep Learning\n",
        "\n",
        "from keras.models  import Sequential\n",
        "from keras.layers import Input, Dense, Flatten, Dropout, BatchNormalization\n",
        "from keras.optimizers import Adam, SGD, RMSprop\n",
        "\n",
        "# Load the dataset\n",
        "filepath = \"pima-indians-diabetes.csv\"\n",
        "names = [\"times_pregnant\", \"glucose_tolerance_test\", \"blood_pressure\", \"skin_thickness\", \"insulin\",\n",
        "         \"bmi\", \"pedigree_function\", \"age\", \"has_diabetes\"]\n",
        "diabetes_df = pd.read_csv(filepath, names=names)\n",
        "\n",
        "X = diabetes_df.iloc[:, :-1].values\n",
        "y = diabetes_df[\"has_diabetes\"].values\n",
        "\n",
        "# Split the data into 75% for train set and 25% for test set\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=11111)\n",
        "\n",
        "# Normalize the data\n",
        "normalizer = StandardScaler()\n",
        "X_train_norm = normalizer.fit_transform(X_train)\n",
        "X_test_norm = normalizer.transform(X_test)"
      ],
      "metadata": {
        "id": "QNWGKunV8rYM"
      },
      "id": "QNWGKunV8rYM",
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# TASK 1 and 2:\n",
        "- Build a model with two hidden layers, each with 6 nodes\n",
        "- Use the \"relu\" activation function for the hidden layers, and \"sigmoid\" for the final layer"
      ],
      "metadata": {
        "id": "F9WC1Pja9inA"
      },
      "id": "F9WC1Pja9inA"
    },
    {
      "cell_type": "code",
      "source": [
        "model_supple  = Sequential([\n",
        "    Dense(6, input_shape=(8,), activation=\"relu\"),\n",
        "    Dense(6, activation=\"relu\"),\n",
        "    Dense(1, activation=\"sigmoid\")\n",
        "])"
      ],
      "metadata": {
        "id": "nJ9FZXs24IOr"
      },
      "id": "nJ9FZXs24IOr",
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# TASK 3:\n",
        "- Use a learning rate of .003 and train for 1500 epochs"
      ],
      "metadata": {
        "id": "uhVpNGsL9rMr"
      },
      "id": "uhVpNGsL9rMr"
    },
    {
      "cell_type": "code",
      "source": [
        "# Task 3\n",
        "model_supple.compile(SGD(lr = .003), \"binary_crossentropy\", metrics=[\"accuracy\"])\n",
        "run_hist_2 = model_supple.fit(X_train_norm, y_train, validation_data=(X_test_norm, y_test), epochs=1500)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RbX25ksr4cZp",
        "outputId": "798723fb-c80b-4dec-c85d-e265c0ba00c8"
      },
      "id": "RbX25ksr4cZp",
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.SGD.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/1500\n",
            "18/18 [==============================] - 1s 13ms/step - loss: 0.6455 - accuracy: 0.6493 - val_loss: 0.6517 - val_accuracy: 0.6458\n",
            "Epoch 2/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6414 - accuracy: 0.6580 - val_loss: 0.6484 - val_accuracy: 0.6562\n",
            "Epoch 3/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6373 - accuracy: 0.6580 - val_loss: 0.6453 - val_accuracy: 0.6510\n",
            "Epoch 4/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6335 - accuracy: 0.6580 - val_loss: 0.6422 - val_accuracy: 0.6510\n",
            "Epoch 5/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6298 - accuracy: 0.6580 - val_loss: 0.6393 - val_accuracy: 0.6510\n",
            "Epoch 6/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6261 - accuracy: 0.6580 - val_loss: 0.6364 - val_accuracy: 0.6510\n",
            "Epoch 7/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6227 - accuracy: 0.6580 - val_loss: 0.6337 - val_accuracy: 0.6458\n",
            "Epoch 8/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6194 - accuracy: 0.6580 - val_loss: 0.6311 - val_accuracy: 0.6458\n",
            "Epoch 9/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6162 - accuracy: 0.6597 - val_loss: 0.6285 - val_accuracy: 0.6458\n",
            "Epoch 10/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6131 - accuracy: 0.6597 - val_loss: 0.6259 - val_accuracy: 0.6510\n",
            "Epoch 11/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6099 - accuracy: 0.6615 - val_loss: 0.6233 - val_accuracy: 0.6510\n",
            "Epoch 12/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6068 - accuracy: 0.6632 - val_loss: 0.6207 - val_accuracy: 0.6562\n",
            "Epoch 13/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6038 - accuracy: 0.6667 - val_loss: 0.6183 - val_accuracy: 0.6615\n",
            "Epoch 14/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6007 - accuracy: 0.6701 - val_loss: 0.6158 - val_accuracy: 0.6562\n",
            "Epoch 15/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5976 - accuracy: 0.6736 - val_loss: 0.6134 - val_accuracy: 0.6615\n",
            "Epoch 16/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5946 - accuracy: 0.6736 - val_loss: 0.6110 - val_accuracy: 0.6615\n",
            "Epoch 17/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5914 - accuracy: 0.6788 - val_loss: 0.6087 - val_accuracy: 0.6719\n",
            "Epoch 18/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5883 - accuracy: 0.6823 - val_loss: 0.6063 - val_accuracy: 0.6823\n",
            "Epoch 19/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5851 - accuracy: 0.6823 - val_loss: 0.6040 - val_accuracy: 0.6875\n",
            "Epoch 20/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5819 - accuracy: 0.6823 - val_loss: 0.6017 - val_accuracy: 0.6875\n",
            "Epoch 21/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5787 - accuracy: 0.6806 - val_loss: 0.5994 - val_accuracy: 0.6979\n",
            "Epoch 22/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5755 - accuracy: 0.6858 - val_loss: 0.5971 - val_accuracy: 0.6927\n",
            "Epoch 23/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5723 - accuracy: 0.6840 - val_loss: 0.5947 - val_accuracy: 0.6875\n",
            "Epoch 24/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5692 - accuracy: 0.6927 - val_loss: 0.5924 - val_accuracy: 0.6927\n",
            "Epoch 25/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5660 - accuracy: 0.6944 - val_loss: 0.5900 - val_accuracy: 0.6823\n",
            "Epoch 26/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5628 - accuracy: 0.6944 - val_loss: 0.5875 - val_accuracy: 0.6771\n",
            "Epoch 27/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5594 - accuracy: 0.7031 - val_loss: 0.5850 - val_accuracy: 0.6771\n",
            "Epoch 28/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5560 - accuracy: 0.6979 - val_loss: 0.5825 - val_accuracy: 0.6771\n",
            "Epoch 29/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5525 - accuracy: 0.7014 - val_loss: 0.5800 - val_accuracy: 0.6771\n",
            "Epoch 30/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5490 - accuracy: 0.7014 - val_loss: 0.5774 - val_accuracy: 0.6875\n",
            "Epoch 31/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5451 - accuracy: 0.7049 - val_loss: 0.5749 - val_accuracy: 0.6927\n",
            "Epoch 32/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5414 - accuracy: 0.7083 - val_loss: 0.5725 - val_accuracy: 0.6927\n",
            "Epoch 33/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5379 - accuracy: 0.7083 - val_loss: 0.5702 - val_accuracy: 0.6927\n",
            "Epoch 34/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5344 - accuracy: 0.7118 - val_loss: 0.5680 - val_accuracy: 0.6823\n",
            "Epoch 35/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5312 - accuracy: 0.7118 - val_loss: 0.5659 - val_accuracy: 0.6875\n",
            "Epoch 36/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5280 - accuracy: 0.7153 - val_loss: 0.5637 - val_accuracy: 0.6875\n",
            "Epoch 37/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5249 - accuracy: 0.7066 - val_loss: 0.5616 - val_accuracy: 0.6875\n",
            "Epoch 38/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5219 - accuracy: 0.7135 - val_loss: 0.5596 - val_accuracy: 0.6927\n",
            "Epoch 39/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5191 - accuracy: 0.7170 - val_loss: 0.5575 - val_accuracy: 0.6979\n",
            "Epoch 40/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5163 - accuracy: 0.7240 - val_loss: 0.5555 - val_accuracy: 0.7135\n",
            "Epoch 41/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5137 - accuracy: 0.7274 - val_loss: 0.5537 - val_accuracy: 0.7188\n",
            "Epoch 42/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5112 - accuracy: 0.7309 - val_loss: 0.5518 - val_accuracy: 0.7292\n",
            "Epoch 43/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5087 - accuracy: 0.7344 - val_loss: 0.5500 - val_accuracy: 0.7396\n",
            "Epoch 44/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5064 - accuracy: 0.7326 - val_loss: 0.5483 - val_accuracy: 0.7396\n",
            "Epoch 45/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5040 - accuracy: 0.7378 - val_loss: 0.5467 - val_accuracy: 0.7448\n",
            "Epoch 46/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5019 - accuracy: 0.7465 - val_loss: 0.5452 - val_accuracy: 0.7396\n",
            "Epoch 47/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4998 - accuracy: 0.7517 - val_loss: 0.5438 - val_accuracy: 0.7500\n",
            "Epoch 48/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4980 - accuracy: 0.7587 - val_loss: 0.5425 - val_accuracy: 0.7552\n",
            "Epoch 49/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4960 - accuracy: 0.7587 - val_loss: 0.5413 - val_accuracy: 0.7552\n",
            "Epoch 50/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4940 - accuracy: 0.7587 - val_loss: 0.5401 - val_accuracy: 0.7500\n",
            "Epoch 51/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4923 - accuracy: 0.7587 - val_loss: 0.5390 - val_accuracy: 0.7500\n",
            "Epoch 52/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4906 - accuracy: 0.7604 - val_loss: 0.5380 - val_accuracy: 0.7344\n",
            "Epoch 53/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4889 - accuracy: 0.7604 - val_loss: 0.5370 - val_accuracy: 0.7448\n",
            "Epoch 54/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4873 - accuracy: 0.7743 - val_loss: 0.5361 - val_accuracy: 0.7552\n",
            "Epoch 55/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4859 - accuracy: 0.7743 - val_loss: 0.5353 - val_accuracy: 0.7552\n",
            "Epoch 56/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4844 - accuracy: 0.7760 - val_loss: 0.5344 - val_accuracy: 0.7552\n",
            "Epoch 57/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4831 - accuracy: 0.7743 - val_loss: 0.5335 - val_accuracy: 0.7552\n",
            "Epoch 58/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4817 - accuracy: 0.7708 - val_loss: 0.5327 - val_accuracy: 0.7604\n",
            "Epoch 59/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4804 - accuracy: 0.7726 - val_loss: 0.5318 - val_accuracy: 0.7604\n",
            "Epoch 60/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4792 - accuracy: 0.7674 - val_loss: 0.5310 - val_accuracy: 0.7604\n",
            "Epoch 61/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4779 - accuracy: 0.7622 - val_loss: 0.5304 - val_accuracy: 0.7604\n",
            "Epoch 62/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4768 - accuracy: 0.7639 - val_loss: 0.5297 - val_accuracy: 0.7604\n",
            "Epoch 63/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4756 - accuracy: 0.7622 - val_loss: 0.5291 - val_accuracy: 0.7604\n",
            "Epoch 64/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4745 - accuracy: 0.7622 - val_loss: 0.5285 - val_accuracy: 0.7604\n",
            "Epoch 65/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4736 - accuracy: 0.7656 - val_loss: 0.5280 - val_accuracy: 0.7604\n",
            "Epoch 66/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4725 - accuracy: 0.7656 - val_loss: 0.5275 - val_accuracy: 0.7604\n",
            "Epoch 67/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4716 - accuracy: 0.7674 - val_loss: 0.5271 - val_accuracy: 0.7604\n",
            "Epoch 68/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4706 - accuracy: 0.7674 - val_loss: 0.5266 - val_accuracy: 0.7656\n",
            "Epoch 69/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4698 - accuracy: 0.7674 - val_loss: 0.5262 - val_accuracy: 0.7708\n",
            "Epoch 70/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4691 - accuracy: 0.7674 - val_loss: 0.5260 - val_accuracy: 0.7708\n",
            "Epoch 71/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4681 - accuracy: 0.7656 - val_loss: 0.5256 - val_accuracy: 0.7708\n",
            "Epoch 72/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4673 - accuracy: 0.7674 - val_loss: 0.5254 - val_accuracy: 0.7708\n",
            "Epoch 73/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4666 - accuracy: 0.7656 - val_loss: 0.5251 - val_accuracy: 0.7708\n",
            "Epoch 74/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4660 - accuracy: 0.7656 - val_loss: 0.5247 - val_accuracy: 0.7708\n",
            "Epoch 75/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4652 - accuracy: 0.7656 - val_loss: 0.5244 - val_accuracy: 0.7708\n",
            "Epoch 76/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4645 - accuracy: 0.7691 - val_loss: 0.5242 - val_accuracy: 0.7708\n",
            "Epoch 77/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4638 - accuracy: 0.7674 - val_loss: 0.5239 - val_accuracy: 0.7708\n",
            "Epoch 78/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4633 - accuracy: 0.7691 - val_loss: 0.5236 - val_accuracy: 0.7708\n",
            "Epoch 79/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4628 - accuracy: 0.7726 - val_loss: 0.5234 - val_accuracy: 0.7708\n",
            "Epoch 80/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4620 - accuracy: 0.7760 - val_loss: 0.5231 - val_accuracy: 0.7708\n",
            "Epoch 81/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4615 - accuracy: 0.7760 - val_loss: 0.5229 - val_accuracy: 0.7708\n",
            "Epoch 82/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4609 - accuracy: 0.7743 - val_loss: 0.5227 - val_accuracy: 0.7708\n",
            "Epoch 83/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4603 - accuracy: 0.7743 - val_loss: 0.5226 - val_accuracy: 0.7708\n",
            "Epoch 84/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4598 - accuracy: 0.7760 - val_loss: 0.5224 - val_accuracy: 0.7760\n",
            "Epoch 85/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4592 - accuracy: 0.7760 - val_loss: 0.5222 - val_accuracy: 0.7760\n",
            "Epoch 86/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4587 - accuracy: 0.7795 - val_loss: 0.5221 - val_accuracy: 0.7760\n",
            "Epoch 87/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4583 - accuracy: 0.7760 - val_loss: 0.5220 - val_accuracy: 0.7760\n",
            "Epoch 88/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4578 - accuracy: 0.7778 - val_loss: 0.5218 - val_accuracy: 0.7760\n",
            "Epoch 89/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4574 - accuracy: 0.7795 - val_loss: 0.5217 - val_accuracy: 0.7760\n",
            "Epoch 90/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4569 - accuracy: 0.7778 - val_loss: 0.5216 - val_accuracy: 0.7708\n",
            "Epoch 91/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4566 - accuracy: 0.7812 - val_loss: 0.5215 - val_accuracy: 0.7708\n",
            "Epoch 92/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4560 - accuracy: 0.7795 - val_loss: 0.5215 - val_accuracy: 0.7708\n",
            "Epoch 93/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4556 - accuracy: 0.7830 - val_loss: 0.5213 - val_accuracy: 0.7708\n",
            "Epoch 94/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4553 - accuracy: 0.7830 - val_loss: 0.5212 - val_accuracy: 0.7708\n",
            "Epoch 95/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4549 - accuracy: 0.7812 - val_loss: 0.5211 - val_accuracy: 0.7708\n",
            "Epoch 96/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4545 - accuracy: 0.7812 - val_loss: 0.5210 - val_accuracy: 0.7708\n",
            "Epoch 97/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4540 - accuracy: 0.7795 - val_loss: 0.5208 - val_accuracy: 0.7708\n",
            "Epoch 98/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4536 - accuracy: 0.7812 - val_loss: 0.5207 - val_accuracy: 0.7708\n",
            "Epoch 99/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4535 - accuracy: 0.7795 - val_loss: 0.5205 - val_accuracy: 0.7708\n",
            "Epoch 100/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4529 - accuracy: 0.7812 - val_loss: 0.5204 - val_accuracy: 0.7708\n",
            "Epoch 101/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4525 - accuracy: 0.7795 - val_loss: 0.5202 - val_accuracy: 0.7708\n",
            "Epoch 102/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4522 - accuracy: 0.7830 - val_loss: 0.5201 - val_accuracy: 0.7708\n",
            "Epoch 103/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4518 - accuracy: 0.7812 - val_loss: 0.5201 - val_accuracy: 0.7708\n",
            "Epoch 104/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4517 - accuracy: 0.7847 - val_loss: 0.5199 - val_accuracy: 0.7708\n",
            "Epoch 105/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4513 - accuracy: 0.7812 - val_loss: 0.5198 - val_accuracy: 0.7708\n",
            "Epoch 106/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4512 - accuracy: 0.7812 - val_loss: 0.5198 - val_accuracy: 0.7708\n",
            "Epoch 107/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4509 - accuracy: 0.7830 - val_loss: 0.5198 - val_accuracy: 0.7708\n",
            "Epoch 108/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4505 - accuracy: 0.7830 - val_loss: 0.5196 - val_accuracy: 0.7708\n",
            "Epoch 109/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4502 - accuracy: 0.7812 - val_loss: 0.5196 - val_accuracy: 0.7708\n",
            "Epoch 110/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4500 - accuracy: 0.7795 - val_loss: 0.5194 - val_accuracy: 0.7708\n",
            "Epoch 111/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4497 - accuracy: 0.7830 - val_loss: 0.5194 - val_accuracy: 0.7656\n",
            "Epoch 112/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4494 - accuracy: 0.7830 - val_loss: 0.5194 - val_accuracy: 0.7656\n",
            "Epoch 113/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4494 - accuracy: 0.7795 - val_loss: 0.5192 - val_accuracy: 0.7656\n",
            "Epoch 114/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4490 - accuracy: 0.7830 - val_loss: 0.5192 - val_accuracy: 0.7656\n",
            "Epoch 115/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4488 - accuracy: 0.7830 - val_loss: 0.5192 - val_accuracy: 0.7656\n",
            "Epoch 116/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4486 - accuracy: 0.7830 - val_loss: 0.5190 - val_accuracy: 0.7656\n",
            "Epoch 117/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4485 - accuracy: 0.7812 - val_loss: 0.5189 - val_accuracy: 0.7656\n",
            "Epoch 118/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4482 - accuracy: 0.7830 - val_loss: 0.5189 - val_accuracy: 0.7656\n",
            "Epoch 119/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4480 - accuracy: 0.7830 - val_loss: 0.5189 - val_accuracy: 0.7656\n",
            "Epoch 120/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4476 - accuracy: 0.7830 - val_loss: 0.5189 - val_accuracy: 0.7656\n",
            "Epoch 121/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4476 - accuracy: 0.7830 - val_loss: 0.5188 - val_accuracy: 0.7656\n",
            "Epoch 122/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4473 - accuracy: 0.7812 - val_loss: 0.5188 - val_accuracy: 0.7656\n",
            "Epoch 123/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4473 - accuracy: 0.7812 - val_loss: 0.5188 - val_accuracy: 0.7656\n",
            "Epoch 124/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4470 - accuracy: 0.7795 - val_loss: 0.5188 - val_accuracy: 0.7656\n",
            "Epoch 125/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4468 - accuracy: 0.7812 - val_loss: 0.5187 - val_accuracy: 0.7656\n",
            "Epoch 126/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4467 - accuracy: 0.7812 - val_loss: 0.5186 - val_accuracy: 0.7656\n",
            "Epoch 127/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4464 - accuracy: 0.7812 - val_loss: 0.5188 - val_accuracy: 0.7656\n",
            "Epoch 128/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4461 - accuracy: 0.7830 - val_loss: 0.5187 - val_accuracy: 0.7656\n",
            "Epoch 129/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4460 - accuracy: 0.7812 - val_loss: 0.5187 - val_accuracy: 0.7656\n",
            "Epoch 130/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4458 - accuracy: 0.7812 - val_loss: 0.5187 - val_accuracy: 0.7656\n",
            "Epoch 131/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4457 - accuracy: 0.7830 - val_loss: 0.5187 - val_accuracy: 0.7656\n",
            "Epoch 132/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4454 - accuracy: 0.7830 - val_loss: 0.5186 - val_accuracy: 0.7656\n",
            "Epoch 133/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4454 - accuracy: 0.7812 - val_loss: 0.5186 - val_accuracy: 0.7656\n",
            "Epoch 134/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4452 - accuracy: 0.7812 - val_loss: 0.5186 - val_accuracy: 0.7656\n",
            "Epoch 135/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4449 - accuracy: 0.7812 - val_loss: 0.5186 - val_accuracy: 0.7656\n",
            "Epoch 136/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4446 - accuracy: 0.7812 - val_loss: 0.5186 - val_accuracy: 0.7656\n",
            "Epoch 137/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4447 - accuracy: 0.7812 - val_loss: 0.5187 - val_accuracy: 0.7656\n",
            "Epoch 138/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4444 - accuracy: 0.7812 - val_loss: 0.5187 - val_accuracy: 0.7656\n",
            "Epoch 139/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4442 - accuracy: 0.7830 - val_loss: 0.5186 - val_accuracy: 0.7656\n",
            "Epoch 140/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4441 - accuracy: 0.7812 - val_loss: 0.5185 - val_accuracy: 0.7656\n",
            "Epoch 141/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4439 - accuracy: 0.7795 - val_loss: 0.5184 - val_accuracy: 0.7656\n",
            "Epoch 142/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4436 - accuracy: 0.7812 - val_loss: 0.5184 - val_accuracy: 0.7656\n",
            "Epoch 143/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4434 - accuracy: 0.7812 - val_loss: 0.5185 - val_accuracy: 0.7656\n",
            "Epoch 144/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4435 - accuracy: 0.7812 - val_loss: 0.5185 - val_accuracy: 0.7656\n",
            "Epoch 145/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4431 - accuracy: 0.7812 - val_loss: 0.5183 - val_accuracy: 0.7656\n",
            "Epoch 146/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4431 - accuracy: 0.7830 - val_loss: 0.5184 - val_accuracy: 0.7656\n",
            "Epoch 147/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4428 - accuracy: 0.7812 - val_loss: 0.5183 - val_accuracy: 0.7656\n",
            "Epoch 148/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4428 - accuracy: 0.7830 - val_loss: 0.5184 - val_accuracy: 0.7656\n",
            "Epoch 149/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4428 - accuracy: 0.7830 - val_loss: 0.5183 - val_accuracy: 0.7604\n",
            "Epoch 150/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4425 - accuracy: 0.7830 - val_loss: 0.5182 - val_accuracy: 0.7604\n",
            "Epoch 151/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4423 - accuracy: 0.7830 - val_loss: 0.5184 - val_accuracy: 0.7604\n",
            "Epoch 152/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4421 - accuracy: 0.7830 - val_loss: 0.5185 - val_accuracy: 0.7656\n",
            "Epoch 153/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4420 - accuracy: 0.7882 - val_loss: 0.5183 - val_accuracy: 0.7604\n",
            "Epoch 154/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4418 - accuracy: 0.7830 - val_loss: 0.5183 - val_accuracy: 0.7604\n",
            "Epoch 155/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4416 - accuracy: 0.7795 - val_loss: 0.5184 - val_accuracy: 0.7552\n",
            "Epoch 156/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4415 - accuracy: 0.7830 - val_loss: 0.5185 - val_accuracy: 0.7656\n",
            "Epoch 157/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4414 - accuracy: 0.7847 - val_loss: 0.5184 - val_accuracy: 0.7552\n",
            "Epoch 158/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4414 - accuracy: 0.7812 - val_loss: 0.5184 - val_accuracy: 0.7552\n",
            "Epoch 159/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4414 - accuracy: 0.7795 - val_loss: 0.5183 - val_accuracy: 0.7552\n",
            "Epoch 160/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4409 - accuracy: 0.7847 - val_loss: 0.5184 - val_accuracy: 0.7552\n",
            "Epoch 161/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4410 - accuracy: 0.7865 - val_loss: 0.5183 - val_accuracy: 0.7552\n",
            "Epoch 162/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4409 - accuracy: 0.7830 - val_loss: 0.5182 - val_accuracy: 0.7552\n",
            "Epoch 163/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4405 - accuracy: 0.7865 - val_loss: 0.5183 - val_accuracy: 0.7552\n",
            "Epoch 164/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4405 - accuracy: 0.7899 - val_loss: 0.5184 - val_accuracy: 0.7552\n",
            "Epoch 165/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4403 - accuracy: 0.7865 - val_loss: 0.5184 - val_accuracy: 0.7552\n",
            "Epoch 166/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4401 - accuracy: 0.7882 - val_loss: 0.5184 - val_accuracy: 0.7552\n",
            "Epoch 167/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4401 - accuracy: 0.7882 - val_loss: 0.5184 - val_accuracy: 0.7552\n",
            "Epoch 168/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4400 - accuracy: 0.7865 - val_loss: 0.5184 - val_accuracy: 0.7552\n",
            "Epoch 169/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4398 - accuracy: 0.7899 - val_loss: 0.5185 - val_accuracy: 0.7552\n",
            "Epoch 170/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4398 - accuracy: 0.7917 - val_loss: 0.5185 - val_accuracy: 0.7552\n",
            "Epoch 171/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4395 - accuracy: 0.7899 - val_loss: 0.5186 - val_accuracy: 0.7552\n",
            "Epoch 172/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4393 - accuracy: 0.7899 - val_loss: 0.5186 - val_accuracy: 0.7552\n",
            "Epoch 173/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4393 - accuracy: 0.7917 - val_loss: 0.5187 - val_accuracy: 0.7552\n",
            "Epoch 174/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4392 - accuracy: 0.7899 - val_loss: 0.5187 - val_accuracy: 0.7552\n",
            "Epoch 175/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4391 - accuracy: 0.7917 - val_loss: 0.5187 - val_accuracy: 0.7552\n",
            "Epoch 176/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4391 - accuracy: 0.7917 - val_loss: 0.5187 - val_accuracy: 0.7552\n",
            "Epoch 177/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4389 - accuracy: 0.7917 - val_loss: 0.5187 - val_accuracy: 0.7500\n",
            "Epoch 178/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4388 - accuracy: 0.7951 - val_loss: 0.5188 - val_accuracy: 0.7500\n",
            "Epoch 179/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4388 - accuracy: 0.7899 - val_loss: 0.5187 - val_accuracy: 0.7500\n",
            "Epoch 180/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4386 - accuracy: 0.7934 - val_loss: 0.5189 - val_accuracy: 0.7500\n",
            "Epoch 181/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4385 - accuracy: 0.7917 - val_loss: 0.5191 - val_accuracy: 0.7500\n",
            "Epoch 182/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4383 - accuracy: 0.7917 - val_loss: 0.5190 - val_accuracy: 0.7500\n",
            "Epoch 183/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4384 - accuracy: 0.7934 - val_loss: 0.5191 - val_accuracy: 0.7500\n",
            "Epoch 184/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4381 - accuracy: 0.7934 - val_loss: 0.5190 - val_accuracy: 0.7500\n",
            "Epoch 185/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4382 - accuracy: 0.7899 - val_loss: 0.5192 - val_accuracy: 0.7500\n",
            "Epoch 186/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4378 - accuracy: 0.7934 - val_loss: 0.5192 - val_accuracy: 0.7500\n",
            "Epoch 187/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4379 - accuracy: 0.7899 - val_loss: 0.5193 - val_accuracy: 0.7500\n",
            "Epoch 188/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4377 - accuracy: 0.7917 - val_loss: 0.5194 - val_accuracy: 0.7500\n",
            "Epoch 189/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4377 - accuracy: 0.7934 - val_loss: 0.5193 - val_accuracy: 0.7500\n",
            "Epoch 190/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4376 - accuracy: 0.7917 - val_loss: 0.5194 - val_accuracy: 0.7500\n",
            "Epoch 191/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4376 - accuracy: 0.7934 - val_loss: 0.5194 - val_accuracy: 0.7500\n",
            "Epoch 192/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4374 - accuracy: 0.7899 - val_loss: 0.5193 - val_accuracy: 0.7500\n",
            "Epoch 193/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4372 - accuracy: 0.7917 - val_loss: 0.5194 - val_accuracy: 0.7500\n",
            "Epoch 194/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4371 - accuracy: 0.7917 - val_loss: 0.5194 - val_accuracy: 0.7500\n",
            "Epoch 195/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4369 - accuracy: 0.7899 - val_loss: 0.5193 - val_accuracy: 0.7500\n",
            "Epoch 196/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4369 - accuracy: 0.7917 - val_loss: 0.5193 - val_accuracy: 0.7500\n",
            "Epoch 197/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4369 - accuracy: 0.7917 - val_loss: 0.5193 - val_accuracy: 0.7500\n",
            "Epoch 198/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4365 - accuracy: 0.7917 - val_loss: 0.5193 - val_accuracy: 0.7500\n",
            "Epoch 199/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4365 - accuracy: 0.7934 - val_loss: 0.5192 - val_accuracy: 0.7552\n",
            "Epoch 200/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4366 - accuracy: 0.7917 - val_loss: 0.5193 - val_accuracy: 0.7552\n",
            "Epoch 201/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4366 - accuracy: 0.7917 - val_loss: 0.5192 - val_accuracy: 0.7552\n",
            "Epoch 202/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4364 - accuracy: 0.7934 - val_loss: 0.5194 - val_accuracy: 0.7552\n",
            "Epoch 203/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4365 - accuracy: 0.7899 - val_loss: 0.5192 - val_accuracy: 0.7552\n",
            "Epoch 204/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4361 - accuracy: 0.7899 - val_loss: 0.5192 - val_accuracy: 0.7552\n",
            "Epoch 205/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4360 - accuracy: 0.7899 - val_loss: 0.5193 - val_accuracy: 0.7500\n",
            "Epoch 206/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4359 - accuracy: 0.7917 - val_loss: 0.5193 - val_accuracy: 0.7500\n",
            "Epoch 207/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4357 - accuracy: 0.7917 - val_loss: 0.5193 - val_accuracy: 0.7500\n",
            "Epoch 208/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4358 - accuracy: 0.7917 - val_loss: 0.5193 - val_accuracy: 0.7500\n",
            "Epoch 209/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4356 - accuracy: 0.7934 - val_loss: 0.5193 - val_accuracy: 0.7500\n",
            "Epoch 210/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4355 - accuracy: 0.7951 - val_loss: 0.5193 - val_accuracy: 0.7500\n",
            "Epoch 211/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4354 - accuracy: 0.7934 - val_loss: 0.5193 - val_accuracy: 0.7500\n",
            "Epoch 212/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4353 - accuracy: 0.7917 - val_loss: 0.5194 - val_accuracy: 0.7500\n",
            "Epoch 213/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4353 - accuracy: 0.7934 - val_loss: 0.5193 - val_accuracy: 0.7500\n",
            "Epoch 214/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4351 - accuracy: 0.7934 - val_loss: 0.5193 - val_accuracy: 0.7500\n",
            "Epoch 215/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4351 - accuracy: 0.7934 - val_loss: 0.5192 - val_accuracy: 0.7500\n",
            "Epoch 216/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4350 - accuracy: 0.7934 - val_loss: 0.5192 - val_accuracy: 0.7500\n",
            "Epoch 217/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4348 - accuracy: 0.7934 - val_loss: 0.5189 - val_accuracy: 0.7500\n",
            "Epoch 218/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4348 - accuracy: 0.7917 - val_loss: 0.5190 - val_accuracy: 0.7500\n",
            "Epoch 219/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4347 - accuracy: 0.7917 - val_loss: 0.5191 - val_accuracy: 0.7500\n",
            "Epoch 220/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4347 - accuracy: 0.7934 - val_loss: 0.5190 - val_accuracy: 0.7500\n",
            "Epoch 221/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4346 - accuracy: 0.7917 - val_loss: 0.5190 - val_accuracy: 0.7500\n",
            "Epoch 222/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4345 - accuracy: 0.7934 - val_loss: 0.5190 - val_accuracy: 0.7448\n",
            "Epoch 223/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4343 - accuracy: 0.7917 - val_loss: 0.5190 - val_accuracy: 0.7500\n",
            "Epoch 224/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4343 - accuracy: 0.7934 - val_loss: 0.5189 - val_accuracy: 0.7500\n",
            "Epoch 225/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4341 - accuracy: 0.7917 - val_loss: 0.5188 - val_accuracy: 0.7500\n",
            "Epoch 226/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4342 - accuracy: 0.7917 - val_loss: 0.5188 - val_accuracy: 0.7500\n",
            "Epoch 227/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4339 - accuracy: 0.7934 - val_loss: 0.5187 - val_accuracy: 0.7500\n",
            "Epoch 228/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4338 - accuracy: 0.7934 - val_loss: 0.5186 - val_accuracy: 0.7500\n",
            "Epoch 229/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4338 - accuracy: 0.7934 - val_loss: 0.5185 - val_accuracy: 0.7500\n",
            "Epoch 230/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4337 - accuracy: 0.7934 - val_loss: 0.5186 - val_accuracy: 0.7500\n",
            "Epoch 231/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4335 - accuracy: 0.7934 - val_loss: 0.5185 - val_accuracy: 0.7500\n",
            "Epoch 232/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4336 - accuracy: 0.7917 - val_loss: 0.5185 - val_accuracy: 0.7500\n",
            "Epoch 233/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4335 - accuracy: 0.7934 - val_loss: 0.5184 - val_accuracy: 0.7500\n",
            "Epoch 234/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4335 - accuracy: 0.7934 - val_loss: 0.5182 - val_accuracy: 0.7500\n",
            "Epoch 235/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4333 - accuracy: 0.7917 - val_loss: 0.5182 - val_accuracy: 0.7500\n",
            "Epoch 236/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4333 - accuracy: 0.7917 - val_loss: 0.5182 - val_accuracy: 0.7552\n",
            "Epoch 237/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4334 - accuracy: 0.7951 - val_loss: 0.5181 - val_accuracy: 0.7552\n",
            "Epoch 238/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4332 - accuracy: 0.7934 - val_loss: 0.5181 - val_accuracy: 0.7552\n",
            "Epoch 239/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4329 - accuracy: 0.7917 - val_loss: 0.5179 - val_accuracy: 0.7552\n",
            "Epoch 240/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4328 - accuracy: 0.7882 - val_loss: 0.5178 - val_accuracy: 0.7552\n",
            "Epoch 241/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4327 - accuracy: 0.7899 - val_loss: 0.5177 - val_accuracy: 0.7552\n",
            "Epoch 242/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4329 - accuracy: 0.7882 - val_loss: 0.5177 - val_accuracy: 0.7552\n",
            "Epoch 243/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4328 - accuracy: 0.7899 - val_loss: 0.5177 - val_accuracy: 0.7552\n",
            "Epoch 244/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4326 - accuracy: 0.7917 - val_loss: 0.5176 - val_accuracy: 0.7552\n",
            "Epoch 245/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4326 - accuracy: 0.7882 - val_loss: 0.5176 - val_accuracy: 0.7500\n",
            "Epoch 246/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4324 - accuracy: 0.7899 - val_loss: 0.5175 - val_accuracy: 0.7500\n",
            "Epoch 247/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4321 - accuracy: 0.7917 - val_loss: 0.5175 - val_accuracy: 0.7500\n",
            "Epoch 248/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4324 - accuracy: 0.7882 - val_loss: 0.5176 - val_accuracy: 0.7500\n",
            "Epoch 249/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4321 - accuracy: 0.7899 - val_loss: 0.5176 - val_accuracy: 0.7500\n",
            "Epoch 250/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4321 - accuracy: 0.7917 - val_loss: 0.5175 - val_accuracy: 0.7500\n",
            "Epoch 251/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4319 - accuracy: 0.7882 - val_loss: 0.5176 - val_accuracy: 0.7500\n",
            "Epoch 252/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4318 - accuracy: 0.7899 - val_loss: 0.5176 - val_accuracy: 0.7500\n",
            "Epoch 253/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4316 - accuracy: 0.7899 - val_loss: 0.5177 - val_accuracy: 0.7448\n",
            "Epoch 254/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4319 - accuracy: 0.7899 - val_loss: 0.5176 - val_accuracy: 0.7448\n",
            "Epoch 255/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4317 - accuracy: 0.7865 - val_loss: 0.5176 - val_accuracy: 0.7448\n",
            "Epoch 256/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4315 - accuracy: 0.7882 - val_loss: 0.5176 - val_accuracy: 0.7448\n",
            "Epoch 257/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4313 - accuracy: 0.7882 - val_loss: 0.5176 - val_accuracy: 0.7448\n",
            "Epoch 258/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4313 - accuracy: 0.7847 - val_loss: 0.5176 - val_accuracy: 0.7448\n",
            "Epoch 259/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4313 - accuracy: 0.7882 - val_loss: 0.5175 - val_accuracy: 0.7448\n",
            "Epoch 260/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4313 - accuracy: 0.7917 - val_loss: 0.5176 - val_accuracy: 0.7448\n",
            "Epoch 261/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4311 - accuracy: 0.7882 - val_loss: 0.5175 - val_accuracy: 0.7448\n",
            "Epoch 262/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4310 - accuracy: 0.7882 - val_loss: 0.5177 - val_accuracy: 0.7448\n",
            "Epoch 263/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4311 - accuracy: 0.7899 - val_loss: 0.5176 - val_accuracy: 0.7448\n",
            "Epoch 264/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4311 - accuracy: 0.7882 - val_loss: 0.5176 - val_accuracy: 0.7448\n",
            "Epoch 265/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4309 - accuracy: 0.7847 - val_loss: 0.5177 - val_accuracy: 0.7448\n",
            "Epoch 266/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4309 - accuracy: 0.7882 - val_loss: 0.5176 - val_accuracy: 0.7448\n",
            "Epoch 267/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4308 - accuracy: 0.7865 - val_loss: 0.5178 - val_accuracy: 0.7448\n",
            "Epoch 268/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4308 - accuracy: 0.7882 - val_loss: 0.5177 - val_accuracy: 0.7448\n",
            "Epoch 269/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4307 - accuracy: 0.7899 - val_loss: 0.5176 - val_accuracy: 0.7448\n",
            "Epoch 270/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4306 - accuracy: 0.7899 - val_loss: 0.5176 - val_accuracy: 0.7448\n",
            "Epoch 271/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4305 - accuracy: 0.7882 - val_loss: 0.5176 - val_accuracy: 0.7448\n",
            "Epoch 272/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4304 - accuracy: 0.7899 - val_loss: 0.5178 - val_accuracy: 0.7448\n",
            "Epoch 273/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4307 - accuracy: 0.7899 - val_loss: 0.5177 - val_accuracy: 0.7448\n",
            "Epoch 274/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4305 - accuracy: 0.7882 - val_loss: 0.5177 - val_accuracy: 0.7448\n",
            "Epoch 275/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4304 - accuracy: 0.7865 - val_loss: 0.5178 - val_accuracy: 0.7448\n",
            "Epoch 276/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4302 - accuracy: 0.7882 - val_loss: 0.5178 - val_accuracy: 0.7448\n",
            "Epoch 277/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4302 - accuracy: 0.7882 - val_loss: 0.5177 - val_accuracy: 0.7448\n",
            "Epoch 278/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4300 - accuracy: 0.7882 - val_loss: 0.5176 - val_accuracy: 0.7448\n",
            "Epoch 279/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4301 - accuracy: 0.7882 - val_loss: 0.5177 - val_accuracy: 0.7448\n",
            "Epoch 280/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4300 - accuracy: 0.7882 - val_loss: 0.5176 - val_accuracy: 0.7448\n",
            "Epoch 281/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4300 - accuracy: 0.7899 - val_loss: 0.5176 - val_accuracy: 0.7448\n",
            "Epoch 282/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4300 - accuracy: 0.7847 - val_loss: 0.5176 - val_accuracy: 0.7448\n",
            "Epoch 283/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4298 - accuracy: 0.7899 - val_loss: 0.5178 - val_accuracy: 0.7448\n",
            "Epoch 284/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4297 - accuracy: 0.7882 - val_loss: 0.5177 - val_accuracy: 0.7448\n",
            "Epoch 285/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4296 - accuracy: 0.7865 - val_loss: 0.5178 - val_accuracy: 0.7448\n",
            "Epoch 286/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4296 - accuracy: 0.7899 - val_loss: 0.5176 - val_accuracy: 0.7448\n",
            "Epoch 287/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4295 - accuracy: 0.7882 - val_loss: 0.5177 - val_accuracy: 0.7448\n",
            "Epoch 288/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4296 - accuracy: 0.7865 - val_loss: 0.5177 - val_accuracy: 0.7448\n",
            "Epoch 289/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4296 - accuracy: 0.7882 - val_loss: 0.5176 - val_accuracy: 0.7448\n",
            "Epoch 290/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4293 - accuracy: 0.7865 - val_loss: 0.5177 - val_accuracy: 0.7448\n",
            "Epoch 291/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4293 - accuracy: 0.7865 - val_loss: 0.5176 - val_accuracy: 0.7448\n",
            "Epoch 292/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4293 - accuracy: 0.7847 - val_loss: 0.5176 - val_accuracy: 0.7448\n",
            "Epoch 293/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4292 - accuracy: 0.7865 - val_loss: 0.5177 - val_accuracy: 0.7448\n",
            "Epoch 294/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4291 - accuracy: 0.7882 - val_loss: 0.5175 - val_accuracy: 0.7448\n",
            "Epoch 295/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4290 - accuracy: 0.7882 - val_loss: 0.5176 - val_accuracy: 0.7448\n",
            "Epoch 296/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4290 - accuracy: 0.7899 - val_loss: 0.5176 - val_accuracy: 0.7448\n",
            "Epoch 297/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4288 - accuracy: 0.7882 - val_loss: 0.5175 - val_accuracy: 0.7448\n",
            "Epoch 298/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4287 - accuracy: 0.7882 - val_loss: 0.5175 - val_accuracy: 0.7448\n",
            "Epoch 299/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4287 - accuracy: 0.7882 - val_loss: 0.5175 - val_accuracy: 0.7448\n",
            "Epoch 300/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4287 - accuracy: 0.7865 - val_loss: 0.5175 - val_accuracy: 0.7448\n",
            "Epoch 301/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4284 - accuracy: 0.7882 - val_loss: 0.5176 - val_accuracy: 0.7500\n",
            "Epoch 302/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4285 - accuracy: 0.7865 - val_loss: 0.5175 - val_accuracy: 0.7500\n",
            "Epoch 303/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4283 - accuracy: 0.7865 - val_loss: 0.5176 - val_accuracy: 0.7500\n",
            "Epoch 304/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4283 - accuracy: 0.7882 - val_loss: 0.5175 - val_accuracy: 0.7500\n",
            "Epoch 305/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4282 - accuracy: 0.7882 - val_loss: 0.5174 - val_accuracy: 0.7500\n",
            "Epoch 306/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4282 - accuracy: 0.7882 - val_loss: 0.5174 - val_accuracy: 0.7500\n",
            "Epoch 307/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4280 - accuracy: 0.7882 - val_loss: 0.5173 - val_accuracy: 0.7500\n",
            "Epoch 308/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4279 - accuracy: 0.7847 - val_loss: 0.5174 - val_accuracy: 0.7500\n",
            "Epoch 309/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4278 - accuracy: 0.7882 - val_loss: 0.5172 - val_accuracy: 0.7500\n",
            "Epoch 310/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4278 - accuracy: 0.7865 - val_loss: 0.5172 - val_accuracy: 0.7500\n",
            "Epoch 311/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4277 - accuracy: 0.7882 - val_loss: 0.5171 - val_accuracy: 0.7500\n",
            "Epoch 312/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4278 - accuracy: 0.7847 - val_loss: 0.5172 - val_accuracy: 0.7500\n",
            "Epoch 313/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4274 - accuracy: 0.7899 - val_loss: 0.5171 - val_accuracy: 0.7500\n",
            "Epoch 314/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4275 - accuracy: 0.7865 - val_loss: 0.5169 - val_accuracy: 0.7500\n",
            "Epoch 315/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4275 - accuracy: 0.7847 - val_loss: 0.5169 - val_accuracy: 0.7500\n",
            "Epoch 316/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4270 - accuracy: 0.7865 - val_loss: 0.5169 - val_accuracy: 0.7500\n",
            "Epoch 317/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4270 - accuracy: 0.7865 - val_loss: 0.5169 - val_accuracy: 0.7500\n",
            "Epoch 318/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4270 - accuracy: 0.7847 - val_loss: 0.5170 - val_accuracy: 0.7500\n",
            "Epoch 319/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4270 - accuracy: 0.7865 - val_loss: 0.5170 - val_accuracy: 0.7500\n",
            "Epoch 320/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4269 - accuracy: 0.7847 - val_loss: 0.5171 - val_accuracy: 0.7448\n",
            "Epoch 321/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4267 - accuracy: 0.7882 - val_loss: 0.5170 - val_accuracy: 0.7396\n",
            "Epoch 322/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4268 - accuracy: 0.7847 - val_loss: 0.5169 - val_accuracy: 0.7396\n",
            "Epoch 323/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4267 - accuracy: 0.7847 - val_loss: 0.5169 - val_accuracy: 0.7396\n",
            "Epoch 324/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4265 - accuracy: 0.7865 - val_loss: 0.5170 - val_accuracy: 0.7396\n",
            "Epoch 325/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4265 - accuracy: 0.7882 - val_loss: 0.5170 - val_accuracy: 0.7396\n",
            "Epoch 326/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4263 - accuracy: 0.7865 - val_loss: 0.5169 - val_accuracy: 0.7396\n",
            "Epoch 327/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4264 - accuracy: 0.7847 - val_loss: 0.5169 - val_accuracy: 0.7396\n",
            "Epoch 328/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4264 - accuracy: 0.7847 - val_loss: 0.5170 - val_accuracy: 0.7396\n",
            "Epoch 329/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4263 - accuracy: 0.7847 - val_loss: 0.5170 - val_accuracy: 0.7396\n",
            "Epoch 330/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4260 - accuracy: 0.7865 - val_loss: 0.5171 - val_accuracy: 0.7396\n",
            "Epoch 331/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4260 - accuracy: 0.7847 - val_loss: 0.5171 - val_accuracy: 0.7396\n",
            "Epoch 332/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4261 - accuracy: 0.7847 - val_loss: 0.5172 - val_accuracy: 0.7396\n",
            "Epoch 333/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4258 - accuracy: 0.7899 - val_loss: 0.5170 - val_accuracy: 0.7396\n",
            "Epoch 334/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4258 - accuracy: 0.7882 - val_loss: 0.5169 - val_accuracy: 0.7396\n",
            "Epoch 335/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4258 - accuracy: 0.7882 - val_loss: 0.5168 - val_accuracy: 0.7396\n",
            "Epoch 336/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4255 - accuracy: 0.7865 - val_loss: 0.5169 - val_accuracy: 0.7396\n",
            "Epoch 337/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4256 - accuracy: 0.7865 - val_loss: 0.5169 - val_accuracy: 0.7396\n",
            "Epoch 338/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4256 - accuracy: 0.7865 - val_loss: 0.5169 - val_accuracy: 0.7344\n",
            "Epoch 339/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4256 - accuracy: 0.7865 - val_loss: 0.5170 - val_accuracy: 0.7344\n",
            "Epoch 340/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4256 - accuracy: 0.7865 - val_loss: 0.5169 - val_accuracy: 0.7344\n",
            "Epoch 341/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4252 - accuracy: 0.7865 - val_loss: 0.5169 - val_accuracy: 0.7344\n",
            "Epoch 342/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4252 - accuracy: 0.7882 - val_loss: 0.5168 - val_accuracy: 0.7344\n",
            "Epoch 343/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4252 - accuracy: 0.7865 - val_loss: 0.5168 - val_accuracy: 0.7344\n",
            "Epoch 344/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4251 - accuracy: 0.7882 - val_loss: 0.5169 - val_accuracy: 0.7344\n",
            "Epoch 345/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4251 - accuracy: 0.7882 - val_loss: 0.5167 - val_accuracy: 0.7344\n",
            "Epoch 346/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4249 - accuracy: 0.7882 - val_loss: 0.5167 - val_accuracy: 0.7344\n",
            "Epoch 347/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4250 - accuracy: 0.7865 - val_loss: 0.5166 - val_accuracy: 0.7344\n",
            "Epoch 348/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4248 - accuracy: 0.7865 - val_loss: 0.5168 - val_accuracy: 0.7344\n",
            "Epoch 349/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4248 - accuracy: 0.7865 - val_loss: 0.5169 - val_accuracy: 0.7344\n",
            "Epoch 350/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4248 - accuracy: 0.7882 - val_loss: 0.5170 - val_accuracy: 0.7344\n",
            "Epoch 351/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4248 - accuracy: 0.7882 - val_loss: 0.5170 - val_accuracy: 0.7344\n",
            "Epoch 352/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4248 - accuracy: 0.7865 - val_loss: 0.5172 - val_accuracy: 0.7344\n",
            "Epoch 353/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4247 - accuracy: 0.7882 - val_loss: 0.5172 - val_accuracy: 0.7344\n",
            "Epoch 354/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4245 - accuracy: 0.7899 - val_loss: 0.5173 - val_accuracy: 0.7344\n",
            "Epoch 355/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4245 - accuracy: 0.7882 - val_loss: 0.5174 - val_accuracy: 0.7344\n",
            "Epoch 356/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4244 - accuracy: 0.7882 - val_loss: 0.5174 - val_accuracy: 0.7344\n",
            "Epoch 357/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4243 - accuracy: 0.7847 - val_loss: 0.5175 - val_accuracy: 0.7344\n",
            "Epoch 358/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4243 - accuracy: 0.7865 - val_loss: 0.5175 - val_accuracy: 0.7344\n",
            "Epoch 359/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4244 - accuracy: 0.7865 - val_loss: 0.5175 - val_accuracy: 0.7396\n",
            "Epoch 360/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4243 - accuracy: 0.7882 - val_loss: 0.5176 - val_accuracy: 0.7396\n",
            "Epoch 361/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4241 - accuracy: 0.7882 - val_loss: 0.5174 - val_accuracy: 0.7396\n",
            "Epoch 362/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4239 - accuracy: 0.7899 - val_loss: 0.5173 - val_accuracy: 0.7396\n",
            "Epoch 363/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4239 - accuracy: 0.7899 - val_loss: 0.5173 - val_accuracy: 0.7396\n",
            "Epoch 364/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4239 - accuracy: 0.7917 - val_loss: 0.5172 - val_accuracy: 0.7396\n",
            "Epoch 365/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4237 - accuracy: 0.7934 - val_loss: 0.5172 - val_accuracy: 0.7396\n",
            "Epoch 366/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4239 - accuracy: 0.7899 - val_loss: 0.5172 - val_accuracy: 0.7396\n",
            "Epoch 367/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4239 - accuracy: 0.7882 - val_loss: 0.5173 - val_accuracy: 0.7396\n",
            "Epoch 368/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4237 - accuracy: 0.7847 - val_loss: 0.5173 - val_accuracy: 0.7396\n",
            "Epoch 369/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4236 - accuracy: 0.7899 - val_loss: 0.5174 - val_accuracy: 0.7396\n",
            "Epoch 370/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4238 - accuracy: 0.7934 - val_loss: 0.5174 - val_accuracy: 0.7396\n",
            "Epoch 371/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4235 - accuracy: 0.7882 - val_loss: 0.5175 - val_accuracy: 0.7396\n",
            "Epoch 372/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4236 - accuracy: 0.7917 - val_loss: 0.5176 - val_accuracy: 0.7396\n",
            "Epoch 373/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4233 - accuracy: 0.7899 - val_loss: 0.5176 - val_accuracy: 0.7396\n",
            "Epoch 374/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4233 - accuracy: 0.7917 - val_loss: 0.5175 - val_accuracy: 0.7448\n",
            "Epoch 375/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4233 - accuracy: 0.7899 - val_loss: 0.5174 - val_accuracy: 0.7448\n",
            "Epoch 376/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4233 - accuracy: 0.7882 - val_loss: 0.5175 - val_accuracy: 0.7448\n",
            "Epoch 377/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4232 - accuracy: 0.7899 - val_loss: 0.5176 - val_accuracy: 0.7448\n",
            "Epoch 378/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4233 - accuracy: 0.7917 - val_loss: 0.5175 - val_accuracy: 0.7448\n",
            "Epoch 379/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4234 - accuracy: 0.7917 - val_loss: 0.5175 - val_accuracy: 0.7448\n",
            "Epoch 380/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4230 - accuracy: 0.7882 - val_loss: 0.5176 - val_accuracy: 0.7448\n",
            "Epoch 381/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4230 - accuracy: 0.7917 - val_loss: 0.5177 - val_accuracy: 0.7448\n",
            "Epoch 382/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4229 - accuracy: 0.7899 - val_loss: 0.5178 - val_accuracy: 0.7448\n",
            "Epoch 383/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4228 - accuracy: 0.7934 - val_loss: 0.5179 - val_accuracy: 0.7448\n",
            "Epoch 384/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4229 - accuracy: 0.7934 - val_loss: 0.5178 - val_accuracy: 0.7448\n",
            "Epoch 385/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4229 - accuracy: 0.7865 - val_loss: 0.5179 - val_accuracy: 0.7448\n",
            "Epoch 386/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4227 - accuracy: 0.7917 - val_loss: 0.5179 - val_accuracy: 0.7396\n",
            "Epoch 387/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4227 - accuracy: 0.7934 - val_loss: 0.5178 - val_accuracy: 0.7396\n",
            "Epoch 388/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4227 - accuracy: 0.7882 - val_loss: 0.5181 - val_accuracy: 0.7448\n",
            "Epoch 389/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4226 - accuracy: 0.7899 - val_loss: 0.5182 - val_accuracy: 0.7396\n",
            "Epoch 390/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4227 - accuracy: 0.7934 - val_loss: 0.5183 - val_accuracy: 0.7396\n",
            "Epoch 391/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4226 - accuracy: 0.7917 - val_loss: 0.5184 - val_accuracy: 0.7396\n",
            "Epoch 392/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4223 - accuracy: 0.7934 - val_loss: 0.5183 - val_accuracy: 0.7344\n",
            "Epoch 393/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4223 - accuracy: 0.7951 - val_loss: 0.5184 - val_accuracy: 0.7344\n",
            "Epoch 394/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4222 - accuracy: 0.7934 - val_loss: 0.5183 - val_accuracy: 0.7344\n",
            "Epoch 395/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4222 - accuracy: 0.7917 - val_loss: 0.5184 - val_accuracy: 0.7344\n",
            "Epoch 396/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4221 - accuracy: 0.7917 - val_loss: 0.5183 - val_accuracy: 0.7344\n",
            "Epoch 397/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4221 - accuracy: 0.7865 - val_loss: 0.5185 - val_accuracy: 0.7344\n",
            "Epoch 398/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4220 - accuracy: 0.7934 - val_loss: 0.5186 - val_accuracy: 0.7344\n",
            "Epoch 399/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4221 - accuracy: 0.7917 - val_loss: 0.5187 - val_accuracy: 0.7344\n",
            "Epoch 400/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4218 - accuracy: 0.7934 - val_loss: 0.5185 - val_accuracy: 0.7344\n",
            "Epoch 401/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4219 - accuracy: 0.7934 - val_loss: 0.5185 - val_accuracy: 0.7344\n",
            "Epoch 402/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4218 - accuracy: 0.7917 - val_loss: 0.5187 - val_accuracy: 0.7344\n",
            "Epoch 403/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4217 - accuracy: 0.7917 - val_loss: 0.5188 - val_accuracy: 0.7344\n",
            "Epoch 404/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4215 - accuracy: 0.7934 - val_loss: 0.5188 - val_accuracy: 0.7344\n",
            "Epoch 405/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4214 - accuracy: 0.7934 - val_loss: 0.5188 - val_accuracy: 0.7344\n",
            "Epoch 406/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4214 - accuracy: 0.7934 - val_loss: 0.5188 - val_accuracy: 0.7344\n",
            "Epoch 407/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4216 - accuracy: 0.7917 - val_loss: 0.5188 - val_accuracy: 0.7344\n",
            "Epoch 408/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4212 - accuracy: 0.7917 - val_loss: 0.5188 - val_accuracy: 0.7344\n",
            "Epoch 409/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4215 - accuracy: 0.7917 - val_loss: 0.5188 - val_accuracy: 0.7344\n",
            "Epoch 410/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4212 - accuracy: 0.7917 - val_loss: 0.5189 - val_accuracy: 0.7344\n",
            "Epoch 411/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4212 - accuracy: 0.7917 - val_loss: 0.5188 - val_accuracy: 0.7344\n",
            "Epoch 412/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4213 - accuracy: 0.7951 - val_loss: 0.5188 - val_accuracy: 0.7344\n",
            "Epoch 413/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4210 - accuracy: 0.7951 - val_loss: 0.5187 - val_accuracy: 0.7344\n",
            "Epoch 414/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4211 - accuracy: 0.7951 - val_loss: 0.5189 - val_accuracy: 0.7344\n",
            "Epoch 415/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4210 - accuracy: 0.7934 - val_loss: 0.5189 - val_accuracy: 0.7344\n",
            "Epoch 416/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4208 - accuracy: 0.7899 - val_loss: 0.5189 - val_accuracy: 0.7344\n",
            "Epoch 417/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4209 - accuracy: 0.7969 - val_loss: 0.5188 - val_accuracy: 0.7344\n",
            "Epoch 418/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4207 - accuracy: 0.7934 - val_loss: 0.5189 - val_accuracy: 0.7344\n",
            "Epoch 419/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4206 - accuracy: 0.7951 - val_loss: 0.5190 - val_accuracy: 0.7344\n",
            "Epoch 420/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4205 - accuracy: 0.7951 - val_loss: 0.5189 - val_accuracy: 0.7344\n",
            "Epoch 421/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4205 - accuracy: 0.7951 - val_loss: 0.5189 - val_accuracy: 0.7344\n",
            "Epoch 422/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4205 - accuracy: 0.7934 - val_loss: 0.5191 - val_accuracy: 0.7344\n",
            "Epoch 423/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4204 - accuracy: 0.7951 - val_loss: 0.5191 - val_accuracy: 0.7344\n",
            "Epoch 424/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4205 - accuracy: 0.7969 - val_loss: 0.5189 - val_accuracy: 0.7344\n",
            "Epoch 425/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4204 - accuracy: 0.7951 - val_loss: 0.5189 - val_accuracy: 0.7344\n",
            "Epoch 426/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4203 - accuracy: 0.7934 - val_loss: 0.5188 - val_accuracy: 0.7344\n",
            "Epoch 427/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4201 - accuracy: 0.7934 - val_loss: 0.5191 - val_accuracy: 0.7344\n",
            "Epoch 428/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4202 - accuracy: 0.7986 - val_loss: 0.5190 - val_accuracy: 0.7344\n",
            "Epoch 429/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4202 - accuracy: 0.7917 - val_loss: 0.5191 - val_accuracy: 0.7344\n",
            "Epoch 430/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4201 - accuracy: 0.7951 - val_loss: 0.5190 - val_accuracy: 0.7344\n",
            "Epoch 431/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4201 - accuracy: 0.7969 - val_loss: 0.5188 - val_accuracy: 0.7344\n",
            "Epoch 432/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4198 - accuracy: 0.7951 - val_loss: 0.5190 - val_accuracy: 0.7344\n",
            "Epoch 433/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4202 - accuracy: 0.7934 - val_loss: 0.5192 - val_accuracy: 0.7344\n",
            "Epoch 434/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4199 - accuracy: 0.7951 - val_loss: 0.5195 - val_accuracy: 0.7344\n",
            "Epoch 435/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4200 - accuracy: 0.7951 - val_loss: 0.5196 - val_accuracy: 0.7344\n",
            "Epoch 436/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4200 - accuracy: 0.7951 - val_loss: 0.5196 - val_accuracy: 0.7396\n",
            "Epoch 437/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4197 - accuracy: 0.7951 - val_loss: 0.5194 - val_accuracy: 0.7396\n",
            "Epoch 438/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4195 - accuracy: 0.7969 - val_loss: 0.5192 - val_accuracy: 0.7396\n",
            "Epoch 439/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4196 - accuracy: 0.7969 - val_loss: 0.5192 - val_accuracy: 0.7396\n",
            "Epoch 440/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4196 - accuracy: 0.7951 - val_loss: 0.5192 - val_accuracy: 0.7396\n",
            "Epoch 441/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4194 - accuracy: 0.7951 - val_loss: 0.5194 - val_accuracy: 0.7396\n",
            "Epoch 442/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4193 - accuracy: 0.7969 - val_loss: 0.5193 - val_accuracy: 0.7396\n",
            "Epoch 443/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4195 - accuracy: 0.7986 - val_loss: 0.5193 - val_accuracy: 0.7396\n",
            "Epoch 444/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4192 - accuracy: 0.7986 - val_loss: 0.5194 - val_accuracy: 0.7344\n",
            "Epoch 445/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4194 - accuracy: 0.7951 - val_loss: 0.5195 - val_accuracy: 0.7396\n",
            "Epoch 446/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4192 - accuracy: 0.7986 - val_loss: 0.5194 - val_accuracy: 0.7344\n",
            "Epoch 447/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4192 - accuracy: 0.7951 - val_loss: 0.5196 - val_accuracy: 0.7344\n",
            "Epoch 448/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4191 - accuracy: 0.7986 - val_loss: 0.5196 - val_accuracy: 0.7344\n",
            "Epoch 449/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4193 - accuracy: 0.7986 - val_loss: 0.5195 - val_accuracy: 0.7344\n",
            "Epoch 450/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4192 - accuracy: 0.7986 - val_loss: 0.5194 - val_accuracy: 0.7344\n",
            "Epoch 451/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4192 - accuracy: 0.7986 - val_loss: 0.5193 - val_accuracy: 0.7344\n",
            "Epoch 452/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4190 - accuracy: 0.8003 - val_loss: 0.5194 - val_accuracy: 0.7344\n",
            "Epoch 453/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4190 - accuracy: 0.7986 - val_loss: 0.5195 - val_accuracy: 0.7344\n",
            "Epoch 454/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4188 - accuracy: 0.8003 - val_loss: 0.5197 - val_accuracy: 0.7344\n",
            "Epoch 455/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4189 - accuracy: 0.7986 - val_loss: 0.5196 - val_accuracy: 0.7344\n",
            "Epoch 456/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4188 - accuracy: 0.8003 - val_loss: 0.5197 - val_accuracy: 0.7396\n",
            "Epoch 457/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4190 - accuracy: 0.8003 - val_loss: 0.5198 - val_accuracy: 0.7396\n",
            "Epoch 458/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4188 - accuracy: 0.8003 - val_loss: 0.5197 - val_accuracy: 0.7396\n",
            "Epoch 459/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4187 - accuracy: 0.8003 - val_loss: 0.5195 - val_accuracy: 0.7344\n",
            "Epoch 460/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4187 - accuracy: 0.7951 - val_loss: 0.5198 - val_accuracy: 0.7396\n",
            "Epoch 461/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4186 - accuracy: 0.8003 - val_loss: 0.5198 - val_accuracy: 0.7396\n",
            "Epoch 462/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4185 - accuracy: 0.7986 - val_loss: 0.5198 - val_accuracy: 0.7396\n",
            "Epoch 463/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4186 - accuracy: 0.8003 - val_loss: 0.5199 - val_accuracy: 0.7396\n",
            "Epoch 464/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4185 - accuracy: 0.8021 - val_loss: 0.5200 - val_accuracy: 0.7396\n",
            "Epoch 465/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4185 - accuracy: 0.8003 - val_loss: 0.5202 - val_accuracy: 0.7396\n",
            "Epoch 466/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4184 - accuracy: 0.7986 - val_loss: 0.5200 - val_accuracy: 0.7396\n",
            "Epoch 467/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4185 - accuracy: 0.7986 - val_loss: 0.5199 - val_accuracy: 0.7396\n",
            "Epoch 468/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4183 - accuracy: 0.7986 - val_loss: 0.5199 - val_accuracy: 0.7396\n",
            "Epoch 469/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4185 - accuracy: 0.7969 - val_loss: 0.5200 - val_accuracy: 0.7396\n",
            "Epoch 470/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4183 - accuracy: 0.8021 - val_loss: 0.5202 - val_accuracy: 0.7396\n",
            "Epoch 471/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4182 - accuracy: 0.7986 - val_loss: 0.5202 - val_accuracy: 0.7396\n",
            "Epoch 472/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4182 - accuracy: 0.7986 - val_loss: 0.5201 - val_accuracy: 0.7396\n",
            "Epoch 473/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4182 - accuracy: 0.8003 - val_loss: 0.5200 - val_accuracy: 0.7396\n",
            "Epoch 474/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4181 - accuracy: 0.8003 - val_loss: 0.5202 - val_accuracy: 0.7396\n",
            "Epoch 475/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4180 - accuracy: 0.8003 - val_loss: 0.5199 - val_accuracy: 0.7396\n",
            "Epoch 476/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4182 - accuracy: 0.7969 - val_loss: 0.5202 - val_accuracy: 0.7396\n",
            "Epoch 477/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4180 - accuracy: 0.7986 - val_loss: 0.5203 - val_accuracy: 0.7396\n",
            "Epoch 478/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4179 - accuracy: 0.7986 - val_loss: 0.5203 - val_accuracy: 0.7396\n",
            "Epoch 479/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4180 - accuracy: 0.8003 - val_loss: 0.5204 - val_accuracy: 0.7396\n",
            "Epoch 480/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4179 - accuracy: 0.8003 - val_loss: 0.5205 - val_accuracy: 0.7396\n",
            "Epoch 481/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4181 - accuracy: 0.7986 - val_loss: 0.5205 - val_accuracy: 0.7396\n",
            "Epoch 482/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4179 - accuracy: 0.8021 - val_loss: 0.5202 - val_accuracy: 0.7396\n",
            "Epoch 483/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4179 - accuracy: 0.8021 - val_loss: 0.5203 - val_accuracy: 0.7396\n",
            "Epoch 484/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4178 - accuracy: 0.7986 - val_loss: 0.5203 - val_accuracy: 0.7396\n",
            "Epoch 485/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4178 - accuracy: 0.7986 - val_loss: 0.5207 - val_accuracy: 0.7396\n",
            "Epoch 486/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4178 - accuracy: 0.8003 - val_loss: 0.5205 - val_accuracy: 0.7396\n",
            "Epoch 487/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4178 - accuracy: 0.8003 - val_loss: 0.5205 - val_accuracy: 0.7396\n",
            "Epoch 488/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4177 - accuracy: 0.8021 - val_loss: 0.5208 - val_accuracy: 0.7396\n",
            "Epoch 489/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4179 - accuracy: 0.8003 - val_loss: 0.5207 - val_accuracy: 0.7396\n",
            "Epoch 490/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4177 - accuracy: 0.8003 - val_loss: 0.5209 - val_accuracy: 0.7396\n",
            "Epoch 491/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4175 - accuracy: 0.8021 - val_loss: 0.5208 - val_accuracy: 0.7396\n",
            "Epoch 492/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4174 - accuracy: 0.7986 - val_loss: 0.5209 - val_accuracy: 0.7396\n",
            "Epoch 493/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4176 - accuracy: 0.7986 - val_loss: 0.5210 - val_accuracy: 0.7396\n",
            "Epoch 494/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4174 - accuracy: 0.7986 - val_loss: 0.5210 - val_accuracy: 0.7396\n",
            "Epoch 495/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4175 - accuracy: 0.8003 - val_loss: 0.5207 - val_accuracy: 0.7396\n",
            "Epoch 496/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4173 - accuracy: 0.8003 - val_loss: 0.5208 - val_accuracy: 0.7396\n",
            "Epoch 497/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4175 - accuracy: 0.7986 - val_loss: 0.5209 - val_accuracy: 0.7396\n",
            "Epoch 498/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4172 - accuracy: 0.8003 - val_loss: 0.5208 - val_accuracy: 0.7396\n",
            "Epoch 499/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4174 - accuracy: 0.8003 - val_loss: 0.5210 - val_accuracy: 0.7396\n",
            "Epoch 500/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4173 - accuracy: 0.7986 - val_loss: 0.5212 - val_accuracy: 0.7396\n",
            "Epoch 501/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4172 - accuracy: 0.8003 - val_loss: 0.5212 - val_accuracy: 0.7396\n",
            "Epoch 502/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4172 - accuracy: 0.8038 - val_loss: 0.5213 - val_accuracy: 0.7396\n",
            "Epoch 503/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4172 - accuracy: 0.8021 - val_loss: 0.5214 - val_accuracy: 0.7396\n",
            "Epoch 504/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4171 - accuracy: 0.8021 - val_loss: 0.5216 - val_accuracy: 0.7396\n",
            "Epoch 505/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4171 - accuracy: 0.7986 - val_loss: 0.5216 - val_accuracy: 0.7396\n",
            "Epoch 506/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4171 - accuracy: 0.8003 - val_loss: 0.5216 - val_accuracy: 0.7396\n",
            "Epoch 507/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4170 - accuracy: 0.8021 - val_loss: 0.5215 - val_accuracy: 0.7396\n",
            "Epoch 508/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4171 - accuracy: 0.7986 - val_loss: 0.5213 - val_accuracy: 0.7396\n",
            "Epoch 509/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4168 - accuracy: 0.8003 - val_loss: 0.5211 - val_accuracy: 0.7396\n",
            "Epoch 510/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4168 - accuracy: 0.8021 - val_loss: 0.5213 - val_accuracy: 0.7396\n",
            "Epoch 511/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4169 - accuracy: 0.8021 - val_loss: 0.5217 - val_accuracy: 0.7396\n",
            "Epoch 512/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4168 - accuracy: 0.8021 - val_loss: 0.5219 - val_accuracy: 0.7396\n",
            "Epoch 513/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4167 - accuracy: 0.8003 - val_loss: 0.5217 - val_accuracy: 0.7396\n",
            "Epoch 514/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4168 - accuracy: 0.8021 - val_loss: 0.5218 - val_accuracy: 0.7396\n",
            "Epoch 515/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4167 - accuracy: 0.7986 - val_loss: 0.5218 - val_accuracy: 0.7396\n",
            "Epoch 516/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4166 - accuracy: 0.8003 - val_loss: 0.5216 - val_accuracy: 0.7396\n",
            "Epoch 517/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4165 - accuracy: 0.7986 - val_loss: 0.5216 - val_accuracy: 0.7396\n",
            "Epoch 518/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4165 - accuracy: 0.8021 - val_loss: 0.5216 - val_accuracy: 0.7448\n",
            "Epoch 519/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4165 - accuracy: 0.8003 - val_loss: 0.5213 - val_accuracy: 0.7448\n",
            "Epoch 520/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4165 - accuracy: 0.8021 - val_loss: 0.5217 - val_accuracy: 0.7448\n",
            "Epoch 521/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4164 - accuracy: 0.8003 - val_loss: 0.5218 - val_accuracy: 0.7396\n",
            "Epoch 522/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4166 - accuracy: 0.8003 - val_loss: 0.5217 - val_accuracy: 0.7448\n",
            "Epoch 523/1500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.4166 - accuracy: 0.7986 - val_loss: 0.5217 - val_accuracy: 0.7448\n",
            "Epoch 524/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4163 - accuracy: 0.8003 - val_loss: 0.5217 - val_accuracy: 0.7448\n",
            "Epoch 525/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4162 - accuracy: 0.8021 - val_loss: 0.5219 - val_accuracy: 0.7396\n",
            "Epoch 526/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4163 - accuracy: 0.8021 - val_loss: 0.5222 - val_accuracy: 0.7396\n",
            "Epoch 527/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4163 - accuracy: 0.8021 - val_loss: 0.5223 - val_accuracy: 0.7396\n",
            "Epoch 528/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4161 - accuracy: 0.7986 - val_loss: 0.5222 - val_accuracy: 0.7396\n",
            "Epoch 529/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4163 - accuracy: 0.8003 - val_loss: 0.5221 - val_accuracy: 0.7396\n",
            "Epoch 530/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4161 - accuracy: 0.8003 - val_loss: 0.5219 - val_accuracy: 0.7396\n",
            "Epoch 531/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4163 - accuracy: 0.8021 - val_loss: 0.5221 - val_accuracy: 0.7396\n",
            "Epoch 532/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4160 - accuracy: 0.8003 - val_loss: 0.5219 - val_accuracy: 0.7396\n",
            "Epoch 533/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4159 - accuracy: 0.8021 - val_loss: 0.5219 - val_accuracy: 0.7396\n",
            "Epoch 534/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4160 - accuracy: 0.7986 - val_loss: 0.5218 - val_accuracy: 0.7396\n",
            "Epoch 535/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4160 - accuracy: 0.8038 - val_loss: 0.5220 - val_accuracy: 0.7396\n",
            "Epoch 536/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4159 - accuracy: 0.8021 - val_loss: 0.5220 - val_accuracy: 0.7396\n",
            "Epoch 537/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4159 - accuracy: 0.8003 - val_loss: 0.5221 - val_accuracy: 0.7396\n",
            "Epoch 538/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4160 - accuracy: 0.7969 - val_loss: 0.5220 - val_accuracy: 0.7396\n",
            "Epoch 539/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4158 - accuracy: 0.8021 - val_loss: 0.5220 - val_accuracy: 0.7396\n",
            "Epoch 540/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4159 - accuracy: 0.8003 - val_loss: 0.5222 - val_accuracy: 0.7396\n",
            "Epoch 541/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4158 - accuracy: 0.8021 - val_loss: 0.5222 - val_accuracy: 0.7396\n",
            "Epoch 542/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4157 - accuracy: 0.8021 - val_loss: 0.5221 - val_accuracy: 0.7396\n",
            "Epoch 543/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4159 - accuracy: 0.7986 - val_loss: 0.5219 - val_accuracy: 0.7396\n",
            "Epoch 544/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4158 - accuracy: 0.8003 - val_loss: 0.5219 - val_accuracy: 0.7396\n",
            "Epoch 545/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4156 - accuracy: 0.8003 - val_loss: 0.5220 - val_accuracy: 0.7396\n",
            "Epoch 546/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4155 - accuracy: 0.7986 - val_loss: 0.5217 - val_accuracy: 0.7396\n",
            "Epoch 547/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4155 - accuracy: 0.8021 - val_loss: 0.5217 - val_accuracy: 0.7344\n",
            "Epoch 548/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4156 - accuracy: 0.8021 - val_loss: 0.5219 - val_accuracy: 0.7396\n",
            "Epoch 549/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4155 - accuracy: 0.7986 - val_loss: 0.5223 - val_accuracy: 0.7396\n",
            "Epoch 550/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4156 - accuracy: 0.8003 - val_loss: 0.5221 - val_accuracy: 0.7396\n",
            "Epoch 551/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4156 - accuracy: 0.8021 - val_loss: 0.5218 - val_accuracy: 0.7344\n",
            "Epoch 552/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4154 - accuracy: 0.8038 - val_loss: 0.5217 - val_accuracy: 0.7344\n",
            "Epoch 553/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4152 - accuracy: 0.8021 - val_loss: 0.5216 - val_accuracy: 0.7344\n",
            "Epoch 554/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4154 - accuracy: 0.8038 - val_loss: 0.5218 - val_accuracy: 0.7396\n",
            "Epoch 555/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4153 - accuracy: 0.8021 - val_loss: 0.5219 - val_accuracy: 0.7396\n",
            "Epoch 556/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4153 - accuracy: 0.8003 - val_loss: 0.5218 - val_accuracy: 0.7396\n",
            "Epoch 557/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4154 - accuracy: 0.8038 - val_loss: 0.5218 - val_accuracy: 0.7396\n",
            "Epoch 558/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4153 - accuracy: 0.8003 - val_loss: 0.5219 - val_accuracy: 0.7396\n",
            "Epoch 559/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4153 - accuracy: 0.8003 - val_loss: 0.5219 - val_accuracy: 0.7396\n",
            "Epoch 560/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4151 - accuracy: 0.8021 - val_loss: 0.5217 - val_accuracy: 0.7396\n",
            "Epoch 561/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4153 - accuracy: 0.7986 - val_loss: 0.5216 - val_accuracy: 0.7396\n",
            "Epoch 562/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4152 - accuracy: 0.8003 - val_loss: 0.5216 - val_accuracy: 0.7396\n",
            "Epoch 563/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4152 - accuracy: 0.8021 - val_loss: 0.5216 - val_accuracy: 0.7396\n",
            "Epoch 564/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4151 - accuracy: 0.8003 - val_loss: 0.5216 - val_accuracy: 0.7396\n",
            "Epoch 565/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4150 - accuracy: 0.7986 - val_loss: 0.5213 - val_accuracy: 0.7344\n",
            "Epoch 566/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4150 - accuracy: 0.8021 - val_loss: 0.5212 - val_accuracy: 0.7344\n",
            "Epoch 567/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4150 - accuracy: 0.8021 - val_loss: 0.5215 - val_accuracy: 0.7396\n",
            "Epoch 568/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4150 - accuracy: 0.8003 - val_loss: 0.5214 - val_accuracy: 0.7344\n",
            "Epoch 569/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4149 - accuracy: 0.8003 - val_loss: 0.5215 - val_accuracy: 0.7344\n",
            "Epoch 570/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4148 - accuracy: 0.8021 - val_loss: 0.5215 - val_accuracy: 0.7396\n",
            "Epoch 571/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4149 - accuracy: 0.8003 - val_loss: 0.5214 - val_accuracy: 0.7396\n",
            "Epoch 572/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4148 - accuracy: 0.8021 - val_loss: 0.5214 - val_accuracy: 0.7396\n",
            "Epoch 573/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4149 - accuracy: 0.8021 - val_loss: 0.5215 - val_accuracy: 0.7396\n",
            "Epoch 574/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4148 - accuracy: 0.8003 - val_loss: 0.5216 - val_accuracy: 0.7396\n",
            "Epoch 575/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4148 - accuracy: 0.8003 - val_loss: 0.5214 - val_accuracy: 0.7396\n",
            "Epoch 576/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4148 - accuracy: 0.8003 - val_loss: 0.5213 - val_accuracy: 0.7344\n",
            "Epoch 577/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4147 - accuracy: 0.8021 - val_loss: 0.5216 - val_accuracy: 0.7396\n",
            "Epoch 578/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4146 - accuracy: 0.8021 - val_loss: 0.5217 - val_accuracy: 0.7448\n",
            "Epoch 579/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4146 - accuracy: 0.7986 - val_loss: 0.5218 - val_accuracy: 0.7448\n",
            "Epoch 580/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4146 - accuracy: 0.8021 - val_loss: 0.5218 - val_accuracy: 0.7448\n",
            "Epoch 581/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4146 - accuracy: 0.8003 - val_loss: 0.5216 - val_accuracy: 0.7448\n",
            "Epoch 582/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4146 - accuracy: 0.8021 - val_loss: 0.5217 - val_accuracy: 0.7448\n",
            "Epoch 583/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4144 - accuracy: 0.7986 - val_loss: 0.5216 - val_accuracy: 0.7448\n",
            "Epoch 584/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4145 - accuracy: 0.8056 - val_loss: 0.5216 - val_accuracy: 0.7448\n",
            "Epoch 585/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4145 - accuracy: 0.8021 - val_loss: 0.5215 - val_accuracy: 0.7396\n",
            "Epoch 586/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4143 - accuracy: 0.8021 - val_loss: 0.5215 - val_accuracy: 0.7396\n",
            "Epoch 587/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4144 - accuracy: 0.8003 - val_loss: 0.5217 - val_accuracy: 0.7448\n",
            "Epoch 588/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4144 - accuracy: 0.8038 - val_loss: 0.5217 - val_accuracy: 0.7448\n",
            "Epoch 589/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4145 - accuracy: 0.8038 - val_loss: 0.5219 - val_accuracy: 0.7448\n",
            "Epoch 590/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4143 - accuracy: 0.8038 - val_loss: 0.5218 - val_accuracy: 0.7448\n",
            "Epoch 591/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4140 - accuracy: 0.8021 - val_loss: 0.5218 - val_accuracy: 0.7448\n",
            "Epoch 592/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4142 - accuracy: 0.8038 - val_loss: 0.5218 - val_accuracy: 0.7448\n",
            "Epoch 593/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4140 - accuracy: 0.8038 - val_loss: 0.5217 - val_accuracy: 0.7448\n",
            "Epoch 594/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4141 - accuracy: 0.8003 - val_loss: 0.5218 - val_accuracy: 0.7448\n",
            "Epoch 595/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4139 - accuracy: 0.8038 - val_loss: 0.5216 - val_accuracy: 0.7448\n",
            "Epoch 596/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4139 - accuracy: 0.8003 - val_loss: 0.5218 - val_accuracy: 0.7448\n",
            "Epoch 597/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4139 - accuracy: 0.8073 - val_loss: 0.5217 - val_accuracy: 0.7448\n",
            "Epoch 598/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4140 - accuracy: 0.8038 - val_loss: 0.5218 - val_accuracy: 0.7448\n",
            "Epoch 599/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4142 - accuracy: 0.7969 - val_loss: 0.5220 - val_accuracy: 0.7448\n",
            "Epoch 600/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4138 - accuracy: 0.8038 - val_loss: 0.5221 - val_accuracy: 0.7448\n",
            "Epoch 601/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4137 - accuracy: 0.8056 - val_loss: 0.5221 - val_accuracy: 0.7448\n",
            "Epoch 602/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4138 - accuracy: 0.8073 - val_loss: 0.5220 - val_accuracy: 0.7448\n",
            "Epoch 603/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4139 - accuracy: 0.8073 - val_loss: 0.5220 - val_accuracy: 0.7448\n",
            "Epoch 604/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4137 - accuracy: 0.8038 - val_loss: 0.5219 - val_accuracy: 0.7448\n",
            "Epoch 605/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4134 - accuracy: 0.8021 - val_loss: 0.5219 - val_accuracy: 0.7448\n",
            "Epoch 606/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4136 - accuracy: 0.8073 - val_loss: 0.5218 - val_accuracy: 0.7448\n",
            "Epoch 607/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4136 - accuracy: 0.8073 - val_loss: 0.5220 - val_accuracy: 0.7448\n",
            "Epoch 608/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4135 - accuracy: 0.8056 - val_loss: 0.5218 - val_accuracy: 0.7448\n",
            "Epoch 609/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4135 - accuracy: 0.8073 - val_loss: 0.5220 - val_accuracy: 0.7448\n",
            "Epoch 610/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4135 - accuracy: 0.8073 - val_loss: 0.5220 - val_accuracy: 0.7500\n",
            "Epoch 611/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4135 - accuracy: 0.8056 - val_loss: 0.5222 - val_accuracy: 0.7448\n",
            "Epoch 612/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4132 - accuracy: 0.8090 - val_loss: 0.5219 - val_accuracy: 0.7448\n",
            "Epoch 613/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4135 - accuracy: 0.8073 - val_loss: 0.5219 - val_accuracy: 0.7396\n",
            "Epoch 614/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4135 - accuracy: 0.8090 - val_loss: 0.5219 - val_accuracy: 0.7396\n",
            "Epoch 615/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4133 - accuracy: 0.8073 - val_loss: 0.5220 - val_accuracy: 0.7396\n",
            "Epoch 616/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4134 - accuracy: 0.8073 - val_loss: 0.5221 - val_accuracy: 0.7396\n",
            "Epoch 617/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4130 - accuracy: 0.8056 - val_loss: 0.5222 - val_accuracy: 0.7396\n",
            "Epoch 618/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4132 - accuracy: 0.8073 - val_loss: 0.5219 - val_accuracy: 0.7396\n",
            "Epoch 619/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4132 - accuracy: 0.8056 - val_loss: 0.5222 - val_accuracy: 0.7396\n",
            "Epoch 620/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4133 - accuracy: 0.8090 - val_loss: 0.5221 - val_accuracy: 0.7396\n",
            "Epoch 621/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4131 - accuracy: 0.8073 - val_loss: 0.5221 - val_accuracy: 0.7396\n",
            "Epoch 622/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4130 - accuracy: 0.8090 - val_loss: 0.5222 - val_accuracy: 0.7396\n",
            "Epoch 623/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4132 - accuracy: 0.8073 - val_loss: 0.5224 - val_accuracy: 0.7396\n",
            "Epoch 624/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4130 - accuracy: 0.8090 - val_loss: 0.5221 - val_accuracy: 0.7396\n",
            "Epoch 625/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4130 - accuracy: 0.8073 - val_loss: 0.5218 - val_accuracy: 0.7396\n",
            "Epoch 626/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4128 - accuracy: 0.8090 - val_loss: 0.5218 - val_accuracy: 0.7396\n",
            "Epoch 627/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4130 - accuracy: 0.8090 - val_loss: 0.5221 - val_accuracy: 0.7396\n",
            "Epoch 628/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4129 - accuracy: 0.8038 - val_loss: 0.5223 - val_accuracy: 0.7396\n",
            "Epoch 629/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4128 - accuracy: 0.8073 - val_loss: 0.5224 - val_accuracy: 0.7396\n",
            "Epoch 630/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4132 - accuracy: 0.8108 - val_loss: 0.5225 - val_accuracy: 0.7396\n",
            "Epoch 631/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4128 - accuracy: 0.8108 - val_loss: 0.5225 - val_accuracy: 0.7396\n",
            "Epoch 632/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4129 - accuracy: 0.8090 - val_loss: 0.5224 - val_accuracy: 0.7396\n",
            "Epoch 633/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4128 - accuracy: 0.8108 - val_loss: 0.5224 - val_accuracy: 0.7396\n",
            "Epoch 634/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4128 - accuracy: 0.8090 - val_loss: 0.5226 - val_accuracy: 0.7396\n",
            "Epoch 635/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4128 - accuracy: 0.8108 - val_loss: 0.5226 - val_accuracy: 0.7396\n",
            "Epoch 636/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4127 - accuracy: 0.8073 - val_loss: 0.5223 - val_accuracy: 0.7396\n",
            "Epoch 637/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4126 - accuracy: 0.8073 - val_loss: 0.5223 - val_accuracy: 0.7396\n",
            "Epoch 638/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4127 - accuracy: 0.8090 - val_loss: 0.5224 - val_accuracy: 0.7396\n",
            "Epoch 639/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4126 - accuracy: 0.8090 - val_loss: 0.5223 - val_accuracy: 0.7396\n",
            "Epoch 640/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4125 - accuracy: 0.8090 - val_loss: 0.5223 - val_accuracy: 0.7396\n",
            "Epoch 641/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4128 - accuracy: 0.8090 - val_loss: 0.5223 - val_accuracy: 0.7396\n",
            "Epoch 642/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4125 - accuracy: 0.8108 - val_loss: 0.5225 - val_accuracy: 0.7396\n",
            "Epoch 643/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4126 - accuracy: 0.8108 - val_loss: 0.5227 - val_accuracy: 0.7396\n",
            "Epoch 644/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4125 - accuracy: 0.8090 - val_loss: 0.5224 - val_accuracy: 0.7396\n",
            "Epoch 645/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4124 - accuracy: 0.8090 - val_loss: 0.5225 - val_accuracy: 0.7396\n",
            "Epoch 646/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4125 - accuracy: 0.8108 - val_loss: 0.5224 - val_accuracy: 0.7396\n",
            "Epoch 647/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4122 - accuracy: 0.8108 - val_loss: 0.5226 - val_accuracy: 0.7396\n",
            "Epoch 648/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4121 - accuracy: 0.8108 - val_loss: 0.5225 - val_accuracy: 0.7396\n",
            "Epoch 649/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4124 - accuracy: 0.8108 - val_loss: 0.5224 - val_accuracy: 0.7396\n",
            "Epoch 650/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4124 - accuracy: 0.8090 - val_loss: 0.5225 - val_accuracy: 0.7396\n",
            "Epoch 651/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4125 - accuracy: 0.8090 - val_loss: 0.5222 - val_accuracy: 0.7396\n",
            "Epoch 652/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4122 - accuracy: 0.8090 - val_loss: 0.5224 - val_accuracy: 0.7396\n",
            "Epoch 653/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4121 - accuracy: 0.8090 - val_loss: 0.5227 - val_accuracy: 0.7396\n",
            "Epoch 654/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4123 - accuracy: 0.8108 - val_loss: 0.5226 - val_accuracy: 0.7396\n",
            "Epoch 655/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4123 - accuracy: 0.8056 - val_loss: 0.5227 - val_accuracy: 0.7448\n",
            "Epoch 656/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4121 - accuracy: 0.8073 - val_loss: 0.5224 - val_accuracy: 0.7396\n",
            "Epoch 657/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4121 - accuracy: 0.8108 - val_loss: 0.5227 - val_accuracy: 0.7448\n",
            "Epoch 658/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4122 - accuracy: 0.8108 - val_loss: 0.5228 - val_accuracy: 0.7448\n",
            "Epoch 659/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4120 - accuracy: 0.8125 - val_loss: 0.5229 - val_accuracy: 0.7448\n",
            "Epoch 660/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4119 - accuracy: 0.8090 - val_loss: 0.5230 - val_accuracy: 0.7448\n",
            "Epoch 661/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4120 - accuracy: 0.8108 - val_loss: 0.5228 - val_accuracy: 0.7448\n",
            "Epoch 662/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4121 - accuracy: 0.8108 - val_loss: 0.5228 - val_accuracy: 0.7448\n",
            "Epoch 663/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4120 - accuracy: 0.8090 - val_loss: 0.5228 - val_accuracy: 0.7448\n",
            "Epoch 664/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4120 - accuracy: 0.8073 - val_loss: 0.5231 - val_accuracy: 0.7500\n",
            "Epoch 665/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4119 - accuracy: 0.8108 - val_loss: 0.5232 - val_accuracy: 0.7500\n",
            "Epoch 666/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4118 - accuracy: 0.8090 - val_loss: 0.5231 - val_accuracy: 0.7500\n",
            "Epoch 667/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4120 - accuracy: 0.8090 - val_loss: 0.5234 - val_accuracy: 0.7500\n",
            "Epoch 668/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4117 - accuracy: 0.8108 - val_loss: 0.5232 - val_accuracy: 0.7500\n",
            "Epoch 669/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4118 - accuracy: 0.8125 - val_loss: 0.5232 - val_accuracy: 0.7500\n",
            "Epoch 670/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4118 - accuracy: 0.8090 - val_loss: 0.5228 - val_accuracy: 0.7448\n",
            "Epoch 671/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4118 - accuracy: 0.8090 - val_loss: 0.5226 - val_accuracy: 0.7396\n",
            "Epoch 672/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4119 - accuracy: 0.8090 - val_loss: 0.5229 - val_accuracy: 0.7448\n",
            "Epoch 673/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4118 - accuracy: 0.8090 - val_loss: 0.5231 - val_accuracy: 0.7448\n",
            "Epoch 674/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4117 - accuracy: 0.8108 - val_loss: 0.5231 - val_accuracy: 0.7448\n",
            "Epoch 675/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4117 - accuracy: 0.8125 - val_loss: 0.5232 - val_accuracy: 0.7448\n",
            "Epoch 676/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4116 - accuracy: 0.8090 - val_loss: 0.5232 - val_accuracy: 0.7448\n",
            "Epoch 677/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4117 - accuracy: 0.8108 - val_loss: 0.5230 - val_accuracy: 0.7448\n",
            "Epoch 678/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4116 - accuracy: 0.8090 - val_loss: 0.5230 - val_accuracy: 0.7448\n",
            "Epoch 679/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4116 - accuracy: 0.8108 - val_loss: 0.5230 - val_accuracy: 0.7448\n",
            "Epoch 680/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4115 - accuracy: 0.8108 - val_loss: 0.5230 - val_accuracy: 0.7448\n",
            "Epoch 681/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4114 - accuracy: 0.8108 - val_loss: 0.5229 - val_accuracy: 0.7500\n",
            "Epoch 682/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4116 - accuracy: 0.8073 - val_loss: 0.5230 - val_accuracy: 0.7500\n",
            "Epoch 683/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4115 - accuracy: 0.8108 - val_loss: 0.5226 - val_accuracy: 0.7448\n",
            "Epoch 684/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4114 - accuracy: 0.8108 - val_loss: 0.5226 - val_accuracy: 0.7448\n",
            "Epoch 685/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4116 - accuracy: 0.8108 - val_loss: 0.5227 - val_accuracy: 0.7448\n",
            "Epoch 686/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4112 - accuracy: 0.8108 - val_loss: 0.5227 - val_accuracy: 0.7448\n",
            "Epoch 687/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4114 - accuracy: 0.8108 - val_loss: 0.5228 - val_accuracy: 0.7500\n",
            "Epoch 688/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4113 - accuracy: 0.8108 - val_loss: 0.5227 - val_accuracy: 0.7500\n",
            "Epoch 689/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4116 - accuracy: 0.8090 - val_loss: 0.5224 - val_accuracy: 0.7448\n",
            "Epoch 690/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4113 - accuracy: 0.8108 - val_loss: 0.5225 - val_accuracy: 0.7500\n",
            "Epoch 691/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4114 - accuracy: 0.8073 - val_loss: 0.5226 - val_accuracy: 0.7500\n",
            "Epoch 692/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4113 - accuracy: 0.8090 - val_loss: 0.5225 - val_accuracy: 0.7448\n",
            "Epoch 693/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4112 - accuracy: 0.8108 - val_loss: 0.5224 - val_accuracy: 0.7448\n",
            "Epoch 694/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4111 - accuracy: 0.8108 - val_loss: 0.5223 - val_accuracy: 0.7448\n",
            "Epoch 695/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4113 - accuracy: 0.8108 - val_loss: 0.5224 - val_accuracy: 0.7448\n",
            "Epoch 696/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4113 - accuracy: 0.8090 - val_loss: 0.5223 - val_accuracy: 0.7448\n",
            "Epoch 697/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4110 - accuracy: 0.8108 - val_loss: 0.5221 - val_accuracy: 0.7448\n",
            "Epoch 698/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4112 - accuracy: 0.8108 - val_loss: 0.5219 - val_accuracy: 0.7448\n",
            "Epoch 699/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4109 - accuracy: 0.8108 - val_loss: 0.5223 - val_accuracy: 0.7448\n",
            "Epoch 700/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4109 - accuracy: 0.8108 - val_loss: 0.5227 - val_accuracy: 0.7500\n",
            "Epoch 701/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4111 - accuracy: 0.8108 - val_loss: 0.5227 - val_accuracy: 0.7500\n",
            "Epoch 702/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4109 - accuracy: 0.8090 - val_loss: 0.5224 - val_accuracy: 0.7448\n",
            "Epoch 703/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4113 - accuracy: 0.8090 - val_loss: 0.5225 - val_accuracy: 0.7500\n",
            "Epoch 704/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4108 - accuracy: 0.8108 - val_loss: 0.5226 - val_accuracy: 0.7500\n",
            "Epoch 705/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4110 - accuracy: 0.8090 - val_loss: 0.5227 - val_accuracy: 0.7500\n",
            "Epoch 706/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4109 - accuracy: 0.8125 - val_loss: 0.5226 - val_accuracy: 0.7448\n",
            "Epoch 707/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4111 - accuracy: 0.8090 - val_loss: 0.5222 - val_accuracy: 0.7448\n",
            "Epoch 708/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4109 - accuracy: 0.8108 - val_loss: 0.5220 - val_accuracy: 0.7500\n",
            "Epoch 709/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4110 - accuracy: 0.8108 - val_loss: 0.5221 - val_accuracy: 0.7552\n",
            "Epoch 710/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4108 - accuracy: 0.8108 - val_loss: 0.5222 - val_accuracy: 0.7552\n",
            "Epoch 711/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4111 - accuracy: 0.8108 - val_loss: 0.5220 - val_accuracy: 0.7552\n",
            "Epoch 712/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4109 - accuracy: 0.8125 - val_loss: 0.5219 - val_accuracy: 0.7552\n",
            "Epoch 713/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4108 - accuracy: 0.8108 - val_loss: 0.5220 - val_accuracy: 0.7552\n",
            "Epoch 714/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4110 - accuracy: 0.8125 - val_loss: 0.5222 - val_accuracy: 0.7552\n",
            "Epoch 715/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4108 - accuracy: 0.8108 - val_loss: 0.5225 - val_accuracy: 0.7552\n",
            "Epoch 716/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4109 - accuracy: 0.8108 - val_loss: 0.5224 - val_accuracy: 0.7552\n",
            "Epoch 717/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4106 - accuracy: 0.8108 - val_loss: 0.5223 - val_accuracy: 0.7552\n",
            "Epoch 718/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4109 - accuracy: 0.8108 - val_loss: 0.5221 - val_accuracy: 0.7552\n",
            "Epoch 719/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4108 - accuracy: 0.8108 - val_loss: 0.5223 - val_accuracy: 0.7552\n",
            "Epoch 720/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4106 - accuracy: 0.8125 - val_loss: 0.5220 - val_accuracy: 0.7552\n",
            "Epoch 721/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4106 - accuracy: 0.8108 - val_loss: 0.5222 - val_accuracy: 0.7552\n",
            "Epoch 722/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4106 - accuracy: 0.8125 - val_loss: 0.5220 - val_accuracy: 0.7552\n",
            "Epoch 723/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4107 - accuracy: 0.8108 - val_loss: 0.5219 - val_accuracy: 0.7552\n",
            "Epoch 724/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4106 - accuracy: 0.8090 - val_loss: 0.5216 - val_accuracy: 0.7500\n",
            "Epoch 725/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4107 - accuracy: 0.8108 - val_loss: 0.5218 - val_accuracy: 0.7552\n",
            "Epoch 726/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4106 - accuracy: 0.8108 - val_loss: 0.5220 - val_accuracy: 0.7552\n",
            "Epoch 727/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4105 - accuracy: 0.8108 - val_loss: 0.5223 - val_accuracy: 0.7552\n",
            "Epoch 728/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4105 - accuracy: 0.8125 - val_loss: 0.5221 - val_accuracy: 0.7552\n",
            "Epoch 729/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4105 - accuracy: 0.8142 - val_loss: 0.5218 - val_accuracy: 0.7552\n",
            "Epoch 730/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4104 - accuracy: 0.8125 - val_loss: 0.5218 - val_accuracy: 0.7552\n",
            "Epoch 731/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8108 - val_loss: 0.5218 - val_accuracy: 0.7552\n",
            "Epoch 732/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4104 - accuracy: 0.8125 - val_loss: 0.5220 - val_accuracy: 0.7552\n",
            "Epoch 733/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4103 - accuracy: 0.8125 - val_loss: 0.5222 - val_accuracy: 0.7552\n",
            "Epoch 734/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4104 - accuracy: 0.8125 - val_loss: 0.5222 - val_accuracy: 0.7552\n",
            "Epoch 735/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4106 - accuracy: 0.8108 - val_loss: 0.5223 - val_accuracy: 0.7552\n",
            "Epoch 736/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4102 - accuracy: 0.8142 - val_loss: 0.5220 - val_accuracy: 0.7552\n",
            "Epoch 737/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4101 - accuracy: 0.8125 - val_loss: 0.5220 - val_accuracy: 0.7552\n",
            "Epoch 738/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4104 - accuracy: 0.8142 - val_loss: 0.5220 - val_accuracy: 0.7552\n",
            "Epoch 739/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4107 - accuracy: 0.8125 - val_loss: 0.5221 - val_accuracy: 0.7552\n",
            "Epoch 740/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4103 - accuracy: 0.8125 - val_loss: 0.5221 - val_accuracy: 0.7552\n",
            "Epoch 741/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4102 - accuracy: 0.8125 - val_loss: 0.5220 - val_accuracy: 0.7552\n",
            "Epoch 742/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4102 - accuracy: 0.8142 - val_loss: 0.5219 - val_accuracy: 0.7552\n",
            "Epoch 743/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4103 - accuracy: 0.8142 - val_loss: 0.5219 - val_accuracy: 0.7552\n",
            "Epoch 744/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4101 - accuracy: 0.8125 - val_loss: 0.5219 - val_accuracy: 0.7552\n",
            "Epoch 745/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4099 - accuracy: 0.8125 - val_loss: 0.5219 - val_accuracy: 0.7552\n",
            "Epoch 746/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4102 - accuracy: 0.8142 - val_loss: 0.5220 - val_accuracy: 0.7552\n",
            "Epoch 747/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4100 - accuracy: 0.8125 - val_loss: 0.5219 - val_accuracy: 0.7552\n",
            "Epoch 748/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4101 - accuracy: 0.8108 - val_loss: 0.5216 - val_accuracy: 0.7552\n",
            "Epoch 749/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4100 - accuracy: 0.8108 - val_loss: 0.5219 - val_accuracy: 0.7552\n",
            "Epoch 750/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4102 - accuracy: 0.8108 - val_loss: 0.5214 - val_accuracy: 0.7552\n",
            "Epoch 751/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4100 - accuracy: 0.8125 - val_loss: 0.5214 - val_accuracy: 0.7552\n",
            "Epoch 752/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4101 - accuracy: 0.8108 - val_loss: 0.5214 - val_accuracy: 0.7552\n",
            "Epoch 753/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4100 - accuracy: 0.8125 - val_loss: 0.5214 - val_accuracy: 0.7552\n",
            "Epoch 754/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4099 - accuracy: 0.8125 - val_loss: 0.5215 - val_accuracy: 0.7552\n",
            "Epoch 755/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4099 - accuracy: 0.8108 - val_loss: 0.5213 - val_accuracy: 0.7552\n",
            "Epoch 756/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4098 - accuracy: 0.8142 - val_loss: 0.5215 - val_accuracy: 0.7552\n",
            "Epoch 757/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4099 - accuracy: 0.8125 - val_loss: 0.5215 - val_accuracy: 0.7552\n",
            "Epoch 758/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4098 - accuracy: 0.8125 - val_loss: 0.5214 - val_accuracy: 0.7552\n",
            "Epoch 759/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4098 - accuracy: 0.8125 - val_loss: 0.5217 - val_accuracy: 0.7552\n",
            "Epoch 760/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4099 - accuracy: 0.8125 - val_loss: 0.5217 - val_accuracy: 0.7552\n",
            "Epoch 761/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4097 - accuracy: 0.8108 - val_loss: 0.5217 - val_accuracy: 0.7552\n",
            "Epoch 762/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4097 - accuracy: 0.8108 - val_loss: 0.5214 - val_accuracy: 0.7552\n",
            "Epoch 763/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4098 - accuracy: 0.8125 - val_loss: 0.5218 - val_accuracy: 0.7552\n",
            "Epoch 764/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4095 - accuracy: 0.8108 - val_loss: 0.5215 - val_accuracy: 0.7552\n",
            "Epoch 765/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4099 - accuracy: 0.8125 - val_loss: 0.5214 - val_accuracy: 0.7552\n",
            "Epoch 766/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4097 - accuracy: 0.8142 - val_loss: 0.5215 - val_accuracy: 0.7552\n",
            "Epoch 767/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4097 - accuracy: 0.8142 - val_loss: 0.5214 - val_accuracy: 0.7552\n",
            "Epoch 768/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4096 - accuracy: 0.8125 - val_loss: 0.5214 - val_accuracy: 0.7552\n",
            "Epoch 769/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4095 - accuracy: 0.8108 - val_loss: 0.5215 - val_accuracy: 0.7552\n",
            "Epoch 770/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4097 - accuracy: 0.8125 - val_loss: 0.5213 - val_accuracy: 0.7552\n",
            "Epoch 771/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4096 - accuracy: 0.8125 - val_loss: 0.5213 - val_accuracy: 0.7552\n",
            "Epoch 772/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4099 - accuracy: 0.8125 - val_loss: 0.5216 - val_accuracy: 0.7552\n",
            "Epoch 773/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4096 - accuracy: 0.8073 - val_loss: 0.5214 - val_accuracy: 0.7552\n",
            "Epoch 774/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4095 - accuracy: 0.8125 - val_loss: 0.5215 - val_accuracy: 0.7552\n",
            "Epoch 775/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4095 - accuracy: 0.8090 - val_loss: 0.5216 - val_accuracy: 0.7552\n",
            "Epoch 776/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4093 - accuracy: 0.8125 - val_loss: 0.5217 - val_accuracy: 0.7552\n",
            "Epoch 777/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4093 - accuracy: 0.8125 - val_loss: 0.5215 - val_accuracy: 0.7552\n",
            "Epoch 778/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4096 - accuracy: 0.8142 - val_loss: 0.5215 - val_accuracy: 0.7552\n",
            "Epoch 779/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4093 - accuracy: 0.8142 - val_loss: 0.5216 - val_accuracy: 0.7552\n",
            "Epoch 780/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4093 - accuracy: 0.8108 - val_loss: 0.5218 - val_accuracy: 0.7552\n",
            "Epoch 781/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4092 - accuracy: 0.8125 - val_loss: 0.5218 - val_accuracy: 0.7552\n",
            "Epoch 782/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4094 - accuracy: 0.8125 - val_loss: 0.5218 - val_accuracy: 0.7500\n",
            "Epoch 783/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4093 - accuracy: 0.8142 - val_loss: 0.5218 - val_accuracy: 0.7552\n",
            "Epoch 784/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4094 - accuracy: 0.8090 - val_loss: 0.5218 - val_accuracy: 0.7552\n",
            "Epoch 785/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4094 - accuracy: 0.8108 - val_loss: 0.5217 - val_accuracy: 0.7552\n",
            "Epoch 786/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4092 - accuracy: 0.8108 - val_loss: 0.5216 - val_accuracy: 0.7552\n",
            "Epoch 787/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4091 - accuracy: 0.8125 - val_loss: 0.5217 - val_accuracy: 0.7552\n",
            "Epoch 788/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4095 - accuracy: 0.8108 - val_loss: 0.5218 - val_accuracy: 0.7552\n",
            "Epoch 789/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4093 - accuracy: 0.8125 - val_loss: 0.5220 - val_accuracy: 0.7552\n",
            "Epoch 790/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4091 - accuracy: 0.8090 - val_loss: 0.5216 - val_accuracy: 0.7552\n",
            "Epoch 791/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4093 - accuracy: 0.8108 - val_loss: 0.5220 - val_accuracy: 0.7552\n",
            "Epoch 792/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4090 - accuracy: 0.8125 - val_loss: 0.5223 - val_accuracy: 0.7552\n",
            "Epoch 793/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4091 - accuracy: 0.8160 - val_loss: 0.5224 - val_accuracy: 0.7552\n",
            "Epoch 794/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4091 - accuracy: 0.8125 - val_loss: 0.5227 - val_accuracy: 0.7552\n",
            "Epoch 795/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4090 - accuracy: 0.8108 - val_loss: 0.5222 - val_accuracy: 0.7500\n",
            "Epoch 796/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4091 - accuracy: 0.8125 - val_loss: 0.5221 - val_accuracy: 0.7552\n",
            "Epoch 797/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4091 - accuracy: 0.8125 - val_loss: 0.5224 - val_accuracy: 0.7552\n",
            "Epoch 798/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4091 - accuracy: 0.8108 - val_loss: 0.5223 - val_accuracy: 0.7552\n",
            "Epoch 799/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4089 - accuracy: 0.8125 - val_loss: 0.5225 - val_accuracy: 0.7500\n",
            "Epoch 800/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4089 - accuracy: 0.8125 - val_loss: 0.5222 - val_accuracy: 0.7552\n",
            "Epoch 801/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4088 - accuracy: 0.8142 - val_loss: 0.5222 - val_accuracy: 0.7552\n",
            "Epoch 802/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4093 - accuracy: 0.8142 - val_loss: 0.5218 - val_accuracy: 0.7500\n",
            "Epoch 803/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4091 - accuracy: 0.8090 - val_loss: 0.5216 - val_accuracy: 0.7500\n",
            "Epoch 804/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4089 - accuracy: 0.8125 - val_loss: 0.5217 - val_accuracy: 0.7500\n",
            "Epoch 805/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4089 - accuracy: 0.8125 - val_loss: 0.5217 - val_accuracy: 0.7552\n",
            "Epoch 806/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4089 - accuracy: 0.8125 - val_loss: 0.5215 - val_accuracy: 0.7500\n",
            "Epoch 807/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4088 - accuracy: 0.8108 - val_loss: 0.5221 - val_accuracy: 0.7500\n",
            "Epoch 808/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4090 - accuracy: 0.8125 - val_loss: 0.5221 - val_accuracy: 0.7500\n",
            "Epoch 809/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4090 - accuracy: 0.8142 - val_loss: 0.5217 - val_accuracy: 0.7448\n",
            "Epoch 810/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4088 - accuracy: 0.8125 - val_loss: 0.5219 - val_accuracy: 0.7500\n",
            "Epoch 811/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4087 - accuracy: 0.8108 - val_loss: 0.5222 - val_accuracy: 0.7500\n",
            "Epoch 812/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4087 - accuracy: 0.8108 - val_loss: 0.5221 - val_accuracy: 0.7500\n",
            "Epoch 813/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4088 - accuracy: 0.8125 - val_loss: 0.5223 - val_accuracy: 0.7500\n",
            "Epoch 814/1500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.4087 - accuracy: 0.8142 - val_loss: 0.5224 - val_accuracy: 0.7500\n",
            "Epoch 815/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4087 - accuracy: 0.8160 - val_loss: 0.5223 - val_accuracy: 0.7448\n",
            "Epoch 816/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4088 - accuracy: 0.8125 - val_loss: 0.5224 - val_accuracy: 0.7448\n",
            "Epoch 817/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4086 - accuracy: 0.8125 - val_loss: 0.5222 - val_accuracy: 0.7448\n",
            "Epoch 818/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4086 - accuracy: 0.8125 - val_loss: 0.5222 - val_accuracy: 0.7448\n",
            "Epoch 819/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4086 - accuracy: 0.8125 - val_loss: 0.5222 - val_accuracy: 0.7448\n",
            "Epoch 820/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4086 - accuracy: 0.8142 - val_loss: 0.5224 - val_accuracy: 0.7448\n",
            "Epoch 821/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4084 - accuracy: 0.8125 - val_loss: 0.5221 - val_accuracy: 0.7448\n",
            "Epoch 822/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4084 - accuracy: 0.8108 - val_loss: 0.5221 - val_accuracy: 0.7448\n",
            "Epoch 823/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4084 - accuracy: 0.8108 - val_loss: 0.5222 - val_accuracy: 0.7448\n",
            "Epoch 824/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4085 - accuracy: 0.8125 - val_loss: 0.5224 - val_accuracy: 0.7500\n",
            "Epoch 825/1500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.4086 - accuracy: 0.8125 - val_loss: 0.5222 - val_accuracy: 0.7448\n",
            "Epoch 826/1500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.4086 - accuracy: 0.8142 - val_loss: 0.5222 - val_accuracy: 0.7500\n",
            "Epoch 827/1500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.4086 - accuracy: 0.8125 - val_loss: 0.5222 - val_accuracy: 0.7500\n",
            "Epoch 828/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4086 - accuracy: 0.8160 - val_loss: 0.5222 - val_accuracy: 0.7500\n",
            "Epoch 829/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4082 - accuracy: 0.8125 - val_loss: 0.5224 - val_accuracy: 0.7500\n",
            "Epoch 830/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4084 - accuracy: 0.8125 - val_loss: 0.5223 - val_accuracy: 0.7500\n",
            "Epoch 831/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4085 - accuracy: 0.8125 - val_loss: 0.5224 - val_accuracy: 0.7500\n",
            "Epoch 832/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4083 - accuracy: 0.8125 - val_loss: 0.5223 - val_accuracy: 0.7448\n",
            "Epoch 833/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4081 - accuracy: 0.8125 - val_loss: 0.5224 - val_accuracy: 0.7500\n",
            "Epoch 834/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4086 - accuracy: 0.8125 - val_loss: 0.5224 - val_accuracy: 0.7500\n",
            "Epoch 835/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4080 - accuracy: 0.8160 - val_loss: 0.5223 - val_accuracy: 0.7448\n",
            "Epoch 836/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4081 - accuracy: 0.8142 - val_loss: 0.5222 - val_accuracy: 0.7448\n",
            "Epoch 837/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4082 - accuracy: 0.8108 - val_loss: 0.5222 - val_accuracy: 0.7448\n",
            "Epoch 838/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4081 - accuracy: 0.8125 - val_loss: 0.5225 - val_accuracy: 0.7448\n",
            "Epoch 839/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4081 - accuracy: 0.8142 - val_loss: 0.5225 - val_accuracy: 0.7500\n",
            "Epoch 840/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4081 - accuracy: 0.8125 - val_loss: 0.5224 - val_accuracy: 0.7500\n",
            "Epoch 841/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4080 - accuracy: 0.8142 - val_loss: 0.5227 - val_accuracy: 0.7500\n",
            "Epoch 842/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4080 - accuracy: 0.8160 - val_loss: 0.5226 - val_accuracy: 0.7448\n",
            "Epoch 843/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4080 - accuracy: 0.8177 - val_loss: 0.5223 - val_accuracy: 0.7448\n",
            "Epoch 844/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4080 - accuracy: 0.8108 - val_loss: 0.5226 - val_accuracy: 0.7500\n",
            "Epoch 845/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4081 - accuracy: 0.8125 - val_loss: 0.5227 - val_accuracy: 0.7500\n",
            "Epoch 846/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4082 - accuracy: 0.8125 - val_loss: 0.5226 - val_accuracy: 0.7500\n",
            "Epoch 847/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4080 - accuracy: 0.8160 - val_loss: 0.5224 - val_accuracy: 0.7448\n",
            "Epoch 848/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4083 - accuracy: 0.8142 - val_loss: 0.5224 - val_accuracy: 0.7448\n",
            "Epoch 849/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4080 - accuracy: 0.8142 - val_loss: 0.5225 - val_accuracy: 0.7448\n",
            "Epoch 850/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4079 - accuracy: 0.8108 - val_loss: 0.5223 - val_accuracy: 0.7500\n",
            "Epoch 851/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4080 - accuracy: 0.8125 - val_loss: 0.5221 - val_accuracy: 0.7448\n",
            "Epoch 852/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4078 - accuracy: 0.8125 - val_loss: 0.5223 - val_accuracy: 0.7448\n",
            "Epoch 853/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4080 - accuracy: 0.8108 - val_loss: 0.5225 - val_accuracy: 0.7448\n",
            "Epoch 854/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4077 - accuracy: 0.8125 - val_loss: 0.5226 - val_accuracy: 0.7500\n",
            "Epoch 855/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4077 - accuracy: 0.8160 - val_loss: 0.5225 - val_accuracy: 0.7448\n",
            "Epoch 856/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4078 - accuracy: 0.8142 - val_loss: 0.5228 - val_accuracy: 0.7448\n",
            "Epoch 857/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4077 - accuracy: 0.8142 - val_loss: 0.5226 - val_accuracy: 0.7448\n",
            "Epoch 858/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4078 - accuracy: 0.8160 - val_loss: 0.5223 - val_accuracy: 0.7448\n",
            "Epoch 859/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4076 - accuracy: 0.8125 - val_loss: 0.5223 - val_accuracy: 0.7500\n",
            "Epoch 860/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4077 - accuracy: 0.8125 - val_loss: 0.5223 - val_accuracy: 0.7500\n",
            "Epoch 861/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4077 - accuracy: 0.8142 - val_loss: 0.5223 - val_accuracy: 0.7448\n",
            "Epoch 862/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4074 - accuracy: 0.8160 - val_loss: 0.5223 - val_accuracy: 0.7448\n",
            "Epoch 863/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4076 - accuracy: 0.8125 - val_loss: 0.5223 - val_accuracy: 0.7448\n",
            "Epoch 864/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4077 - accuracy: 0.8125 - val_loss: 0.5226 - val_accuracy: 0.7448\n",
            "Epoch 865/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4075 - accuracy: 0.8108 - val_loss: 0.5226 - val_accuracy: 0.7448\n",
            "Epoch 866/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4076 - accuracy: 0.8142 - val_loss: 0.5224 - val_accuracy: 0.7448\n",
            "Epoch 867/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4076 - accuracy: 0.8142 - val_loss: 0.5225 - val_accuracy: 0.7448\n",
            "Epoch 868/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4076 - accuracy: 0.8142 - val_loss: 0.5224 - val_accuracy: 0.7448\n",
            "Epoch 869/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4076 - accuracy: 0.8160 - val_loss: 0.5225 - val_accuracy: 0.7448\n",
            "Epoch 870/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4075 - accuracy: 0.8125 - val_loss: 0.5224 - val_accuracy: 0.7448\n",
            "Epoch 871/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4075 - accuracy: 0.8125 - val_loss: 0.5222 - val_accuracy: 0.7448\n",
            "Epoch 872/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4077 - accuracy: 0.8142 - val_loss: 0.5221 - val_accuracy: 0.7448\n",
            "Epoch 873/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4077 - accuracy: 0.8125 - val_loss: 0.5227 - val_accuracy: 0.7448\n",
            "Epoch 874/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4076 - accuracy: 0.8125 - val_loss: 0.5231 - val_accuracy: 0.7448\n",
            "Epoch 875/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4075 - accuracy: 0.8142 - val_loss: 0.5231 - val_accuracy: 0.7448\n",
            "Epoch 876/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4077 - accuracy: 0.8108 - val_loss: 0.5229 - val_accuracy: 0.7448\n",
            "Epoch 877/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4075 - accuracy: 0.8125 - val_loss: 0.5223 - val_accuracy: 0.7448\n",
            "Epoch 878/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4073 - accuracy: 0.8108 - val_loss: 0.5226 - val_accuracy: 0.7448\n",
            "Epoch 879/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4074 - accuracy: 0.8142 - val_loss: 0.5226 - val_accuracy: 0.7448\n",
            "Epoch 880/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4072 - accuracy: 0.8142 - val_loss: 0.5224 - val_accuracy: 0.7448\n",
            "Epoch 881/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4073 - accuracy: 0.8142 - val_loss: 0.5224 - val_accuracy: 0.7448\n",
            "Epoch 882/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4071 - accuracy: 0.8194 - val_loss: 0.5220 - val_accuracy: 0.7448\n",
            "Epoch 883/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4073 - accuracy: 0.8142 - val_loss: 0.5224 - val_accuracy: 0.7448\n",
            "Epoch 884/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4074 - accuracy: 0.8142 - val_loss: 0.5221 - val_accuracy: 0.7448\n",
            "Epoch 885/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4075 - accuracy: 0.8125 - val_loss: 0.5224 - val_accuracy: 0.7448\n",
            "Epoch 886/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4072 - accuracy: 0.8177 - val_loss: 0.5222 - val_accuracy: 0.7448\n",
            "Epoch 887/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4071 - accuracy: 0.8160 - val_loss: 0.5220 - val_accuracy: 0.7448\n",
            "Epoch 888/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4073 - accuracy: 0.8142 - val_loss: 0.5218 - val_accuracy: 0.7448\n",
            "Epoch 889/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4077 - accuracy: 0.8108 - val_loss: 0.5221 - val_accuracy: 0.7448\n",
            "Epoch 890/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4071 - accuracy: 0.8125 - val_loss: 0.5222 - val_accuracy: 0.7448\n",
            "Epoch 891/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4073 - accuracy: 0.8142 - val_loss: 0.5223 - val_accuracy: 0.7448\n",
            "Epoch 892/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4070 - accuracy: 0.8194 - val_loss: 0.5222 - val_accuracy: 0.7448\n",
            "Epoch 893/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4071 - accuracy: 0.8177 - val_loss: 0.5224 - val_accuracy: 0.7448\n",
            "Epoch 894/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4071 - accuracy: 0.8108 - val_loss: 0.5229 - val_accuracy: 0.7448\n",
            "Epoch 895/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4074 - accuracy: 0.8142 - val_loss: 0.5229 - val_accuracy: 0.7448\n",
            "Epoch 896/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4071 - accuracy: 0.8125 - val_loss: 0.5225 - val_accuracy: 0.7448\n",
            "Epoch 897/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4072 - accuracy: 0.8160 - val_loss: 0.5227 - val_accuracy: 0.7448\n",
            "Epoch 898/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4071 - accuracy: 0.8160 - val_loss: 0.5226 - val_accuracy: 0.7448\n",
            "Epoch 899/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4071 - accuracy: 0.8160 - val_loss: 0.5224 - val_accuracy: 0.7448\n",
            "Epoch 900/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4071 - accuracy: 0.8125 - val_loss: 0.5226 - val_accuracy: 0.7448\n",
            "Epoch 901/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4071 - accuracy: 0.8142 - val_loss: 0.5226 - val_accuracy: 0.7448\n",
            "Epoch 902/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4069 - accuracy: 0.8160 - val_loss: 0.5226 - val_accuracy: 0.7448\n",
            "Epoch 903/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4073 - accuracy: 0.8125 - val_loss: 0.5227 - val_accuracy: 0.7448\n",
            "Epoch 904/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4069 - accuracy: 0.8160 - val_loss: 0.5226 - val_accuracy: 0.7448\n",
            "Epoch 905/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4069 - accuracy: 0.8194 - val_loss: 0.5225 - val_accuracy: 0.7448\n",
            "Epoch 906/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4071 - accuracy: 0.8142 - val_loss: 0.5225 - val_accuracy: 0.7448\n",
            "Epoch 907/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4071 - accuracy: 0.8142 - val_loss: 0.5226 - val_accuracy: 0.7448\n",
            "Epoch 908/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4066 - accuracy: 0.8160 - val_loss: 0.5226 - val_accuracy: 0.7448\n",
            "Epoch 909/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4069 - accuracy: 0.8160 - val_loss: 0.5227 - val_accuracy: 0.7448\n",
            "Epoch 910/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4068 - accuracy: 0.8160 - val_loss: 0.5228 - val_accuracy: 0.7448\n",
            "Epoch 911/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4066 - accuracy: 0.8142 - val_loss: 0.5230 - val_accuracy: 0.7448\n",
            "Epoch 912/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4070 - accuracy: 0.8125 - val_loss: 0.5231 - val_accuracy: 0.7448\n",
            "Epoch 913/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4066 - accuracy: 0.8177 - val_loss: 0.5231 - val_accuracy: 0.7448\n",
            "Epoch 914/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4067 - accuracy: 0.8177 - val_loss: 0.5228 - val_accuracy: 0.7448\n",
            "Epoch 915/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4066 - accuracy: 0.8160 - val_loss: 0.5229 - val_accuracy: 0.7448\n",
            "Epoch 916/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4068 - accuracy: 0.8125 - val_loss: 0.5228 - val_accuracy: 0.7448\n",
            "Epoch 917/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4066 - accuracy: 0.8160 - val_loss: 0.5225 - val_accuracy: 0.7448\n",
            "Epoch 918/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4065 - accuracy: 0.8125 - val_loss: 0.5229 - val_accuracy: 0.7448\n",
            "Epoch 919/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4065 - accuracy: 0.8177 - val_loss: 0.5228 - val_accuracy: 0.7448\n",
            "Epoch 920/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4067 - accuracy: 0.8160 - val_loss: 0.5224 - val_accuracy: 0.7448\n",
            "Epoch 921/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4064 - accuracy: 0.8125 - val_loss: 0.5227 - val_accuracy: 0.7448\n",
            "Epoch 922/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4064 - accuracy: 0.8160 - val_loss: 0.5227 - val_accuracy: 0.7448\n",
            "Epoch 923/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4065 - accuracy: 0.8160 - val_loss: 0.5226 - val_accuracy: 0.7448\n",
            "Epoch 924/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4063 - accuracy: 0.8194 - val_loss: 0.5226 - val_accuracy: 0.7448\n",
            "Epoch 925/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4065 - accuracy: 0.8160 - val_loss: 0.5226 - val_accuracy: 0.7448\n",
            "Epoch 926/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4065 - accuracy: 0.8160 - val_loss: 0.5223 - val_accuracy: 0.7448\n",
            "Epoch 927/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4062 - accuracy: 0.8160 - val_loss: 0.5222 - val_accuracy: 0.7448\n",
            "Epoch 928/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4064 - accuracy: 0.8090 - val_loss: 0.5225 - val_accuracy: 0.7448\n",
            "Epoch 929/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4063 - accuracy: 0.8177 - val_loss: 0.5223 - val_accuracy: 0.7448\n",
            "Epoch 930/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4063 - accuracy: 0.8142 - val_loss: 0.5224 - val_accuracy: 0.7448\n",
            "Epoch 931/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4062 - accuracy: 0.8142 - val_loss: 0.5224 - val_accuracy: 0.7448\n",
            "Epoch 932/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4063 - accuracy: 0.8125 - val_loss: 0.5225 - val_accuracy: 0.7448\n",
            "Epoch 933/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4060 - accuracy: 0.8142 - val_loss: 0.5226 - val_accuracy: 0.7448\n",
            "Epoch 934/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4061 - accuracy: 0.8108 - val_loss: 0.5228 - val_accuracy: 0.7448\n",
            "Epoch 935/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4060 - accuracy: 0.8142 - val_loss: 0.5228 - val_accuracy: 0.7448\n",
            "Epoch 936/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4062 - accuracy: 0.8160 - val_loss: 0.5228 - val_accuracy: 0.7448\n",
            "Epoch 937/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4062 - accuracy: 0.8108 - val_loss: 0.5226 - val_accuracy: 0.7448\n",
            "Epoch 938/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4061 - accuracy: 0.8194 - val_loss: 0.5225 - val_accuracy: 0.7448\n",
            "Epoch 939/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4060 - accuracy: 0.8160 - val_loss: 0.5224 - val_accuracy: 0.7448\n",
            "Epoch 940/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4059 - accuracy: 0.8108 - val_loss: 0.5229 - val_accuracy: 0.7448\n",
            "Epoch 941/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4060 - accuracy: 0.8142 - val_loss: 0.5226 - val_accuracy: 0.7448\n",
            "Epoch 942/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4060 - accuracy: 0.8142 - val_loss: 0.5228 - val_accuracy: 0.7448\n",
            "Epoch 943/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4057 - accuracy: 0.8125 - val_loss: 0.5233 - val_accuracy: 0.7448\n",
            "Epoch 944/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4059 - accuracy: 0.8160 - val_loss: 0.5232 - val_accuracy: 0.7448\n",
            "Epoch 945/1500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.4057 - accuracy: 0.8142 - val_loss: 0.5230 - val_accuracy: 0.7448\n",
            "Epoch 946/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4058 - accuracy: 0.8142 - val_loss: 0.5232 - val_accuracy: 0.7448\n",
            "Epoch 947/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4057 - accuracy: 0.8194 - val_loss: 0.5231 - val_accuracy: 0.7448\n",
            "Epoch 948/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4057 - accuracy: 0.8142 - val_loss: 0.5233 - val_accuracy: 0.7448\n",
            "Epoch 949/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4057 - accuracy: 0.8160 - val_loss: 0.5231 - val_accuracy: 0.7448\n",
            "Epoch 950/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4055 - accuracy: 0.8177 - val_loss: 0.5231 - val_accuracy: 0.7448\n",
            "Epoch 951/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4058 - accuracy: 0.8160 - val_loss: 0.5231 - val_accuracy: 0.7448\n",
            "Epoch 952/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4056 - accuracy: 0.8142 - val_loss: 0.5231 - val_accuracy: 0.7448\n",
            "Epoch 953/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4056 - accuracy: 0.8160 - val_loss: 0.5230 - val_accuracy: 0.7448\n",
            "Epoch 954/1500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.4055 - accuracy: 0.8194 - val_loss: 0.5228 - val_accuracy: 0.7448\n",
            "Epoch 955/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4056 - accuracy: 0.8108 - val_loss: 0.5230 - val_accuracy: 0.7448\n",
            "Epoch 956/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4054 - accuracy: 0.8125 - val_loss: 0.5231 - val_accuracy: 0.7448\n",
            "Epoch 957/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4054 - accuracy: 0.8125 - val_loss: 0.5235 - val_accuracy: 0.7448\n",
            "Epoch 958/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4052 - accuracy: 0.8108 - val_loss: 0.5235 - val_accuracy: 0.7448\n",
            "Epoch 959/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4052 - accuracy: 0.8142 - val_loss: 0.5232 - val_accuracy: 0.7448\n",
            "Epoch 960/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4052 - accuracy: 0.8142 - val_loss: 0.5232 - val_accuracy: 0.7448\n",
            "Epoch 961/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4050 - accuracy: 0.8142 - val_loss: 0.5233 - val_accuracy: 0.7448\n",
            "Epoch 962/1500\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.4051 - accuracy: 0.8142 - val_loss: 0.5231 - val_accuracy: 0.7448\n",
            "Epoch 963/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4049 - accuracy: 0.8125 - val_loss: 0.5235 - val_accuracy: 0.7448\n",
            "Epoch 964/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4049 - accuracy: 0.8108 - val_loss: 0.5235 - val_accuracy: 0.7448\n",
            "Epoch 965/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4050 - accuracy: 0.8160 - val_loss: 0.5235 - val_accuracy: 0.7448\n",
            "Epoch 966/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4050 - accuracy: 0.8142 - val_loss: 0.5232 - val_accuracy: 0.7448\n",
            "Epoch 967/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4052 - accuracy: 0.8125 - val_loss: 0.5234 - val_accuracy: 0.7448\n",
            "Epoch 968/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4050 - accuracy: 0.8160 - val_loss: 0.5230 - val_accuracy: 0.7448\n",
            "Epoch 969/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4050 - accuracy: 0.8142 - val_loss: 0.5231 - val_accuracy: 0.7448\n",
            "Epoch 970/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4047 - accuracy: 0.8142 - val_loss: 0.5229 - val_accuracy: 0.7448\n",
            "Epoch 971/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4049 - accuracy: 0.8142 - val_loss: 0.5228 - val_accuracy: 0.7448\n",
            "Epoch 972/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4046 - accuracy: 0.8108 - val_loss: 0.5228 - val_accuracy: 0.7448\n",
            "Epoch 973/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4047 - accuracy: 0.8142 - val_loss: 0.5228 - val_accuracy: 0.7448\n",
            "Epoch 974/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4048 - accuracy: 0.8108 - val_loss: 0.5229 - val_accuracy: 0.7448\n",
            "Epoch 975/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4046 - accuracy: 0.8160 - val_loss: 0.5228 - val_accuracy: 0.7448\n",
            "Epoch 976/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4046 - accuracy: 0.8125 - val_loss: 0.5228 - val_accuracy: 0.7448\n",
            "Epoch 977/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4046 - accuracy: 0.8108 - val_loss: 0.5231 - val_accuracy: 0.7448\n",
            "Epoch 978/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4044 - accuracy: 0.8125 - val_loss: 0.5233 - val_accuracy: 0.7448\n",
            "Epoch 979/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4045 - accuracy: 0.8108 - val_loss: 0.5234 - val_accuracy: 0.7448\n",
            "Epoch 980/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4043 - accuracy: 0.8108 - val_loss: 0.5234 - val_accuracy: 0.7448\n",
            "Epoch 981/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4046 - accuracy: 0.8073 - val_loss: 0.5235 - val_accuracy: 0.7448\n",
            "Epoch 982/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4042 - accuracy: 0.8142 - val_loss: 0.5232 - val_accuracy: 0.7448\n",
            "Epoch 983/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4044 - accuracy: 0.8108 - val_loss: 0.5230 - val_accuracy: 0.7448\n",
            "Epoch 984/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4042 - accuracy: 0.8073 - val_loss: 0.5232 - val_accuracy: 0.7448\n",
            "Epoch 985/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4042 - accuracy: 0.8142 - val_loss: 0.5229 - val_accuracy: 0.7448\n",
            "Epoch 986/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4041 - accuracy: 0.8125 - val_loss: 0.5229 - val_accuracy: 0.7448\n",
            "Epoch 987/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4043 - accuracy: 0.8125 - val_loss: 0.5228 - val_accuracy: 0.7396\n",
            "Epoch 988/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4040 - accuracy: 0.8125 - val_loss: 0.5227 - val_accuracy: 0.7448\n",
            "Epoch 989/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4042 - accuracy: 0.8142 - val_loss: 0.5224 - val_accuracy: 0.7448\n",
            "Epoch 990/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4042 - accuracy: 0.8108 - val_loss: 0.5227 - val_accuracy: 0.7396\n",
            "Epoch 991/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4039 - accuracy: 0.8125 - val_loss: 0.5228 - val_accuracy: 0.7396\n",
            "Epoch 992/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4041 - accuracy: 0.8108 - val_loss: 0.5231 - val_accuracy: 0.7396\n",
            "Epoch 993/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4039 - accuracy: 0.8125 - val_loss: 0.5231 - val_accuracy: 0.7448\n",
            "Epoch 994/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4040 - accuracy: 0.8142 - val_loss: 0.5230 - val_accuracy: 0.7448\n",
            "Epoch 995/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4040 - accuracy: 0.8073 - val_loss: 0.5233 - val_accuracy: 0.7448\n",
            "Epoch 996/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4040 - accuracy: 0.8125 - val_loss: 0.5230 - val_accuracy: 0.7448\n",
            "Epoch 997/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4039 - accuracy: 0.8090 - val_loss: 0.5229 - val_accuracy: 0.7448\n",
            "Epoch 998/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4039 - accuracy: 0.8142 - val_loss: 0.5228 - val_accuracy: 0.7448\n",
            "Epoch 999/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4038 - accuracy: 0.8108 - val_loss: 0.5232 - val_accuracy: 0.7448\n",
            "Epoch 1000/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4037 - accuracy: 0.8125 - val_loss: 0.5229 - val_accuracy: 0.7396\n",
            "Epoch 1001/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4037 - accuracy: 0.8073 - val_loss: 0.5231 - val_accuracy: 0.7396\n",
            "Epoch 1002/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4038 - accuracy: 0.8142 - val_loss: 0.5229 - val_accuracy: 0.7396\n",
            "Epoch 1003/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4037 - accuracy: 0.8108 - val_loss: 0.5227 - val_accuracy: 0.7396\n",
            "Epoch 1004/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4038 - accuracy: 0.8056 - val_loss: 0.5231 - val_accuracy: 0.7396\n",
            "Epoch 1005/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4038 - accuracy: 0.8125 - val_loss: 0.5231 - val_accuracy: 0.7396\n",
            "Epoch 1006/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4035 - accuracy: 0.8073 - val_loss: 0.5232 - val_accuracy: 0.7396\n",
            "Epoch 1007/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4035 - accuracy: 0.8108 - val_loss: 0.5234 - val_accuracy: 0.7448\n",
            "Epoch 1008/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4035 - accuracy: 0.8108 - val_loss: 0.5233 - val_accuracy: 0.7448\n",
            "Epoch 1009/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4034 - accuracy: 0.8125 - val_loss: 0.5230 - val_accuracy: 0.7448\n",
            "Epoch 1010/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4034 - accuracy: 0.8108 - val_loss: 0.5232 - val_accuracy: 0.7448\n",
            "Epoch 1011/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4035 - accuracy: 0.8090 - val_loss: 0.5234 - val_accuracy: 0.7396\n",
            "Epoch 1012/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4037 - accuracy: 0.8125 - val_loss: 0.5232 - val_accuracy: 0.7396\n",
            "Epoch 1013/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4035 - accuracy: 0.8073 - val_loss: 0.5236 - val_accuracy: 0.7396\n",
            "Epoch 1014/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4033 - accuracy: 0.8108 - val_loss: 0.5238 - val_accuracy: 0.7500\n",
            "Epoch 1015/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4036 - accuracy: 0.8108 - val_loss: 0.5237 - val_accuracy: 0.7500\n",
            "Epoch 1016/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4032 - accuracy: 0.8090 - val_loss: 0.5237 - val_accuracy: 0.7500\n",
            "Epoch 1017/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4032 - accuracy: 0.8160 - val_loss: 0.5233 - val_accuracy: 0.7396\n",
            "Epoch 1018/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4033 - accuracy: 0.8125 - val_loss: 0.5232 - val_accuracy: 0.7448\n",
            "Epoch 1019/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4033 - accuracy: 0.8125 - val_loss: 0.5231 - val_accuracy: 0.7448\n",
            "Epoch 1020/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4036 - accuracy: 0.8108 - val_loss: 0.5233 - val_accuracy: 0.7448\n",
            "Epoch 1021/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4031 - accuracy: 0.8108 - val_loss: 0.5232 - val_accuracy: 0.7448\n",
            "Epoch 1022/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4031 - accuracy: 0.8073 - val_loss: 0.5232 - val_accuracy: 0.7448\n",
            "Epoch 1023/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4031 - accuracy: 0.8125 - val_loss: 0.5234 - val_accuracy: 0.7500\n",
            "Epoch 1024/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4031 - accuracy: 0.8090 - val_loss: 0.5235 - val_accuracy: 0.7448\n",
            "Epoch 1025/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4033 - accuracy: 0.8090 - val_loss: 0.5236 - val_accuracy: 0.7448\n",
            "Epoch 1026/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4033 - accuracy: 0.8160 - val_loss: 0.5234 - val_accuracy: 0.7500\n",
            "Epoch 1027/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4030 - accuracy: 0.8108 - val_loss: 0.5234 - val_accuracy: 0.7500\n",
            "Epoch 1028/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4032 - accuracy: 0.8142 - val_loss: 0.5235 - val_accuracy: 0.7500\n",
            "Epoch 1029/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4029 - accuracy: 0.8142 - val_loss: 0.5232 - val_accuracy: 0.7448\n",
            "Epoch 1030/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4029 - accuracy: 0.8090 - val_loss: 0.5236 - val_accuracy: 0.7500\n",
            "Epoch 1031/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4028 - accuracy: 0.8108 - val_loss: 0.5234 - val_accuracy: 0.7500\n",
            "Epoch 1032/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4027 - accuracy: 0.8108 - val_loss: 0.5237 - val_accuracy: 0.7500\n",
            "Epoch 1033/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4027 - accuracy: 0.8108 - val_loss: 0.5235 - val_accuracy: 0.7500\n",
            "Epoch 1034/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4027 - accuracy: 0.8073 - val_loss: 0.5239 - val_accuracy: 0.7500\n",
            "Epoch 1035/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4032 - accuracy: 0.8108 - val_loss: 0.5237 - val_accuracy: 0.7500\n",
            "Epoch 1036/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4027 - accuracy: 0.8090 - val_loss: 0.5237 - val_accuracy: 0.7500\n",
            "Epoch 1037/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4026 - accuracy: 0.8073 - val_loss: 0.5242 - val_accuracy: 0.7500\n",
            "Epoch 1038/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4027 - accuracy: 0.8108 - val_loss: 0.5243 - val_accuracy: 0.7500\n",
            "Epoch 1039/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4025 - accuracy: 0.8142 - val_loss: 0.5242 - val_accuracy: 0.7500\n",
            "Epoch 1040/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4027 - accuracy: 0.8142 - val_loss: 0.5239 - val_accuracy: 0.7500\n",
            "Epoch 1041/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4026 - accuracy: 0.8108 - val_loss: 0.5240 - val_accuracy: 0.7500\n",
            "Epoch 1042/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4024 - accuracy: 0.8073 - val_loss: 0.5243 - val_accuracy: 0.7500\n",
            "Epoch 1043/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4025 - accuracy: 0.8125 - val_loss: 0.5241 - val_accuracy: 0.7500\n",
            "Epoch 1044/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4025 - accuracy: 0.8125 - val_loss: 0.5240 - val_accuracy: 0.7500\n",
            "Epoch 1045/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4023 - accuracy: 0.8090 - val_loss: 0.5238 - val_accuracy: 0.7500\n",
            "Epoch 1046/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4024 - accuracy: 0.8142 - val_loss: 0.5239 - val_accuracy: 0.7500\n",
            "Epoch 1047/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4026 - accuracy: 0.8142 - val_loss: 0.5239 - val_accuracy: 0.7500\n",
            "Epoch 1048/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4023 - accuracy: 0.8125 - val_loss: 0.5236 - val_accuracy: 0.7500\n",
            "Epoch 1049/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4027 - accuracy: 0.8090 - val_loss: 0.5241 - val_accuracy: 0.7500\n",
            "Epoch 1050/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4023 - accuracy: 0.8160 - val_loss: 0.5240 - val_accuracy: 0.7500\n",
            "Epoch 1051/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4022 - accuracy: 0.8090 - val_loss: 0.5240 - val_accuracy: 0.7500\n",
            "Epoch 1052/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4022 - accuracy: 0.8142 - val_loss: 0.5240 - val_accuracy: 0.7500\n",
            "Epoch 1053/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4021 - accuracy: 0.8090 - val_loss: 0.5239 - val_accuracy: 0.7500\n",
            "Epoch 1054/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4023 - accuracy: 0.8108 - val_loss: 0.5240 - val_accuracy: 0.7500\n",
            "Epoch 1055/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4021 - accuracy: 0.8125 - val_loss: 0.5243 - val_accuracy: 0.7448\n",
            "Epoch 1056/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4021 - accuracy: 0.8090 - val_loss: 0.5243 - val_accuracy: 0.7448\n",
            "Epoch 1057/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4022 - accuracy: 0.8160 - val_loss: 0.5240 - val_accuracy: 0.7500\n",
            "Epoch 1058/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4022 - accuracy: 0.8108 - val_loss: 0.5243 - val_accuracy: 0.7448\n",
            "Epoch 1059/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4022 - accuracy: 0.8108 - val_loss: 0.5243 - val_accuracy: 0.7448\n",
            "Epoch 1060/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4020 - accuracy: 0.8125 - val_loss: 0.5240 - val_accuracy: 0.7500\n",
            "Epoch 1061/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4019 - accuracy: 0.8108 - val_loss: 0.5242 - val_accuracy: 0.7500\n",
            "Epoch 1062/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4019 - accuracy: 0.8090 - val_loss: 0.5242 - val_accuracy: 0.7448\n",
            "Epoch 1063/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4019 - accuracy: 0.8125 - val_loss: 0.5241 - val_accuracy: 0.7500\n",
            "Epoch 1064/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4021 - accuracy: 0.8142 - val_loss: 0.5241 - val_accuracy: 0.7500\n",
            "Epoch 1065/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4020 - accuracy: 0.8125 - val_loss: 0.5242 - val_accuracy: 0.7500\n",
            "Epoch 1066/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4019 - accuracy: 0.8108 - val_loss: 0.5246 - val_accuracy: 0.7500\n",
            "Epoch 1067/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4018 - accuracy: 0.8160 - val_loss: 0.5245 - val_accuracy: 0.7500\n",
            "Epoch 1068/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4018 - accuracy: 0.8160 - val_loss: 0.5246 - val_accuracy: 0.7500\n",
            "Epoch 1069/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4017 - accuracy: 0.8125 - val_loss: 0.5251 - val_accuracy: 0.7500\n",
            "Epoch 1070/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4018 - accuracy: 0.8142 - val_loss: 0.5250 - val_accuracy: 0.7500\n",
            "Epoch 1071/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4019 - accuracy: 0.8090 - val_loss: 0.5246 - val_accuracy: 0.7500\n",
            "Epoch 1072/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4018 - accuracy: 0.8108 - val_loss: 0.5243 - val_accuracy: 0.7500\n",
            "Epoch 1073/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4016 - accuracy: 0.8125 - val_loss: 0.5243 - val_accuracy: 0.7500\n",
            "Epoch 1074/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4016 - accuracy: 0.8160 - val_loss: 0.5241 - val_accuracy: 0.7500\n",
            "Epoch 1075/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4016 - accuracy: 0.8142 - val_loss: 0.5242 - val_accuracy: 0.7500\n",
            "Epoch 1076/1500\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.4016 - accuracy: 0.8160 - val_loss: 0.5241 - val_accuracy: 0.7500\n",
            "Epoch 1077/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4013 - accuracy: 0.8125 - val_loss: 0.5241 - val_accuracy: 0.7500\n",
            "Epoch 1078/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4016 - accuracy: 0.8142 - val_loss: 0.5240 - val_accuracy: 0.7500\n",
            "Epoch 1079/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4015 - accuracy: 0.8108 - val_loss: 0.5243 - val_accuracy: 0.7500\n",
            "Epoch 1080/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4014 - accuracy: 0.8108 - val_loss: 0.5247 - val_accuracy: 0.7500\n",
            "Epoch 1081/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4014 - accuracy: 0.8125 - val_loss: 0.5244 - val_accuracy: 0.7500\n",
            "Epoch 1082/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4015 - accuracy: 0.8160 - val_loss: 0.5241 - val_accuracy: 0.7500\n",
            "Epoch 1083/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4015 - accuracy: 0.8090 - val_loss: 0.5245 - val_accuracy: 0.7500\n",
            "Epoch 1084/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4013 - accuracy: 0.8108 - val_loss: 0.5244 - val_accuracy: 0.7500\n",
            "Epoch 1085/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4014 - accuracy: 0.8142 - val_loss: 0.5244 - val_accuracy: 0.7500\n",
            "Epoch 1086/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4012 - accuracy: 0.8142 - val_loss: 0.5244 - val_accuracy: 0.7500\n",
            "Epoch 1087/1500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.4013 - accuracy: 0.8160 - val_loss: 0.5242 - val_accuracy: 0.7500\n",
            "Epoch 1088/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4010 - accuracy: 0.8125 - val_loss: 0.5241 - val_accuracy: 0.7500\n",
            "Epoch 1089/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4011 - accuracy: 0.8160 - val_loss: 0.5241 - val_accuracy: 0.7500\n",
            "Epoch 1090/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4015 - accuracy: 0.8142 - val_loss: 0.5243 - val_accuracy: 0.7552\n",
            "Epoch 1091/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4009 - accuracy: 0.8142 - val_loss: 0.5243 - val_accuracy: 0.7552\n",
            "Epoch 1092/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4011 - accuracy: 0.8142 - val_loss: 0.5242 - val_accuracy: 0.7552\n",
            "Epoch 1093/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4011 - accuracy: 0.8108 - val_loss: 0.5243 - val_accuracy: 0.7552\n",
            "Epoch 1094/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4012 - accuracy: 0.8108 - val_loss: 0.5245 - val_accuracy: 0.7552\n",
            "Epoch 1095/1500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.4011 - accuracy: 0.8125 - val_loss: 0.5244 - val_accuracy: 0.7552\n",
            "Epoch 1096/1500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.4011 - accuracy: 0.8108 - val_loss: 0.5243 - val_accuracy: 0.7552\n",
            "Epoch 1097/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4009 - accuracy: 0.8125 - val_loss: 0.5240 - val_accuracy: 0.7500\n",
            "Epoch 1098/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4010 - accuracy: 0.8142 - val_loss: 0.5240 - val_accuracy: 0.7552\n",
            "Epoch 1099/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4010 - accuracy: 0.8125 - val_loss: 0.5242 - val_accuracy: 0.7552\n",
            "Epoch 1100/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4010 - accuracy: 0.8125 - val_loss: 0.5241 - val_accuracy: 0.7552\n",
            "Epoch 1101/1500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.4008 - accuracy: 0.8090 - val_loss: 0.5244 - val_accuracy: 0.7552\n",
            "Epoch 1102/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4009 - accuracy: 0.8160 - val_loss: 0.5241 - val_accuracy: 0.7552\n",
            "Epoch 1103/1500\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.4009 - accuracy: 0.8108 - val_loss: 0.5245 - val_accuracy: 0.7552\n",
            "Epoch 1104/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4008 - accuracy: 0.8108 - val_loss: 0.5248 - val_accuracy: 0.7552\n",
            "Epoch 1105/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4007 - accuracy: 0.8160 - val_loss: 0.5246 - val_accuracy: 0.7552\n",
            "Epoch 1106/1500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.4010 - accuracy: 0.8125 - val_loss: 0.5247 - val_accuracy: 0.7552\n",
            "Epoch 1107/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4007 - accuracy: 0.8108 - val_loss: 0.5251 - val_accuracy: 0.7552\n",
            "Epoch 1108/1500\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.4010 - accuracy: 0.8142 - val_loss: 0.5246 - val_accuracy: 0.7552\n",
            "Epoch 1109/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4006 - accuracy: 0.8125 - val_loss: 0.5246 - val_accuracy: 0.7552\n",
            "Epoch 1110/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4005 - accuracy: 0.8125 - val_loss: 0.5249 - val_accuracy: 0.7552\n",
            "Epoch 1111/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4006 - accuracy: 0.8160 - val_loss: 0.5247 - val_accuracy: 0.7552\n",
            "Epoch 1112/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4006 - accuracy: 0.8177 - val_loss: 0.5247 - val_accuracy: 0.7552\n",
            "Epoch 1113/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4005 - accuracy: 0.8142 - val_loss: 0.5247 - val_accuracy: 0.7552\n",
            "Epoch 1114/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4004 - accuracy: 0.8108 - val_loss: 0.5251 - val_accuracy: 0.7552\n",
            "Epoch 1115/1500\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.4005 - accuracy: 0.8108 - val_loss: 0.5252 - val_accuracy: 0.7552\n",
            "Epoch 1116/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4006 - accuracy: 0.8108 - val_loss: 0.5251 - val_accuracy: 0.7552\n",
            "Epoch 1117/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4006 - accuracy: 0.8142 - val_loss: 0.5249 - val_accuracy: 0.7552\n",
            "Epoch 1118/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4006 - accuracy: 0.8090 - val_loss: 0.5252 - val_accuracy: 0.7500\n",
            "Epoch 1119/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4004 - accuracy: 0.8125 - val_loss: 0.5254 - val_accuracy: 0.7552\n",
            "Epoch 1120/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4004 - accuracy: 0.8160 - val_loss: 0.5250 - val_accuracy: 0.7552\n",
            "Epoch 1121/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4002 - accuracy: 0.8142 - val_loss: 0.5249 - val_accuracy: 0.7552\n",
            "Epoch 1122/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4006 - accuracy: 0.8142 - val_loss: 0.5251 - val_accuracy: 0.7552\n",
            "Epoch 1123/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4002 - accuracy: 0.8108 - val_loss: 0.5252 - val_accuracy: 0.7500\n",
            "Epoch 1124/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4004 - accuracy: 0.8160 - val_loss: 0.5253 - val_accuracy: 0.7552\n",
            "Epoch 1125/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4001 - accuracy: 0.8142 - val_loss: 0.5250 - val_accuracy: 0.7552\n",
            "Epoch 1126/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4003 - accuracy: 0.8160 - val_loss: 0.5249 - val_accuracy: 0.7552\n",
            "Epoch 1127/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4001 - accuracy: 0.8142 - val_loss: 0.5247 - val_accuracy: 0.7552\n",
            "Epoch 1128/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4002 - accuracy: 0.8142 - val_loss: 0.5245 - val_accuracy: 0.7552\n",
            "Epoch 1129/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4001 - accuracy: 0.8125 - val_loss: 0.5245 - val_accuracy: 0.7552\n",
            "Epoch 1130/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4000 - accuracy: 0.8125 - val_loss: 0.5247 - val_accuracy: 0.7552\n",
            "Epoch 1131/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4001 - accuracy: 0.8090 - val_loss: 0.5252 - val_accuracy: 0.7552\n",
            "Epoch 1132/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4001 - accuracy: 0.8125 - val_loss: 0.5250 - val_accuracy: 0.7552\n",
            "Epoch 1133/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4003 - accuracy: 0.8108 - val_loss: 0.5248 - val_accuracy: 0.7552\n",
            "Epoch 1134/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4001 - accuracy: 0.8090 - val_loss: 0.5248 - val_accuracy: 0.7552\n",
            "Epoch 1135/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4001 - accuracy: 0.8125 - val_loss: 0.5247 - val_accuracy: 0.7552\n",
            "Epoch 1136/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4000 - accuracy: 0.8142 - val_loss: 0.5249 - val_accuracy: 0.7552\n",
            "Epoch 1137/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3999 - accuracy: 0.8160 - val_loss: 0.5247 - val_accuracy: 0.7552\n",
            "Epoch 1138/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4001 - accuracy: 0.8125 - val_loss: 0.5249 - val_accuracy: 0.7552\n",
            "Epoch 1139/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4003 - accuracy: 0.8108 - val_loss: 0.5250 - val_accuracy: 0.7552\n",
            "Epoch 1140/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4000 - accuracy: 0.8090 - val_loss: 0.5252 - val_accuracy: 0.7552\n",
            "Epoch 1141/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3999 - accuracy: 0.8125 - val_loss: 0.5250 - val_accuracy: 0.7500\n",
            "Epoch 1142/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3998 - accuracy: 0.8142 - val_loss: 0.5252 - val_accuracy: 0.7448\n",
            "Epoch 1143/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4000 - accuracy: 0.8160 - val_loss: 0.5248 - val_accuracy: 0.7552\n",
            "Epoch 1144/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4001 - accuracy: 0.8142 - val_loss: 0.5245 - val_accuracy: 0.7552\n",
            "Epoch 1145/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3999 - accuracy: 0.8160 - val_loss: 0.5244 - val_accuracy: 0.7552\n",
            "Epoch 1146/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3998 - accuracy: 0.8108 - val_loss: 0.5244 - val_accuracy: 0.7500\n",
            "Epoch 1147/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3999 - accuracy: 0.8108 - val_loss: 0.5250 - val_accuracy: 0.7500\n",
            "Epoch 1148/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3998 - accuracy: 0.8108 - val_loss: 0.5252 - val_accuracy: 0.7500\n",
            "Epoch 1149/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3994 - accuracy: 0.8142 - val_loss: 0.5250 - val_accuracy: 0.7500\n",
            "Epoch 1150/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3996 - accuracy: 0.8108 - val_loss: 0.5256 - val_accuracy: 0.7500\n",
            "Epoch 1151/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4000 - accuracy: 0.8108 - val_loss: 0.5254 - val_accuracy: 0.7500\n",
            "Epoch 1152/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3996 - accuracy: 0.8160 - val_loss: 0.5256 - val_accuracy: 0.7500\n",
            "Epoch 1153/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3995 - accuracy: 0.8142 - val_loss: 0.5253 - val_accuracy: 0.7500\n",
            "Epoch 1154/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3994 - accuracy: 0.8160 - val_loss: 0.5254 - val_accuracy: 0.7500\n",
            "Epoch 1155/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3998 - accuracy: 0.8194 - val_loss: 0.5250 - val_accuracy: 0.7500\n",
            "Epoch 1156/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3998 - accuracy: 0.8142 - val_loss: 0.5250 - val_accuracy: 0.7500\n",
            "Epoch 1157/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3997 - accuracy: 0.8108 - val_loss: 0.5250 - val_accuracy: 0.7500\n",
            "Epoch 1158/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3996 - accuracy: 0.8108 - val_loss: 0.5249 - val_accuracy: 0.7500\n",
            "Epoch 1159/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3996 - accuracy: 0.8125 - val_loss: 0.5251 - val_accuracy: 0.7500\n",
            "Epoch 1160/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3993 - accuracy: 0.8125 - val_loss: 0.5251 - val_accuracy: 0.7500\n",
            "Epoch 1161/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3993 - accuracy: 0.8125 - val_loss: 0.5255 - val_accuracy: 0.7500\n",
            "Epoch 1162/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3993 - accuracy: 0.8142 - val_loss: 0.5253 - val_accuracy: 0.7448\n",
            "Epoch 1163/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3995 - accuracy: 0.8125 - val_loss: 0.5254 - val_accuracy: 0.7500\n",
            "Epoch 1164/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3993 - accuracy: 0.8108 - val_loss: 0.5255 - val_accuracy: 0.7500\n",
            "Epoch 1165/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3995 - accuracy: 0.8108 - val_loss: 0.5256 - val_accuracy: 0.7500\n",
            "Epoch 1166/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3992 - accuracy: 0.8108 - val_loss: 0.5258 - val_accuracy: 0.7500\n",
            "Epoch 1167/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3993 - accuracy: 0.8125 - val_loss: 0.5255 - val_accuracy: 0.7500\n",
            "Epoch 1168/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3994 - accuracy: 0.8108 - val_loss: 0.5251 - val_accuracy: 0.7500\n",
            "Epoch 1169/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3992 - accuracy: 0.8108 - val_loss: 0.5250 - val_accuracy: 0.7500\n",
            "Epoch 1170/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3993 - accuracy: 0.8142 - val_loss: 0.5248 - val_accuracy: 0.7500\n",
            "Epoch 1171/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3993 - accuracy: 0.8142 - val_loss: 0.5249 - val_accuracy: 0.7500\n",
            "Epoch 1172/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3990 - accuracy: 0.8142 - val_loss: 0.5250 - val_accuracy: 0.7500\n",
            "Epoch 1173/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3993 - accuracy: 0.8125 - val_loss: 0.5246 - val_accuracy: 0.7500\n",
            "Epoch 1174/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3994 - accuracy: 0.8142 - val_loss: 0.5244 - val_accuracy: 0.7448\n",
            "Epoch 1175/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3988 - accuracy: 0.8125 - val_loss: 0.5246 - val_accuracy: 0.7448\n",
            "Epoch 1176/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3989 - accuracy: 0.8125 - val_loss: 0.5252 - val_accuracy: 0.7500\n",
            "Epoch 1177/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3992 - accuracy: 0.8125 - val_loss: 0.5249 - val_accuracy: 0.7500\n",
            "Epoch 1178/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3990 - accuracy: 0.8142 - val_loss: 0.5251 - val_accuracy: 0.7500\n",
            "Epoch 1179/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3989 - accuracy: 0.8108 - val_loss: 0.5250 - val_accuracy: 0.7448\n",
            "Epoch 1180/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3991 - accuracy: 0.8125 - val_loss: 0.5255 - val_accuracy: 0.7500\n",
            "Epoch 1181/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3991 - accuracy: 0.8125 - val_loss: 0.5255 - val_accuracy: 0.7500\n",
            "Epoch 1182/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3990 - accuracy: 0.8073 - val_loss: 0.5257 - val_accuracy: 0.7500\n",
            "Epoch 1183/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3989 - accuracy: 0.8125 - val_loss: 0.5253 - val_accuracy: 0.7500\n",
            "Epoch 1184/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3990 - accuracy: 0.8125 - val_loss: 0.5252 - val_accuracy: 0.7500\n",
            "Epoch 1185/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3990 - accuracy: 0.8125 - val_loss: 0.5251 - val_accuracy: 0.7500\n",
            "Epoch 1186/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3989 - accuracy: 0.8125 - val_loss: 0.5247 - val_accuracy: 0.7500\n",
            "Epoch 1187/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3988 - accuracy: 0.8125 - val_loss: 0.5249 - val_accuracy: 0.7500\n",
            "Epoch 1188/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3987 - accuracy: 0.8142 - val_loss: 0.5249 - val_accuracy: 0.7500\n",
            "Epoch 1189/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3988 - accuracy: 0.8090 - val_loss: 0.5250 - val_accuracy: 0.7500\n",
            "Epoch 1190/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3985 - accuracy: 0.8142 - val_loss: 0.5248 - val_accuracy: 0.7500\n",
            "Epoch 1191/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3987 - accuracy: 0.8090 - val_loss: 0.5246 - val_accuracy: 0.7500\n",
            "Epoch 1192/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3987 - accuracy: 0.8160 - val_loss: 0.5243 - val_accuracy: 0.7500\n",
            "Epoch 1193/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3989 - accuracy: 0.8108 - val_loss: 0.5243 - val_accuracy: 0.7500\n",
            "Epoch 1194/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3987 - accuracy: 0.8108 - val_loss: 0.5245 - val_accuracy: 0.7500\n",
            "Epoch 1195/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3984 - accuracy: 0.8125 - val_loss: 0.5250 - val_accuracy: 0.7500\n",
            "Epoch 1196/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3985 - accuracy: 0.8108 - val_loss: 0.5249 - val_accuracy: 0.7500\n",
            "Epoch 1197/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3986 - accuracy: 0.8108 - val_loss: 0.5245 - val_accuracy: 0.7500\n",
            "Epoch 1198/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3986 - accuracy: 0.8142 - val_loss: 0.5241 - val_accuracy: 0.7500\n",
            "Epoch 1199/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3985 - accuracy: 0.8090 - val_loss: 0.5240 - val_accuracy: 0.7500\n",
            "Epoch 1200/1500\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.3989 - accuracy: 0.8090 - val_loss: 0.5244 - val_accuracy: 0.7500\n",
            "Epoch 1201/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3983 - accuracy: 0.8108 - val_loss: 0.5250 - val_accuracy: 0.7500\n",
            "Epoch 1202/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3983 - accuracy: 0.8108 - val_loss: 0.5249 - val_accuracy: 0.7500\n",
            "Epoch 1203/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3984 - accuracy: 0.8125 - val_loss: 0.5255 - val_accuracy: 0.7500\n",
            "Epoch 1204/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3981 - accuracy: 0.8125 - val_loss: 0.5254 - val_accuracy: 0.7500\n",
            "Epoch 1205/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3985 - accuracy: 0.8125 - val_loss: 0.5255 - val_accuracy: 0.7500\n",
            "Epoch 1206/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.3982 - accuracy: 0.8142 - val_loss: 0.5255 - val_accuracy: 0.7500\n",
            "Epoch 1207/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.3983 - accuracy: 0.8125 - val_loss: 0.5254 - val_accuracy: 0.7500\n",
            "Epoch 1208/1500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.3985 - accuracy: 0.8125 - val_loss: 0.5250 - val_accuracy: 0.7500\n",
            "Epoch 1209/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3983 - accuracy: 0.8142 - val_loss: 0.5252 - val_accuracy: 0.7500\n",
            "Epoch 1210/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3982 - accuracy: 0.8125 - val_loss: 0.5249 - val_accuracy: 0.7500\n",
            "Epoch 1211/1500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.3981 - accuracy: 0.8142 - val_loss: 0.5250 - val_accuracy: 0.7500\n",
            "Epoch 1212/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3984 - accuracy: 0.8108 - val_loss: 0.5251 - val_accuracy: 0.7500\n",
            "Epoch 1213/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.3982 - accuracy: 0.8108 - val_loss: 0.5251 - val_accuracy: 0.7500\n",
            "Epoch 1214/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.3982 - accuracy: 0.8125 - val_loss: 0.5246 - val_accuracy: 0.7500\n",
            "Epoch 1215/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3978 - accuracy: 0.8108 - val_loss: 0.5254 - val_accuracy: 0.7500\n",
            "Epoch 1216/1500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.3980 - accuracy: 0.8160 - val_loss: 0.5246 - val_accuracy: 0.7500\n",
            "Epoch 1217/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3982 - accuracy: 0.8090 - val_loss: 0.5255 - val_accuracy: 0.7500\n",
            "Epoch 1218/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.3979 - accuracy: 0.8142 - val_loss: 0.5255 - val_accuracy: 0.7500\n",
            "Epoch 1219/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3982 - accuracy: 0.8125 - val_loss: 0.5255 - val_accuracy: 0.7500\n",
            "Epoch 1220/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3982 - accuracy: 0.8090 - val_loss: 0.5252 - val_accuracy: 0.7500\n",
            "Epoch 1221/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3977 - accuracy: 0.8108 - val_loss: 0.5248 - val_accuracy: 0.7500\n",
            "Epoch 1222/1500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.3980 - accuracy: 0.8125 - val_loss: 0.5248 - val_accuracy: 0.7500\n",
            "Epoch 1223/1500\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.3980 - accuracy: 0.8108 - val_loss: 0.5246 - val_accuracy: 0.7552\n",
            "Epoch 1224/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3980 - accuracy: 0.8125 - val_loss: 0.5246 - val_accuracy: 0.7500\n",
            "Epoch 1225/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3978 - accuracy: 0.8108 - val_loss: 0.5250 - val_accuracy: 0.7500\n",
            "Epoch 1226/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3977 - accuracy: 0.8125 - val_loss: 0.5253 - val_accuracy: 0.7500\n",
            "Epoch 1227/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3978 - accuracy: 0.8090 - val_loss: 0.5256 - val_accuracy: 0.7500\n",
            "Epoch 1228/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3977 - accuracy: 0.8108 - val_loss: 0.5257 - val_accuracy: 0.7500\n",
            "Epoch 1229/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3978 - accuracy: 0.8108 - val_loss: 0.5253 - val_accuracy: 0.7500\n",
            "Epoch 1230/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3975 - accuracy: 0.8142 - val_loss: 0.5254 - val_accuracy: 0.7500\n",
            "Epoch 1231/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3975 - accuracy: 0.8125 - val_loss: 0.5253 - val_accuracy: 0.7500\n",
            "Epoch 1232/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3975 - accuracy: 0.8125 - val_loss: 0.5252 - val_accuracy: 0.7500\n",
            "Epoch 1233/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3975 - accuracy: 0.8142 - val_loss: 0.5258 - val_accuracy: 0.7500\n",
            "Epoch 1234/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3976 - accuracy: 0.8125 - val_loss: 0.5259 - val_accuracy: 0.7500\n",
            "Epoch 1235/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3976 - accuracy: 0.8125 - val_loss: 0.5258 - val_accuracy: 0.7500\n",
            "Epoch 1236/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3975 - accuracy: 0.8142 - val_loss: 0.5253 - val_accuracy: 0.7500\n",
            "Epoch 1237/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3979 - accuracy: 0.8125 - val_loss: 0.5251 - val_accuracy: 0.7552\n",
            "Epoch 1238/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3975 - accuracy: 0.8125 - val_loss: 0.5251 - val_accuracy: 0.7552\n",
            "Epoch 1239/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3975 - accuracy: 0.8125 - val_loss: 0.5254 - val_accuracy: 0.7500\n",
            "Epoch 1240/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3973 - accuracy: 0.8125 - val_loss: 0.5255 - val_accuracy: 0.7500\n",
            "Epoch 1241/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3974 - accuracy: 0.8108 - val_loss: 0.5255 - val_accuracy: 0.7500\n",
            "Epoch 1242/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3974 - accuracy: 0.8142 - val_loss: 0.5259 - val_accuracy: 0.7500\n",
            "Epoch 1243/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3974 - accuracy: 0.8142 - val_loss: 0.5259 - val_accuracy: 0.7500\n",
            "Epoch 1244/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3976 - accuracy: 0.8125 - val_loss: 0.5262 - val_accuracy: 0.7500\n",
            "Epoch 1245/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3974 - accuracy: 0.8142 - val_loss: 0.5266 - val_accuracy: 0.7500\n",
            "Epoch 1246/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3974 - accuracy: 0.8142 - val_loss: 0.5265 - val_accuracy: 0.7500\n",
            "Epoch 1247/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3974 - accuracy: 0.8108 - val_loss: 0.5268 - val_accuracy: 0.7500\n",
            "Epoch 1248/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3975 - accuracy: 0.8125 - val_loss: 0.5266 - val_accuracy: 0.7500\n",
            "Epoch 1249/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3970 - accuracy: 0.8125 - val_loss: 0.5266 - val_accuracy: 0.7500\n",
            "Epoch 1250/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3969 - accuracy: 0.8108 - val_loss: 0.5264 - val_accuracy: 0.7500\n",
            "Epoch 1251/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3972 - accuracy: 0.8090 - val_loss: 0.5261 - val_accuracy: 0.7500\n",
            "Epoch 1252/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3972 - accuracy: 0.8125 - val_loss: 0.5263 - val_accuracy: 0.7500\n",
            "Epoch 1253/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3972 - accuracy: 0.8142 - val_loss: 0.5264 - val_accuracy: 0.7500\n",
            "Epoch 1254/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3971 - accuracy: 0.8142 - val_loss: 0.5267 - val_accuracy: 0.7500\n",
            "Epoch 1255/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3971 - accuracy: 0.8125 - val_loss: 0.5270 - val_accuracy: 0.7500\n",
            "Epoch 1256/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3972 - accuracy: 0.8125 - val_loss: 0.5264 - val_accuracy: 0.7500\n",
            "Epoch 1257/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3969 - accuracy: 0.8125 - val_loss: 0.5263 - val_accuracy: 0.7500\n",
            "Epoch 1258/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3969 - accuracy: 0.8125 - val_loss: 0.5266 - val_accuracy: 0.7500\n",
            "Epoch 1259/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3970 - accuracy: 0.8125 - val_loss: 0.5270 - val_accuracy: 0.7500\n",
            "Epoch 1260/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3971 - accuracy: 0.8142 - val_loss: 0.5268 - val_accuracy: 0.7500\n",
            "Epoch 1261/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3972 - accuracy: 0.8108 - val_loss: 0.5271 - val_accuracy: 0.7500\n",
            "Epoch 1262/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3968 - accuracy: 0.8125 - val_loss: 0.5271 - val_accuracy: 0.7500\n",
            "Epoch 1263/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3969 - accuracy: 0.8142 - val_loss: 0.5269 - val_accuracy: 0.7500\n",
            "Epoch 1264/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3967 - accuracy: 0.8125 - val_loss: 0.5265 - val_accuracy: 0.7500\n",
            "Epoch 1265/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3967 - accuracy: 0.8142 - val_loss: 0.5266 - val_accuracy: 0.7500\n",
            "Epoch 1266/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3971 - accuracy: 0.8142 - val_loss: 0.5270 - val_accuracy: 0.7500\n",
            "Epoch 1267/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3968 - accuracy: 0.8142 - val_loss: 0.5269 - val_accuracy: 0.7500\n",
            "Epoch 1268/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3969 - accuracy: 0.8160 - val_loss: 0.5265 - val_accuracy: 0.7500\n",
            "Epoch 1269/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3967 - accuracy: 0.8142 - val_loss: 0.5266 - val_accuracy: 0.7500\n",
            "Epoch 1270/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3971 - accuracy: 0.8160 - val_loss: 0.5264 - val_accuracy: 0.7552\n",
            "Epoch 1271/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3969 - accuracy: 0.8142 - val_loss: 0.5266 - val_accuracy: 0.7500\n",
            "Epoch 1272/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3968 - accuracy: 0.8125 - val_loss: 0.5270 - val_accuracy: 0.7500\n",
            "Epoch 1273/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3971 - accuracy: 0.8142 - val_loss: 0.5274 - val_accuracy: 0.7500\n",
            "Epoch 1274/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3968 - accuracy: 0.8160 - val_loss: 0.5270 - val_accuracy: 0.7500\n",
            "Epoch 1275/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3967 - accuracy: 0.8125 - val_loss: 0.5270 - val_accuracy: 0.7500\n",
            "Epoch 1276/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3966 - accuracy: 0.8160 - val_loss: 0.5271 - val_accuracy: 0.7500\n",
            "Epoch 1277/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3966 - accuracy: 0.8125 - val_loss: 0.5279 - val_accuracy: 0.7500\n",
            "Epoch 1278/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3966 - accuracy: 0.8177 - val_loss: 0.5274 - val_accuracy: 0.7500\n",
            "Epoch 1279/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3970 - accuracy: 0.8108 - val_loss: 0.5271 - val_accuracy: 0.7552\n",
            "Epoch 1280/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3969 - accuracy: 0.8177 - val_loss: 0.5273 - val_accuracy: 0.7500\n",
            "Epoch 1281/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3967 - accuracy: 0.8142 - val_loss: 0.5266 - val_accuracy: 0.7604\n",
            "Epoch 1282/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3967 - accuracy: 0.8142 - val_loss: 0.5267 - val_accuracy: 0.7604\n",
            "Epoch 1283/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3965 - accuracy: 0.8160 - val_loss: 0.5275 - val_accuracy: 0.7500\n",
            "Epoch 1284/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3966 - accuracy: 0.8142 - val_loss: 0.5270 - val_accuracy: 0.7552\n",
            "Epoch 1285/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3967 - accuracy: 0.8142 - val_loss: 0.5275 - val_accuracy: 0.7500\n",
            "Epoch 1286/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3966 - accuracy: 0.8125 - val_loss: 0.5276 - val_accuracy: 0.7500\n",
            "Epoch 1287/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3965 - accuracy: 0.8160 - val_loss: 0.5274 - val_accuracy: 0.7500\n",
            "Epoch 1288/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3963 - accuracy: 0.8125 - val_loss: 0.5275 - val_accuracy: 0.7552\n",
            "Epoch 1289/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3966 - accuracy: 0.8142 - val_loss: 0.5280 - val_accuracy: 0.7552\n",
            "Epoch 1290/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3965 - accuracy: 0.8160 - val_loss: 0.5280 - val_accuracy: 0.7552\n",
            "Epoch 1291/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3963 - accuracy: 0.8160 - val_loss: 0.5275 - val_accuracy: 0.7552\n",
            "Epoch 1292/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3964 - accuracy: 0.8142 - val_loss: 0.5281 - val_accuracy: 0.7552\n",
            "Epoch 1293/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3961 - accuracy: 0.8142 - val_loss: 0.5280 - val_accuracy: 0.7500\n",
            "Epoch 1294/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3964 - accuracy: 0.8125 - val_loss: 0.5283 - val_accuracy: 0.7500\n",
            "Epoch 1295/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3962 - accuracy: 0.8142 - val_loss: 0.5287 - val_accuracy: 0.7448\n",
            "Epoch 1296/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3961 - accuracy: 0.8125 - val_loss: 0.5281 - val_accuracy: 0.7552\n",
            "Epoch 1297/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3963 - accuracy: 0.8142 - val_loss: 0.5281 - val_accuracy: 0.7500\n",
            "Epoch 1298/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3960 - accuracy: 0.8142 - val_loss: 0.5280 - val_accuracy: 0.7500\n",
            "Epoch 1299/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3965 - accuracy: 0.8160 - val_loss: 0.5278 - val_accuracy: 0.7500\n",
            "Epoch 1300/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3960 - accuracy: 0.8194 - val_loss: 0.5277 - val_accuracy: 0.7552\n",
            "Epoch 1301/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3966 - accuracy: 0.8160 - val_loss: 0.5279 - val_accuracy: 0.7552\n",
            "Epoch 1302/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3960 - accuracy: 0.8160 - val_loss: 0.5280 - val_accuracy: 0.7552\n",
            "Epoch 1303/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3961 - accuracy: 0.8142 - val_loss: 0.5283 - val_accuracy: 0.7552\n",
            "Epoch 1304/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3961 - accuracy: 0.8125 - val_loss: 0.5282 - val_accuracy: 0.7500\n",
            "Epoch 1305/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3964 - accuracy: 0.8142 - val_loss: 0.5280 - val_accuracy: 0.7448\n",
            "Epoch 1306/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3961 - accuracy: 0.8142 - val_loss: 0.5274 - val_accuracy: 0.7604\n",
            "Epoch 1307/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3962 - accuracy: 0.8142 - val_loss: 0.5276 - val_accuracy: 0.7604\n",
            "Epoch 1308/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3962 - accuracy: 0.8125 - val_loss: 0.5274 - val_accuracy: 0.7604\n",
            "Epoch 1309/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3960 - accuracy: 0.8142 - val_loss: 0.5279 - val_accuracy: 0.7552\n",
            "Epoch 1310/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3966 - accuracy: 0.8125 - val_loss: 0.5278 - val_accuracy: 0.7604\n",
            "Epoch 1311/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3962 - accuracy: 0.8142 - val_loss: 0.5283 - val_accuracy: 0.7500\n",
            "Epoch 1312/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3964 - accuracy: 0.8142 - val_loss: 0.5285 - val_accuracy: 0.7500\n",
            "Epoch 1313/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3960 - accuracy: 0.8142 - val_loss: 0.5283 - val_accuracy: 0.7500\n",
            "Epoch 1314/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3960 - accuracy: 0.8142 - val_loss: 0.5289 - val_accuracy: 0.7500\n",
            "Epoch 1315/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3959 - accuracy: 0.8142 - val_loss: 0.5287 - val_accuracy: 0.7500\n",
            "Epoch 1316/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3961 - accuracy: 0.8160 - val_loss: 0.5287 - val_accuracy: 0.7500\n",
            "Epoch 1317/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3959 - accuracy: 0.8177 - val_loss: 0.5289 - val_accuracy: 0.7500\n",
            "Epoch 1318/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3961 - accuracy: 0.8142 - val_loss: 0.5292 - val_accuracy: 0.7500\n",
            "Epoch 1319/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3957 - accuracy: 0.8142 - val_loss: 0.5291 - val_accuracy: 0.7500\n",
            "Epoch 1320/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3958 - accuracy: 0.8142 - val_loss: 0.5290 - val_accuracy: 0.7500\n",
            "Epoch 1321/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3958 - accuracy: 0.8177 - val_loss: 0.5295 - val_accuracy: 0.7500\n",
            "Epoch 1322/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3957 - accuracy: 0.8125 - val_loss: 0.5295 - val_accuracy: 0.7500\n",
            "Epoch 1323/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3960 - accuracy: 0.8160 - val_loss: 0.5291 - val_accuracy: 0.7500\n",
            "Epoch 1324/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3959 - accuracy: 0.8142 - val_loss: 0.5291 - val_accuracy: 0.7500\n",
            "Epoch 1325/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3958 - accuracy: 0.8160 - val_loss: 0.5290 - val_accuracy: 0.7500\n",
            "Epoch 1326/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3956 - accuracy: 0.8142 - val_loss: 0.5291 - val_accuracy: 0.7500\n",
            "Epoch 1327/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3958 - accuracy: 0.8108 - val_loss: 0.5293 - val_accuracy: 0.7500\n",
            "Epoch 1328/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3958 - accuracy: 0.8142 - val_loss: 0.5290 - val_accuracy: 0.7500\n",
            "Epoch 1329/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.3958 - accuracy: 0.8125 - val_loss: 0.5291 - val_accuracy: 0.7500\n",
            "Epoch 1330/1500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.3959 - accuracy: 0.8177 - val_loss: 0.5299 - val_accuracy: 0.7500\n",
            "Epoch 1331/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3959 - accuracy: 0.8160 - val_loss: 0.5291 - val_accuracy: 0.7500\n",
            "Epoch 1332/1500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.3958 - accuracy: 0.8142 - val_loss: 0.5289 - val_accuracy: 0.7500\n",
            "Epoch 1333/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.3959 - accuracy: 0.8142 - val_loss: 0.5291 - val_accuracy: 0.7552\n",
            "Epoch 1334/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.3957 - accuracy: 0.8142 - val_loss: 0.5296 - val_accuracy: 0.7500\n",
            "Epoch 1335/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3960 - accuracy: 0.8160 - val_loss: 0.5291 - val_accuracy: 0.7500\n",
            "Epoch 1336/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3955 - accuracy: 0.8160 - val_loss: 0.5284 - val_accuracy: 0.7604\n",
            "Epoch 1337/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.3959 - accuracy: 0.8125 - val_loss: 0.5290 - val_accuracy: 0.7500\n",
            "Epoch 1338/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3955 - accuracy: 0.8160 - val_loss: 0.5286 - val_accuracy: 0.7604\n",
            "Epoch 1339/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3958 - accuracy: 0.8142 - val_loss: 0.5288 - val_accuracy: 0.7552\n",
            "Epoch 1340/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3955 - accuracy: 0.8177 - val_loss: 0.5294 - val_accuracy: 0.7552\n",
            "Epoch 1341/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3956 - accuracy: 0.8160 - val_loss: 0.5297 - val_accuracy: 0.7500\n",
            "Epoch 1342/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3957 - accuracy: 0.8142 - val_loss: 0.5296 - val_accuracy: 0.7500\n",
            "Epoch 1343/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3956 - accuracy: 0.8142 - val_loss: 0.5294 - val_accuracy: 0.7500\n",
            "Epoch 1344/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3957 - accuracy: 0.8160 - val_loss: 0.5294 - val_accuracy: 0.7500\n",
            "Epoch 1345/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3955 - accuracy: 0.8142 - val_loss: 0.5297 - val_accuracy: 0.7500\n",
            "Epoch 1346/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3955 - accuracy: 0.8125 - val_loss: 0.5297 - val_accuracy: 0.7500\n",
            "Epoch 1347/1500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.3957 - accuracy: 0.8125 - val_loss: 0.5294 - val_accuracy: 0.7500\n",
            "Epoch 1348/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3955 - accuracy: 0.8125 - val_loss: 0.5289 - val_accuracy: 0.7552\n",
            "Epoch 1349/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3956 - accuracy: 0.8160 - val_loss: 0.5288 - val_accuracy: 0.7552\n",
            "Epoch 1350/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3952 - accuracy: 0.8177 - val_loss: 0.5290 - val_accuracy: 0.7500\n",
            "Epoch 1351/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3956 - accuracy: 0.8125 - val_loss: 0.5296 - val_accuracy: 0.7500\n",
            "Epoch 1352/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3955 - accuracy: 0.8160 - val_loss: 0.5292 - val_accuracy: 0.7500\n",
            "Epoch 1353/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.3956 - accuracy: 0.8177 - val_loss: 0.5297 - val_accuracy: 0.7500\n",
            "Epoch 1354/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.3956 - accuracy: 0.8160 - val_loss: 0.5299 - val_accuracy: 0.7500\n",
            "Epoch 1355/1500\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.3956 - accuracy: 0.8160 - val_loss: 0.5296 - val_accuracy: 0.7500\n",
            "Epoch 1356/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3954 - accuracy: 0.8142 - val_loss: 0.5293 - val_accuracy: 0.7448\n",
            "Epoch 1357/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3953 - accuracy: 0.8177 - val_loss: 0.5295 - val_accuracy: 0.7500\n",
            "Epoch 1358/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3955 - accuracy: 0.8160 - val_loss: 0.5297 - val_accuracy: 0.7500\n",
            "Epoch 1359/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3953 - accuracy: 0.8160 - val_loss: 0.5293 - val_accuracy: 0.7448\n",
            "Epoch 1360/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3952 - accuracy: 0.8142 - val_loss: 0.5295 - val_accuracy: 0.7448\n",
            "Epoch 1361/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3952 - accuracy: 0.8142 - val_loss: 0.5302 - val_accuracy: 0.7500\n",
            "Epoch 1362/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3955 - accuracy: 0.8160 - val_loss: 0.5301 - val_accuracy: 0.7500\n",
            "Epoch 1363/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3955 - accuracy: 0.8160 - val_loss: 0.5306 - val_accuracy: 0.7500\n",
            "Epoch 1364/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3951 - accuracy: 0.8142 - val_loss: 0.5303 - val_accuracy: 0.7500\n",
            "Epoch 1365/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3957 - accuracy: 0.8160 - val_loss: 0.5302 - val_accuracy: 0.7500\n",
            "Epoch 1366/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3953 - accuracy: 0.8160 - val_loss: 0.5303 - val_accuracy: 0.7500\n",
            "Epoch 1367/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3954 - accuracy: 0.8160 - val_loss: 0.5298 - val_accuracy: 0.7500\n",
            "Epoch 1368/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3949 - accuracy: 0.8194 - val_loss: 0.5303 - val_accuracy: 0.7500\n",
            "Epoch 1369/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3953 - accuracy: 0.8142 - val_loss: 0.5304 - val_accuracy: 0.7500\n",
            "Epoch 1370/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3951 - accuracy: 0.8125 - val_loss: 0.5297 - val_accuracy: 0.7396\n",
            "Epoch 1371/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3953 - accuracy: 0.8160 - val_loss: 0.5305 - val_accuracy: 0.7500\n",
            "Epoch 1372/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3954 - accuracy: 0.8177 - val_loss: 0.5308 - val_accuracy: 0.7500\n",
            "Epoch 1373/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3952 - accuracy: 0.8160 - val_loss: 0.5309 - val_accuracy: 0.7500\n",
            "Epoch 1374/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3952 - accuracy: 0.8125 - val_loss: 0.5304 - val_accuracy: 0.7500\n",
            "Epoch 1375/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3949 - accuracy: 0.8142 - val_loss: 0.5300 - val_accuracy: 0.7396\n",
            "Epoch 1376/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3953 - accuracy: 0.8160 - val_loss: 0.5302 - val_accuracy: 0.7448\n",
            "Epoch 1377/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3950 - accuracy: 0.8142 - val_loss: 0.5308 - val_accuracy: 0.7500\n",
            "Epoch 1378/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3955 - accuracy: 0.8125 - val_loss: 0.5306 - val_accuracy: 0.7396\n",
            "Epoch 1379/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3952 - accuracy: 0.8160 - val_loss: 0.5301 - val_accuracy: 0.7396\n",
            "Epoch 1380/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3952 - accuracy: 0.8125 - val_loss: 0.5305 - val_accuracy: 0.7448\n",
            "Epoch 1381/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3952 - accuracy: 0.8177 - val_loss: 0.5306 - val_accuracy: 0.7448\n",
            "Epoch 1382/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3951 - accuracy: 0.8177 - val_loss: 0.5302 - val_accuracy: 0.7448\n",
            "Epoch 1383/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3953 - accuracy: 0.8160 - val_loss: 0.5299 - val_accuracy: 0.7448\n",
            "Epoch 1384/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3954 - accuracy: 0.8160 - val_loss: 0.5304 - val_accuracy: 0.7396\n",
            "Epoch 1385/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3952 - accuracy: 0.8160 - val_loss: 0.5307 - val_accuracy: 0.7500\n",
            "Epoch 1386/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3952 - accuracy: 0.8125 - val_loss: 0.5301 - val_accuracy: 0.7396\n",
            "Epoch 1387/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3949 - accuracy: 0.8160 - val_loss: 0.5303 - val_accuracy: 0.7500\n",
            "Epoch 1388/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3952 - accuracy: 0.8125 - val_loss: 0.5300 - val_accuracy: 0.7552\n",
            "Epoch 1389/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3950 - accuracy: 0.8177 - val_loss: 0.5303 - val_accuracy: 0.7552\n",
            "Epoch 1390/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3952 - accuracy: 0.8160 - val_loss: 0.5306 - val_accuracy: 0.7500\n",
            "Epoch 1391/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3953 - accuracy: 0.8160 - val_loss: 0.5312 - val_accuracy: 0.7500\n",
            "Epoch 1392/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3948 - accuracy: 0.8160 - val_loss: 0.5305 - val_accuracy: 0.7500\n",
            "Epoch 1393/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3953 - accuracy: 0.8108 - val_loss: 0.5302 - val_accuracy: 0.7448\n",
            "Epoch 1394/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3950 - accuracy: 0.8108 - val_loss: 0.5307 - val_accuracy: 0.7396\n",
            "Epoch 1395/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3948 - accuracy: 0.8194 - val_loss: 0.5307 - val_accuracy: 0.7500\n",
            "Epoch 1396/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3951 - accuracy: 0.8125 - val_loss: 0.5310 - val_accuracy: 0.7448\n",
            "Epoch 1397/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3947 - accuracy: 0.8160 - val_loss: 0.5314 - val_accuracy: 0.7500\n",
            "Epoch 1398/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3949 - accuracy: 0.8142 - val_loss: 0.5309 - val_accuracy: 0.7448\n",
            "Epoch 1399/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3947 - accuracy: 0.8125 - val_loss: 0.5312 - val_accuracy: 0.7448\n",
            "Epoch 1400/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3951 - accuracy: 0.8142 - val_loss: 0.5308 - val_accuracy: 0.7396\n",
            "Epoch 1401/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3948 - accuracy: 0.8160 - val_loss: 0.5312 - val_accuracy: 0.7448\n",
            "Epoch 1402/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3950 - accuracy: 0.8142 - val_loss: 0.5308 - val_accuracy: 0.7500\n",
            "Epoch 1403/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3949 - accuracy: 0.8142 - val_loss: 0.5312 - val_accuracy: 0.7448\n",
            "Epoch 1404/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3949 - accuracy: 0.8108 - val_loss: 0.5312 - val_accuracy: 0.7448\n",
            "Epoch 1405/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3946 - accuracy: 0.8160 - val_loss: 0.5311 - val_accuracy: 0.7500\n",
            "Epoch 1406/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3947 - accuracy: 0.8142 - val_loss: 0.5310 - val_accuracy: 0.7448\n",
            "Epoch 1407/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3947 - accuracy: 0.8142 - val_loss: 0.5305 - val_accuracy: 0.7448\n",
            "Epoch 1408/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3946 - accuracy: 0.8125 - val_loss: 0.5306 - val_accuracy: 0.7396\n",
            "Epoch 1409/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3946 - accuracy: 0.8177 - val_loss: 0.5305 - val_accuracy: 0.7448\n",
            "Epoch 1410/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3950 - accuracy: 0.8142 - val_loss: 0.5310 - val_accuracy: 0.7448\n",
            "Epoch 1411/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3947 - accuracy: 0.8177 - val_loss: 0.5308 - val_accuracy: 0.7500\n",
            "Epoch 1412/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3948 - accuracy: 0.8160 - val_loss: 0.5318 - val_accuracy: 0.7448\n",
            "Epoch 1413/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3947 - accuracy: 0.8160 - val_loss: 0.5313 - val_accuracy: 0.7448\n",
            "Epoch 1414/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3944 - accuracy: 0.8125 - val_loss: 0.5312 - val_accuracy: 0.7448\n",
            "Epoch 1415/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3947 - accuracy: 0.8177 - val_loss: 0.5311 - val_accuracy: 0.7396\n",
            "Epoch 1416/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3944 - accuracy: 0.8142 - val_loss: 0.5314 - val_accuracy: 0.7448\n",
            "Epoch 1417/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3949 - accuracy: 0.8142 - val_loss: 0.5312 - val_accuracy: 0.7396\n",
            "Epoch 1418/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3945 - accuracy: 0.8142 - val_loss: 0.5316 - val_accuracy: 0.7448\n",
            "Epoch 1419/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3947 - accuracy: 0.8160 - val_loss: 0.5309 - val_accuracy: 0.7448\n",
            "Epoch 1420/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3948 - accuracy: 0.8125 - val_loss: 0.5313 - val_accuracy: 0.7448\n",
            "Epoch 1421/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3945 - accuracy: 0.8125 - val_loss: 0.5318 - val_accuracy: 0.7396\n",
            "Epoch 1422/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3945 - accuracy: 0.8125 - val_loss: 0.5311 - val_accuracy: 0.7396\n",
            "Epoch 1423/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3945 - accuracy: 0.8160 - val_loss: 0.5312 - val_accuracy: 0.7448\n",
            "Epoch 1424/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3945 - accuracy: 0.8142 - val_loss: 0.5316 - val_accuracy: 0.7448\n",
            "Epoch 1425/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3945 - accuracy: 0.8142 - val_loss: 0.5313 - val_accuracy: 0.7448\n",
            "Epoch 1426/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3947 - accuracy: 0.8142 - val_loss: 0.5313 - val_accuracy: 0.7500\n",
            "Epoch 1427/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3944 - accuracy: 0.8142 - val_loss: 0.5314 - val_accuracy: 0.7448\n",
            "Epoch 1428/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3943 - accuracy: 0.8108 - val_loss: 0.5316 - val_accuracy: 0.7500\n",
            "Epoch 1429/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3942 - accuracy: 0.8177 - val_loss: 0.5314 - val_accuracy: 0.7500\n",
            "Epoch 1430/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3945 - accuracy: 0.8125 - val_loss: 0.5312 - val_accuracy: 0.7448\n",
            "Epoch 1431/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3943 - accuracy: 0.8142 - val_loss: 0.5316 - val_accuracy: 0.7500\n",
            "Epoch 1432/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3943 - accuracy: 0.8142 - val_loss: 0.5310 - val_accuracy: 0.7500\n",
            "Epoch 1433/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3944 - accuracy: 0.8160 - val_loss: 0.5312 - val_accuracy: 0.7448\n",
            "Epoch 1434/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3942 - accuracy: 0.8177 - val_loss: 0.5312 - val_accuracy: 0.7448\n",
            "Epoch 1435/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3942 - accuracy: 0.8142 - val_loss: 0.5306 - val_accuracy: 0.7500\n",
            "Epoch 1436/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3945 - accuracy: 0.8125 - val_loss: 0.5307 - val_accuracy: 0.7552\n",
            "Epoch 1437/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3945 - accuracy: 0.8142 - val_loss: 0.5311 - val_accuracy: 0.7552\n",
            "Epoch 1438/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3941 - accuracy: 0.8160 - val_loss: 0.5311 - val_accuracy: 0.7552\n",
            "Epoch 1439/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3943 - accuracy: 0.8142 - val_loss: 0.5315 - val_accuracy: 0.7500\n",
            "Epoch 1440/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3942 - accuracy: 0.8142 - val_loss: 0.5313 - val_accuracy: 0.7552\n",
            "Epoch 1441/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3944 - accuracy: 0.8125 - val_loss: 0.5312 - val_accuracy: 0.7552\n",
            "Epoch 1442/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3945 - accuracy: 0.8125 - val_loss: 0.5313 - val_accuracy: 0.7448\n",
            "Epoch 1443/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3941 - accuracy: 0.8160 - val_loss: 0.5309 - val_accuracy: 0.7500\n",
            "Epoch 1444/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3943 - accuracy: 0.8160 - val_loss: 0.5312 - val_accuracy: 0.7500\n",
            "Epoch 1445/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3941 - accuracy: 0.8142 - val_loss: 0.5317 - val_accuracy: 0.7448\n",
            "Epoch 1446/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3944 - accuracy: 0.8142 - val_loss: 0.5312 - val_accuracy: 0.7500\n",
            "Epoch 1447/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3942 - accuracy: 0.8142 - val_loss: 0.5314 - val_accuracy: 0.7448\n",
            "Epoch 1448/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3941 - accuracy: 0.8125 - val_loss: 0.5317 - val_accuracy: 0.7448\n",
            "Epoch 1449/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3943 - accuracy: 0.8108 - val_loss: 0.5323 - val_accuracy: 0.7448\n",
            "Epoch 1450/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3942 - accuracy: 0.8160 - val_loss: 0.5321 - val_accuracy: 0.7500\n",
            "Epoch 1451/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3943 - accuracy: 0.8177 - val_loss: 0.5319 - val_accuracy: 0.7500\n",
            "Epoch 1452/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3940 - accuracy: 0.8177 - val_loss: 0.5320 - val_accuracy: 0.7500\n",
            "Epoch 1453/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3942 - accuracy: 0.8177 - val_loss: 0.5319 - val_accuracy: 0.7500\n",
            "Epoch 1454/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3940 - accuracy: 0.8142 - val_loss: 0.5317 - val_accuracy: 0.7448\n",
            "Epoch 1455/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3944 - accuracy: 0.8125 - val_loss: 0.5319 - val_accuracy: 0.7500\n",
            "Epoch 1456/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3942 - accuracy: 0.8160 - val_loss: 0.5319 - val_accuracy: 0.7500\n",
            "Epoch 1457/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3938 - accuracy: 0.8142 - val_loss: 0.5318 - val_accuracy: 0.7500\n",
            "Epoch 1458/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.3940 - accuracy: 0.8160 - val_loss: 0.5315 - val_accuracy: 0.7552\n",
            "Epoch 1459/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3939 - accuracy: 0.8142 - val_loss: 0.5319 - val_accuracy: 0.7500\n",
            "Epoch 1460/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3943 - accuracy: 0.8160 - val_loss: 0.5314 - val_accuracy: 0.7448\n",
            "Epoch 1461/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3941 - accuracy: 0.8160 - val_loss: 0.5320 - val_accuracy: 0.7500\n",
            "Epoch 1462/1500\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.3943 - accuracy: 0.8142 - val_loss: 0.5323 - val_accuracy: 0.7500\n",
            "Epoch 1463/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3942 - accuracy: 0.8125 - val_loss: 0.5323 - val_accuracy: 0.7448\n",
            "Epoch 1464/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3938 - accuracy: 0.8160 - val_loss: 0.5328 - val_accuracy: 0.7448\n",
            "Epoch 1465/1500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.3940 - accuracy: 0.8142 - val_loss: 0.5330 - val_accuracy: 0.7448\n",
            "Epoch 1466/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3938 - accuracy: 0.8177 - val_loss: 0.5319 - val_accuracy: 0.7500\n",
            "Epoch 1467/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3940 - accuracy: 0.8160 - val_loss: 0.5322 - val_accuracy: 0.7448\n",
            "Epoch 1468/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3939 - accuracy: 0.8160 - val_loss: 0.5322 - val_accuracy: 0.7448\n",
            "Epoch 1469/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3938 - accuracy: 0.8125 - val_loss: 0.5324 - val_accuracy: 0.7448\n",
            "Epoch 1470/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3939 - accuracy: 0.8142 - val_loss: 0.5322 - val_accuracy: 0.7448\n",
            "Epoch 1471/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3940 - accuracy: 0.8125 - val_loss: 0.5325 - val_accuracy: 0.7448\n",
            "Epoch 1472/1500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.3939 - accuracy: 0.8108 - val_loss: 0.5313 - val_accuracy: 0.7500\n",
            "Epoch 1473/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3937 - accuracy: 0.8160 - val_loss: 0.5311 - val_accuracy: 0.7500\n",
            "Epoch 1474/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3938 - accuracy: 0.8160 - val_loss: 0.5320 - val_accuracy: 0.7448\n",
            "Epoch 1475/1500\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.3939 - accuracy: 0.8177 - val_loss: 0.5321 - val_accuracy: 0.7500\n",
            "Epoch 1476/1500\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.3942 - accuracy: 0.8125 - val_loss: 0.5318 - val_accuracy: 0.7552\n",
            "Epoch 1477/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3940 - accuracy: 0.8142 - val_loss: 0.5318 - val_accuracy: 0.7500\n",
            "Epoch 1478/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.3935 - accuracy: 0.8177 - val_loss: 0.5323 - val_accuracy: 0.7500\n",
            "Epoch 1479/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3939 - accuracy: 0.8177 - val_loss: 0.5321 - val_accuracy: 0.7448\n",
            "Epoch 1480/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3943 - accuracy: 0.8090 - val_loss: 0.5327 - val_accuracy: 0.7500\n",
            "Epoch 1481/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3937 - accuracy: 0.8212 - val_loss: 0.5321 - val_accuracy: 0.7448\n",
            "Epoch 1482/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3937 - accuracy: 0.8177 - val_loss: 0.5320 - val_accuracy: 0.7448\n",
            "Epoch 1483/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3936 - accuracy: 0.8142 - val_loss: 0.5325 - val_accuracy: 0.7500\n",
            "Epoch 1484/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3938 - accuracy: 0.8142 - val_loss: 0.5319 - val_accuracy: 0.7448\n",
            "Epoch 1485/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3934 - accuracy: 0.8125 - val_loss: 0.5318 - val_accuracy: 0.7552\n",
            "Epoch 1486/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3935 - accuracy: 0.8177 - val_loss: 0.5323 - val_accuracy: 0.7500\n",
            "Epoch 1487/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3939 - accuracy: 0.8142 - val_loss: 0.5326 - val_accuracy: 0.7500\n",
            "Epoch 1488/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3936 - accuracy: 0.8177 - val_loss: 0.5323 - val_accuracy: 0.7552\n",
            "Epoch 1489/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3936 - accuracy: 0.8160 - val_loss: 0.5317 - val_accuracy: 0.7448\n",
            "Epoch 1490/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3935 - accuracy: 0.8142 - val_loss: 0.5326 - val_accuracy: 0.7500\n",
            "Epoch 1491/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3936 - accuracy: 0.8142 - val_loss: 0.5323 - val_accuracy: 0.7500\n",
            "Epoch 1492/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3934 - accuracy: 0.8177 - val_loss: 0.5317 - val_accuracy: 0.7552\n",
            "Epoch 1493/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3936 - accuracy: 0.8125 - val_loss: 0.5325 - val_accuracy: 0.7500\n",
            "Epoch 1494/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3935 - accuracy: 0.8177 - val_loss: 0.5321 - val_accuracy: 0.7500\n",
            "Epoch 1495/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3937 - accuracy: 0.8142 - val_loss: 0.5323 - val_accuracy: 0.7500\n",
            "Epoch 1496/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3934 - accuracy: 0.8194 - val_loss: 0.5321 - val_accuracy: 0.7500\n",
            "Epoch 1497/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3935 - accuracy: 0.8142 - val_loss: 0.5317 - val_accuracy: 0.7552\n",
            "Epoch 1498/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3933 - accuracy: 0.8160 - val_loss: 0.5310 - val_accuracy: 0.7552\n",
            "Epoch 1499/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3934 - accuracy: 0.8160 - val_loss: 0.5318 - val_accuracy: 0.7552\n",
            "Epoch 1500/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3934 - accuracy: 0.8194 - val_loss: 0.5317 - val_accuracy: 0.7552\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# TASK 3:\n",
        "- Graph the trajectory of the loss functions, accuracy on both train and test set"
      ],
      "metadata": {
        "id": "ZfNEiO3W9vkY"
      },
      "id": "ZfNEiO3W9vkY"
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot the loss and val_loss\n",
        "fig, ax = plt.subplots(figsize=(12, 6))\n",
        "ax.plot(run_hist_2.history[\"loss\"],'r', marker='.', label=\"Train Loss\")\n",
        "ax.plot(run_hist_2.history[\"val_loss\"],'b', marker='.', label=\"Validation Loss\")\n",
        "ax.legend()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 539
        },
        "id": "j90pzqv15PUM",
        "outputId": "8a213ef3-d07f-498b-e284-0d9a058ed20b"
      },
      "id": "j90pzqv15PUM",
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x78dadc53c250>"
            ]
          },
          "metadata": {},
          "execution_count": 79
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot the Train Accuracy and Validation Accuracy\n",
        "fig, ax = plt.subplots(figsize=(12, 6))\n",
        "ax.plot(run_hist_2.history[\"accuracy\"],'r', marker='.', label=\"Train Accuracy\")\n",
        "ax.plot(run_hist_2.history[\"val_accuracy\"],'b', marker='.', label=\"Validation Accuracy\")\n",
        "ax.legend()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 539
        },
        "id": "jQVRmrIq-mYM",
        "outputId": "fe6b5379-3829-442d-81b3-c13cfe7df0b1"
      },
      "id": "jQVRmrIq-mYM",
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x78daec9409a0>"
            ]
          },
          "metadata": {},
          "execution_count": 80
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# TASK 4:\n",
        "- Plot the roc curve for the predictions"
      ],
      "metadata": {
        "id": "30kQs49pHwYs"
      },
      "id": "30kQs49pHwYs"
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred_prob_nn_supple = model.predict(X_test_norm)\n",
        "y_pred_class_nn_supple = (y_pred_prob_nn_1 > 0.5).astype(int)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZWUqs-1rHpWp",
        "outputId": "2328eef4-a39e-4585-d97c-da136a5015b8"
      },
      "id": "ZWUqs-1rHpWp",
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "6/6 [==============================] - 0s 7ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def plot_roc(y_test, y_pred, model_name):\n",
        "    fpr, tpr, thr = roc_curve(y_test, y_pred)\n",
        "    fig, ax = plt.subplots(figsize=(8, 8))\n",
        "    ax.plot(fpr, tpr, 'k-')\n",
        "    ax.plot([0, 1], [0, 1], 'k--', linewidth=.5)  # roc curve for random model\n",
        "    ax.grid(True)\n",
        "    ax.set(title='ROC Curve for {} on PIMA diabetes problem'.format(model_name),\n",
        "           xlim=[-0.01, 1.01], ylim=[-0.01, 1.01])\n",
        "\n",
        "print('accuracy is {:.3f}'.format(accuracy_score(y_test,y_pred_class_nn_supple)))\n",
        "print('roc-auc is {:.3f}'.format(roc_auc_score(y_test,y_pred_prob_nn_supple)))\n",
        "\n",
        "plot_roc(y_test, y_pred_prob_nn_supple, 'NN')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 734
        },
        "id": "KeM5fxo_5ZI6",
        "outputId": "f32df305-404b-41a5-ca42-0480d23e6014"
      },
      "id": "KeM5fxo_5ZI6",
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "accuracy is 0.766\n",
            "roc-auc is 0.834\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x800 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# TASK 5, 6, and 7:\n",
        "- Use different learning rates, numbers of epochs, and network structures.\n",
        "- Plot the results of training and validation loss using different learning rates, number of epocgs and network structures\n",
        "- Interpret your result"
      ],
      "metadata": {
        "id": "l6ox12AuH0HD"
      },
      "id": "l6ox12AuH0HD"
    },
    {
      "cell_type": "markdown",
      "source": [
        "# SAMPLE NUMBER 1."
      ],
      "metadata": {
        "id": "XH6MOQymSPn1"
      },
      "id": "XH6MOQymSPn1"
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import confusion_matrix, precision_recall_curve, roc_auc_score, roc_curve, accuracy_score\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "import seaborn as sns\n",
        "\n",
        "%matplotlib inline\n",
        "\n",
        "## Import Keras objects for Deep Learning\n",
        "\n",
        "from keras.models  import Sequential\n",
        "from keras.layers import Input, Dense, Flatten, Dropout, BatchNormalization\n",
        "from keras.optimizers import Adam, SGD, RMSprop\n",
        "\n",
        "# Load the dataset\n",
        "filepath = \"pima-indians-diabetes.csv\"\n",
        "names = [\"times_pregnant\", \"glucose_tolerance_test\", \"blood_pressure\", \"skin_thickness\", \"insulin\",\n",
        "         \"bmi\", \"pedigree_function\", \"age\", \"has_diabetes\"]\n",
        "diabetes_df = pd.read_csv(filepath, names=names)\n",
        "\n",
        "X = diabetes_df.iloc[:, :-1].values\n",
        "y = diabetes_df[\"has_diabetes\"].values\n",
        "\n",
        "# Split the data into 75% for train set and 25% for test set\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=11111)\n",
        "\n",
        "# Normalize the data\n",
        "normalizer = StandardScaler()\n",
        "X_train_norm = normalizer.fit_transform(X_train)\n",
        "X_test_norm = normalizer.transform(X_test)"
      ],
      "metadata": {
        "id": "oDwias_9KR7G"
      },
      "id": "oDwias_9KR7G",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Learning rate = 0.004\n",
        "- Epochs = 1200\n",
        "- Network structure = 3 hidden layers\n",
        "\n"
      ],
      "metadata": {
        "id": "I5HU3A0nNRAd"
      },
      "id": "I5HU3A0nNRAd"
    },
    {
      "cell_type": "code",
      "source": [
        "model_supple_2  = Sequential([\n",
        "    Dense(8, input_shape=(8,), activation=\"relu\"),\n",
        "    Dense(5, activation=\"relu\"),\n",
        "    Dense(3, activation=\"relu\"),\n",
        "    Dense(1, activation=\"sigmoid\")\n",
        "])"
      ],
      "metadata": {
        "id": "Erqrg8RR6N02"
      },
      "id": "Erqrg8RR6N02",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_supple_2.compile(SGD(lr = .004), \"binary_crossentropy\", metrics=[\"accuracy\"])\n",
        "run_hist_4 = model_supple_2.fit(X_train_norm, y_train, validation_data=(X_test_norm, y_test), epochs=1200)"
      ],
      "metadata": {
        "id": "c_uDd7T2I3y9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "516cd084-384b-4807-a09c-ff1f4bf9fd5d"
      },
      "id": "c_uDd7T2I3y9",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.SGD.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/1200\n",
            "18/18 [==============================] - 1s 12ms/step - loss: 0.6943 - accuracy: 0.6545 - val_loss: 0.6914 - val_accuracy: 0.6406\n",
            "Epoch 2/1200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6836 - accuracy: 0.6545 - val_loss: 0.6803 - val_accuracy: 0.6406\n",
            "Epoch 3/1200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6737 - accuracy: 0.6545 - val_loss: 0.6707 - val_accuracy: 0.6406\n",
            "Epoch 4/1200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6640 - accuracy: 0.6545 - val_loss: 0.6620 - val_accuracy: 0.6406\n",
            "Epoch 5/1200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6548 - accuracy: 0.6545 - val_loss: 0.6541 - val_accuracy: 0.6406\n",
            "Epoch 6/1200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6464 - accuracy: 0.6545 - val_loss: 0.6468 - val_accuracy: 0.6406\n",
            "Epoch 7/1200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6385 - accuracy: 0.6545 - val_loss: 0.6406 - val_accuracy: 0.6406\n",
            "Epoch 8/1200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6313 - accuracy: 0.6545 - val_loss: 0.6348 - val_accuracy: 0.6406\n",
            "Epoch 9/1200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6248 - accuracy: 0.6545 - val_loss: 0.6292 - val_accuracy: 0.6406\n",
            "Epoch 10/1200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6189 - accuracy: 0.6545 - val_loss: 0.6239 - val_accuracy: 0.6406\n",
            "Epoch 11/1200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6131 - accuracy: 0.6545 - val_loss: 0.6191 - val_accuracy: 0.6406\n",
            "Epoch 12/1200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6077 - accuracy: 0.6545 - val_loss: 0.6144 - val_accuracy: 0.6406\n",
            "Epoch 13/1200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6027 - accuracy: 0.6545 - val_loss: 0.6100 - val_accuracy: 0.6406\n",
            "Epoch 14/1200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5978 - accuracy: 0.6545 - val_loss: 0.6058 - val_accuracy: 0.6406\n",
            "Epoch 15/1200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5932 - accuracy: 0.6545 - val_loss: 0.6019 - val_accuracy: 0.6406\n",
            "Epoch 16/1200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5891 - accuracy: 0.6545 - val_loss: 0.5982 - val_accuracy: 0.6406\n",
            "Epoch 17/1200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5850 - accuracy: 0.6545 - val_loss: 0.5947 - val_accuracy: 0.6406\n",
            "Epoch 18/1200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5812 - accuracy: 0.6545 - val_loss: 0.5913 - val_accuracy: 0.6406\n",
            "Epoch 19/1200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5774 - accuracy: 0.6545 - val_loss: 0.5882 - val_accuracy: 0.6406\n",
            "Epoch 20/1200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5736 - accuracy: 0.6545 - val_loss: 0.5849 - val_accuracy: 0.6406\n",
            "Epoch 21/1200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5699 - accuracy: 0.6545 - val_loss: 0.5817 - val_accuracy: 0.6406\n",
            "Epoch 22/1200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5665 - accuracy: 0.6545 - val_loss: 0.5785 - val_accuracy: 0.6406\n",
            "Epoch 23/1200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5630 - accuracy: 0.6545 - val_loss: 0.5753 - val_accuracy: 0.6406\n",
            "Epoch 24/1200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5600 - accuracy: 0.6545 - val_loss: 0.5723 - val_accuracy: 0.6406\n",
            "Epoch 25/1200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5566 - accuracy: 0.6545 - val_loss: 0.5694 - val_accuracy: 0.6406\n",
            "Epoch 26/1200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5535 - accuracy: 0.6545 - val_loss: 0.5666 - val_accuracy: 0.6406\n",
            "Epoch 27/1200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5504 - accuracy: 0.6545 - val_loss: 0.5639 - val_accuracy: 0.6406\n",
            "Epoch 28/1200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5475 - accuracy: 0.6545 - val_loss: 0.5614 - val_accuracy: 0.6406\n",
            "Epoch 29/1200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5446 - accuracy: 0.6545 - val_loss: 0.5588 - val_accuracy: 0.6406\n",
            "Epoch 30/1200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5417 - accuracy: 0.6545 - val_loss: 0.5561 - val_accuracy: 0.6406\n",
            "Epoch 31/1200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5392 - accuracy: 0.6545 - val_loss: 0.5537 - val_accuracy: 0.6406\n",
            "Epoch 32/1200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5365 - accuracy: 0.6545 - val_loss: 0.5514 - val_accuracy: 0.6406\n",
            "Epoch 33/1200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5341 - accuracy: 0.6545 - val_loss: 0.5494 - val_accuracy: 0.6406\n",
            "Epoch 34/1200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5320 - accuracy: 0.6997 - val_loss: 0.5475 - val_accuracy: 0.7344\n",
            "Epoch 35/1200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5296 - accuracy: 0.7222 - val_loss: 0.5456 - val_accuracy: 0.7396\n",
            "Epoch 36/1200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5273 - accuracy: 0.7222 - val_loss: 0.5439 - val_accuracy: 0.7500\n",
            "Epoch 37/1200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5252 - accuracy: 0.7274 - val_loss: 0.5422 - val_accuracy: 0.7552\n",
            "Epoch 38/1200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5232 - accuracy: 0.7361 - val_loss: 0.5406 - val_accuracy: 0.7604\n",
            "Epoch 39/1200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5211 - accuracy: 0.7448 - val_loss: 0.5390 - val_accuracy: 0.7604\n",
            "Epoch 40/1200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5193 - accuracy: 0.7448 - val_loss: 0.5375 - val_accuracy: 0.7656\n",
            "Epoch 41/1200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5175 - accuracy: 0.7517 - val_loss: 0.5361 - val_accuracy: 0.7708\n",
            "Epoch 42/1200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5157 - accuracy: 0.7552 - val_loss: 0.5348 - val_accuracy: 0.7656\n",
            "Epoch 43/1200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5138 - accuracy: 0.7587 - val_loss: 0.5337 - val_accuracy: 0.7656\n",
            "Epoch 44/1200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5122 - accuracy: 0.7622 - val_loss: 0.5328 - val_accuracy: 0.7656\n",
            "Epoch 45/1200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5104 - accuracy: 0.7639 - val_loss: 0.5319 - val_accuracy: 0.7708\n",
            "Epoch 46/1200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5089 - accuracy: 0.7639 - val_loss: 0.5310 - val_accuracy: 0.7708\n",
            "Epoch 47/1200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5072 - accuracy: 0.7604 - val_loss: 0.5301 - val_accuracy: 0.7708\n",
            "Epoch 48/1200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5057 - accuracy: 0.7604 - val_loss: 0.5292 - val_accuracy: 0.7708\n",
            "Epoch 49/1200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5041 - accuracy: 0.7604 - val_loss: 0.5283 - val_accuracy: 0.7760\n",
            "Epoch 50/1200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5026 - accuracy: 0.7587 - val_loss: 0.5275 - val_accuracy: 0.7708\n",
            "Epoch 51/1200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5012 - accuracy: 0.7604 - val_loss: 0.5267 - val_accuracy: 0.7708\n",
            "Epoch 52/1200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5000 - accuracy: 0.7569 - val_loss: 0.5260 - val_accuracy: 0.7656\n",
            "Epoch 53/1200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4988 - accuracy: 0.7587 - val_loss: 0.5253 - val_accuracy: 0.7656\n",
            "Epoch 54/1200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4978 - accuracy: 0.7604 - val_loss: 0.5247 - val_accuracy: 0.7656\n",
            "Epoch 55/1200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4968 - accuracy: 0.7587 - val_loss: 0.5242 - val_accuracy: 0.7656\n",
            "Epoch 56/1200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4961 - accuracy: 0.7622 - val_loss: 0.5237 - val_accuracy: 0.7604\n",
            "Epoch 57/1200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4951 - accuracy: 0.7587 - val_loss: 0.5232 - val_accuracy: 0.7656\n",
            "Epoch 58/1200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4941 - accuracy: 0.7622 - val_loss: 0.5228 - val_accuracy: 0.7656\n",
            "Epoch 59/1200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4933 - accuracy: 0.7604 - val_loss: 0.5224 - val_accuracy: 0.7656\n",
            "Epoch 60/1200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4925 - accuracy: 0.7639 - val_loss: 0.5220 - val_accuracy: 0.7708\n",
            "Epoch 61/1200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4916 - accuracy: 0.7639 - val_loss: 0.5216 - val_accuracy: 0.7708\n",
            "Epoch 62/1200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4911 - accuracy: 0.7622 - val_loss: 0.5213 - val_accuracy: 0.7656\n",
            "Epoch 63/1200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4902 - accuracy: 0.7656 - val_loss: 0.5210 - val_accuracy: 0.7656\n",
            "Epoch 64/1200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4896 - accuracy: 0.7674 - val_loss: 0.5208 - val_accuracy: 0.7604\n",
            "Epoch 65/1200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4889 - accuracy: 0.7674 - val_loss: 0.5206 - val_accuracy: 0.7604\n",
            "Epoch 66/1200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4883 - accuracy: 0.7674 - val_loss: 0.5204 - val_accuracy: 0.7604\n",
            "Epoch 67/1200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4874 - accuracy: 0.7674 - val_loss: 0.5203 - val_accuracy: 0.7604\n",
            "Epoch 68/1200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4869 - accuracy: 0.7674 - val_loss: 0.5201 - val_accuracy: 0.7552\n",
            "Epoch 69/1200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4863 - accuracy: 0.7674 - val_loss: 0.5200 - val_accuracy: 0.7552\n",
            "Epoch 70/1200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4857 - accuracy: 0.7691 - val_loss: 0.5199 - val_accuracy: 0.7500\n",
            "Epoch 71/1200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4850 - accuracy: 0.7708 - val_loss: 0.5198 - val_accuracy: 0.7552\n",
            "Epoch 72/1200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4845 - accuracy: 0.7691 - val_loss: 0.5197 - val_accuracy: 0.7552\n",
            "Epoch 73/1200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4839 - accuracy: 0.7708 - val_loss: 0.5196 - val_accuracy: 0.7552\n",
            "Epoch 74/1200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4833 - accuracy: 0.7691 - val_loss: 0.5196 - val_accuracy: 0.7500\n",
            "Epoch 75/1200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4827 - accuracy: 0.7691 - val_loss: 0.5195 - val_accuracy: 0.7448\n",
            "Epoch 76/1200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4820 - accuracy: 0.7726 - val_loss: 0.5195 - val_accuracy: 0.7448\n",
            "Epoch 77/1200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4814 - accuracy: 0.7726 - val_loss: 0.5195 - val_accuracy: 0.7448\n",
            "Epoch 78/1200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4810 - accuracy: 0.7674 - val_loss: 0.5194 - val_accuracy: 0.7448\n",
            "Epoch 79/1200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4804 - accuracy: 0.7708 - val_loss: 0.5194 - val_accuracy: 0.7448\n",
            "Epoch 80/1200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4797 - accuracy: 0.7708 - val_loss: 0.5194 - val_accuracy: 0.7448\n",
            "Epoch 81/1200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4793 - accuracy: 0.7726 - val_loss: 0.5194 - val_accuracy: 0.7448\n",
            "Epoch 82/1200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4787 - accuracy: 0.7691 - val_loss: 0.5194 - val_accuracy: 0.7448\n",
            "Epoch 83/1200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4781 - accuracy: 0.7726 - val_loss: 0.5193 - val_accuracy: 0.7448\n",
            "Epoch 84/1200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4776 - accuracy: 0.7726 - val_loss: 0.5194 - val_accuracy: 0.7448\n",
            "Epoch 85/1200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4771 - accuracy: 0.7708 - val_loss: 0.5194 - val_accuracy: 0.7500\n",
            "Epoch 86/1200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4765 - accuracy: 0.7708 - val_loss: 0.5193 - val_accuracy: 0.7448\n",
            "Epoch 87/1200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4763 - accuracy: 0.7726 - val_loss: 0.5193 - val_accuracy: 0.7448\n",
            "Epoch 88/1200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4759 - accuracy: 0.7726 - val_loss: 0.5192 - val_accuracy: 0.7500\n",
            "Epoch 89/1200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4753 - accuracy: 0.7726 - val_loss: 0.5191 - val_accuracy: 0.7500\n",
            "Epoch 90/1200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4749 - accuracy: 0.7726 - val_loss: 0.5191 - val_accuracy: 0.7500\n",
            "Epoch 91/1200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4743 - accuracy: 0.7691 - val_loss: 0.5190 - val_accuracy: 0.7500\n",
            "Epoch 92/1200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4741 - accuracy: 0.7639 - val_loss: 0.5190 - val_accuracy: 0.7500\n",
            "Epoch 93/1200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4736 - accuracy: 0.7708 - val_loss: 0.5190 - val_accuracy: 0.7552\n",
            "Epoch 94/1200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4731 - accuracy: 0.7674 - val_loss: 0.5190 - val_accuracy: 0.7552\n",
            "Epoch 95/1200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4725 - accuracy: 0.7639 - val_loss: 0.5190 - val_accuracy: 0.7552\n",
            "Epoch 96/1200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4722 - accuracy: 0.7656 - val_loss: 0.5191 - val_accuracy: 0.7552\n",
            "Epoch 97/1200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4718 - accuracy: 0.7639 - val_loss: 0.5191 - val_accuracy: 0.7552\n",
            "Epoch 98/1200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4716 - accuracy: 0.7639 - val_loss: 0.5191 - val_accuracy: 0.7552\n",
            "Epoch 99/1200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4710 - accuracy: 0.7622 - val_loss: 0.5191 - val_accuracy: 0.7552\n",
            "Epoch 100/1200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4707 - accuracy: 0.7656 - val_loss: 0.5191 - val_accuracy: 0.7552\n",
            "Epoch 101/1200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4704 - accuracy: 0.7691 - val_loss: 0.5191 - val_accuracy: 0.7552\n",
            "Epoch 102/1200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4700 - accuracy: 0.7656 - val_loss: 0.5191 - val_accuracy: 0.7552\n",
            "Epoch 103/1200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4697 - accuracy: 0.7674 - val_loss: 0.5191 - val_accuracy: 0.7552\n",
            "Epoch 104/1200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4693 - accuracy: 0.7656 - val_loss: 0.5191 - val_accuracy: 0.7552\n",
            "Epoch 105/1200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4690 - accuracy: 0.7656 - val_loss: 0.5191 - val_accuracy: 0.7552\n",
            "Epoch 106/1200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4686 - accuracy: 0.7674 - val_loss: 0.5192 - val_accuracy: 0.7552\n",
            "Epoch 107/1200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4683 - accuracy: 0.7691 - val_loss: 0.5193 - val_accuracy: 0.7552\n",
            "Epoch 108/1200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4681 - accuracy: 0.7656 - val_loss: 0.5194 - val_accuracy: 0.7552\n",
            "Epoch 109/1200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4677 - accuracy: 0.7656 - val_loss: 0.5194 - val_accuracy: 0.7552\n",
            "Epoch 110/1200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4673 - accuracy: 0.7639 - val_loss: 0.5195 - val_accuracy: 0.7552\n",
            "Epoch 111/1200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4671 - accuracy: 0.7691 - val_loss: 0.5196 - val_accuracy: 0.7500\n",
            "Epoch 112/1200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4667 - accuracy: 0.7691 - val_loss: 0.5196 - val_accuracy: 0.7500\n",
            "Epoch 113/1200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4665 - accuracy: 0.7674 - val_loss: 0.5196 - val_accuracy: 0.7448\n",
            "Epoch 114/1200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4660 - accuracy: 0.7691 - val_loss: 0.5197 - val_accuracy: 0.7448\n",
            "Epoch 115/1200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4658 - accuracy: 0.7691 - val_loss: 0.5198 - val_accuracy: 0.7448\n",
            "Epoch 116/1200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4654 - accuracy: 0.7656 - val_loss: 0.5198 - val_accuracy: 0.7448\n",
            "Epoch 117/1200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4652 - accuracy: 0.7674 - val_loss: 0.5199 - val_accuracy: 0.7396\n",
            "Epoch 118/1200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4650 - accuracy: 0.7691 - val_loss: 0.5199 - val_accuracy: 0.7396\n",
            "Epoch 119/1200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4646 - accuracy: 0.7656 - val_loss: 0.5200 - val_accuracy: 0.7396\n",
            "Epoch 120/1200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4646 - accuracy: 0.7656 - val_loss: 0.5201 - val_accuracy: 0.7396\n",
            "Epoch 121/1200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4641 - accuracy: 0.7691 - val_loss: 0.5203 - val_accuracy: 0.7396\n",
            "Epoch 122/1200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4638 - accuracy: 0.7674 - val_loss: 0.5203 - val_accuracy: 0.7396\n",
            "Epoch 123/1200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4635 - accuracy: 0.7691 - val_loss: 0.5203 - val_accuracy: 0.7448\n",
            "Epoch 124/1200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4633 - accuracy: 0.7691 - val_loss: 0.5203 - val_accuracy: 0.7448\n",
            "Epoch 125/1200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4631 - accuracy: 0.7656 - val_loss: 0.5205 - val_accuracy: 0.7448\n",
            "Epoch 126/1200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4631 - accuracy: 0.7708 - val_loss: 0.5206 - val_accuracy: 0.7448\n",
            "Epoch 127/1200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4626 - accuracy: 0.7674 - val_loss: 0.5207 - val_accuracy: 0.7448\n",
            "Epoch 128/1200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4623 - accuracy: 0.7674 - val_loss: 0.5208 - val_accuracy: 0.7448\n",
            "Epoch 129/1200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4620 - accuracy: 0.7708 - val_loss: 0.5208 - val_accuracy: 0.7448\n",
            "Epoch 130/1200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4616 - accuracy: 0.7691 - val_loss: 0.5209 - val_accuracy: 0.7448\n",
            "Epoch 131/1200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4614 - accuracy: 0.7674 - val_loss: 0.5209 - val_accuracy: 0.7448\n",
            "Epoch 132/1200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4612 - accuracy: 0.7691 - val_loss: 0.5209 - val_accuracy: 0.7448\n",
            "Epoch 133/1200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4610 - accuracy: 0.7726 - val_loss: 0.5211 - val_accuracy: 0.7448\n",
            "Epoch 134/1200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4607 - accuracy: 0.7691 - val_loss: 0.5213 - val_accuracy: 0.7448\n",
            "Epoch 135/1200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4604 - accuracy: 0.7708 - val_loss: 0.5214 - val_accuracy: 0.7448\n",
            "Epoch 136/1200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4602 - accuracy: 0.7691 - val_loss: 0.5214 - val_accuracy: 0.7448\n",
            "Epoch 137/1200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4601 - accuracy: 0.7691 - val_loss: 0.5216 - val_accuracy: 0.7448\n",
            "Epoch 138/1200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4598 - accuracy: 0.7656 - val_loss: 0.5217 - val_accuracy: 0.7448\n",
            "Epoch 139/1200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4596 - accuracy: 0.7639 - val_loss: 0.5219 - val_accuracy: 0.7448\n",
            "Epoch 140/1200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4595 - accuracy: 0.7639 - val_loss: 0.5221 - val_accuracy: 0.7448\n",
            "Epoch 141/1200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4591 - accuracy: 0.7674 - val_loss: 0.5222 - val_accuracy: 0.7396\n",
            "Epoch 142/1200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4589 - accuracy: 0.7691 - val_loss: 0.5222 - val_accuracy: 0.7396\n",
            "Epoch 143/1200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4586 - accuracy: 0.7639 - val_loss: 0.5224 - val_accuracy: 0.7396\n",
            "Epoch 144/1200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4585 - accuracy: 0.7708 - val_loss: 0.5225 - val_accuracy: 0.7396\n",
            "Epoch 145/1200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4580 - accuracy: 0.7639 - val_loss: 0.5226 - val_accuracy: 0.7396\n",
            "Epoch 146/1200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4582 - accuracy: 0.7639 - val_loss: 0.5227 - val_accuracy: 0.7396\n",
            "Epoch 147/1200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4578 - accuracy: 0.7674 - val_loss: 0.5228 - val_accuracy: 0.7396\n",
            "Epoch 148/1200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4574 - accuracy: 0.7639 - val_loss: 0.5229 - val_accuracy: 0.7396\n",
            "Epoch 149/1200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4573 - accuracy: 0.7656 - val_loss: 0.5230 - val_accuracy: 0.7396\n",
            "Epoch 150/1200\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4572 - accuracy: 0.7604 - val_loss: 0.5231 - val_accuracy: 0.7396\n",
            "Epoch 151/1200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4569 - accuracy: 0.7656 - val_loss: 0.5232 - val_accuracy: 0.7396\n",
            "Epoch 152/1200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4568 - accuracy: 0.7639 - val_loss: 0.5234 - val_accuracy: 0.7396\n",
            "Epoch 153/1200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4567 - accuracy: 0.7622 - val_loss: 0.5235 - val_accuracy: 0.7396\n",
            "Epoch 154/1200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4562 - accuracy: 0.7656 - val_loss: 0.5237 - val_accuracy: 0.7396\n",
            "Epoch 155/1200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4562 - accuracy: 0.7639 - val_loss: 0.5237 - val_accuracy: 0.7396\n",
            "Epoch 156/1200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4557 - accuracy: 0.7674 - val_loss: 0.5239 - val_accuracy: 0.7344\n",
            "Epoch 157/1200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4558 - accuracy: 0.7674 - val_loss: 0.5239 - val_accuracy: 0.7344\n",
            "Epoch 158/1200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4553 - accuracy: 0.7656 - val_loss: 0.5241 - val_accuracy: 0.7344\n",
            "Epoch 159/1200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4552 - accuracy: 0.7622 - val_loss: 0.5241 - val_accuracy: 0.7344\n",
            "Epoch 160/1200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4550 - accuracy: 0.7639 - val_loss: 0.5243 - val_accuracy: 0.7344\n",
            "Epoch 161/1200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4549 - accuracy: 0.7639 - val_loss: 0.5245 - val_accuracy: 0.7344\n",
            "Epoch 162/1200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4546 - accuracy: 0.7656 - val_loss: 0.5246 - val_accuracy: 0.7344\n",
            "Epoch 163/1200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4546 - accuracy: 0.7674 - val_loss: 0.5246 - val_accuracy: 0.7344\n",
            "Epoch 164/1200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4543 - accuracy: 0.7639 - val_loss: 0.5247 - val_accuracy: 0.7344\n",
            "Epoch 165/1200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4540 - accuracy: 0.7674 - val_loss: 0.5247 - val_accuracy: 0.7344\n",
            "Epoch 166/1200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4542 - accuracy: 0.7639 - val_loss: 0.5248 - val_accuracy: 0.7344\n",
            "Epoch 167/1200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4537 - accuracy: 0.7656 - val_loss: 0.5250 - val_accuracy: 0.7344\n",
            "Epoch 168/1200\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.4536 - accuracy: 0.7691 - val_loss: 0.5251 - val_accuracy: 0.7344\n",
            "Epoch 169/1200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4533 - accuracy: 0.7656 - val_loss: 0.5253 - val_accuracy: 0.7344\n",
            "Epoch 170/1200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4531 - accuracy: 0.7708 - val_loss: 0.5255 - val_accuracy: 0.7344\n",
            "Epoch 171/1200\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.4528 - accuracy: 0.7656 - val_loss: 0.5256 - val_accuracy: 0.7344\n",
            "Epoch 172/1200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4530 - accuracy: 0.7674 - val_loss: 0.5258 - val_accuracy: 0.7344\n",
            "Epoch 173/1200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4527 - accuracy: 0.7674 - val_loss: 0.5258 - val_accuracy: 0.7292\n",
            "Epoch 174/1200\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.4523 - accuracy: 0.7674 - val_loss: 0.5260 - val_accuracy: 0.7344\n",
            "Epoch 175/1200\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4523 - accuracy: 0.7708 - val_loss: 0.5261 - val_accuracy: 0.7344\n",
            "Epoch 176/1200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4522 - accuracy: 0.7708 - val_loss: 0.5263 - val_accuracy: 0.7344\n",
            "Epoch 177/1200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4517 - accuracy: 0.7708 - val_loss: 0.5266 - val_accuracy: 0.7344\n",
            "Epoch 178/1200\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.4516 - accuracy: 0.7726 - val_loss: 0.5268 - val_accuracy: 0.7344\n",
            "Epoch 179/1200\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4515 - accuracy: 0.7760 - val_loss: 0.5267 - val_accuracy: 0.7344\n",
            "Epoch 180/1200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4513 - accuracy: 0.7760 - val_loss: 0.5269 - val_accuracy: 0.7344\n",
            "Epoch 181/1200\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.4512 - accuracy: 0.7778 - val_loss: 0.5271 - val_accuracy: 0.7344\n",
            "Epoch 182/1200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4511 - accuracy: 0.7760 - val_loss: 0.5272 - val_accuracy: 0.7344\n",
            "Epoch 183/1200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4506 - accuracy: 0.7760 - val_loss: 0.5274 - val_accuracy: 0.7344\n",
            "Epoch 184/1200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4504 - accuracy: 0.7743 - val_loss: 0.5277 - val_accuracy: 0.7344\n",
            "Epoch 185/1200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4502 - accuracy: 0.7795 - val_loss: 0.5279 - val_accuracy: 0.7344\n",
            "Epoch 186/1200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4501 - accuracy: 0.7830 - val_loss: 0.5281 - val_accuracy: 0.7344\n",
            "Epoch 187/1200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4499 - accuracy: 0.7812 - val_loss: 0.5282 - val_accuracy: 0.7344\n",
            "Epoch 188/1200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4495 - accuracy: 0.7795 - val_loss: 0.5284 - val_accuracy: 0.7344\n",
            "Epoch 189/1200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4495 - accuracy: 0.7778 - val_loss: 0.5285 - val_accuracy: 0.7344\n",
            "Epoch 190/1200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4491 - accuracy: 0.7812 - val_loss: 0.5287 - val_accuracy: 0.7344\n",
            "Epoch 191/1200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4488 - accuracy: 0.7812 - val_loss: 0.5287 - val_accuracy: 0.7344\n",
            "Epoch 192/1200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4487 - accuracy: 0.7865 - val_loss: 0.5289 - val_accuracy: 0.7344\n",
            "Epoch 193/1200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4486 - accuracy: 0.7865 - val_loss: 0.5291 - val_accuracy: 0.7344\n",
            "Epoch 194/1200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4482 - accuracy: 0.7847 - val_loss: 0.5292 - val_accuracy: 0.7344\n",
            "Epoch 195/1200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4480 - accuracy: 0.7847 - val_loss: 0.5294 - val_accuracy: 0.7344\n",
            "Epoch 196/1200\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.4477 - accuracy: 0.7847 - val_loss: 0.5295 - val_accuracy: 0.7344\n",
            "Epoch 197/1200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4475 - accuracy: 0.7812 - val_loss: 0.5296 - val_accuracy: 0.7344\n",
            "Epoch 198/1200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4473 - accuracy: 0.7830 - val_loss: 0.5296 - val_accuracy: 0.7292\n",
            "Epoch 199/1200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4470 - accuracy: 0.7847 - val_loss: 0.5299 - val_accuracy: 0.7344\n",
            "Epoch 200/1200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4469 - accuracy: 0.7847 - val_loss: 0.5301 - val_accuracy: 0.7344\n",
            "Epoch 201/1200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4467 - accuracy: 0.7865 - val_loss: 0.5303 - val_accuracy: 0.7292\n",
            "Epoch 202/1200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4465 - accuracy: 0.7847 - val_loss: 0.5305 - val_accuracy: 0.7292\n",
            "Epoch 203/1200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4462 - accuracy: 0.7865 - val_loss: 0.5305 - val_accuracy: 0.7292\n",
            "Epoch 204/1200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4460 - accuracy: 0.7847 - val_loss: 0.5307 - val_accuracy: 0.7292\n",
            "Epoch 205/1200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4461 - accuracy: 0.7865 - val_loss: 0.5307 - val_accuracy: 0.7292\n",
            "Epoch 206/1200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4457 - accuracy: 0.7847 - val_loss: 0.5308 - val_accuracy: 0.7292\n",
            "Epoch 207/1200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4455 - accuracy: 0.7882 - val_loss: 0.5309 - val_accuracy: 0.7292\n",
            "Epoch 208/1200\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4452 - accuracy: 0.7865 - val_loss: 0.5309 - val_accuracy: 0.7292\n",
            "Epoch 209/1200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4450 - accuracy: 0.7865 - val_loss: 0.5310 - val_accuracy: 0.7292\n",
            "Epoch 210/1200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4450 - accuracy: 0.7865 - val_loss: 0.5312 - val_accuracy: 0.7292\n",
            "Epoch 211/1200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4446 - accuracy: 0.7865 - val_loss: 0.5313 - val_accuracy: 0.7292\n",
            "Epoch 212/1200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4446 - accuracy: 0.7865 - val_loss: 0.5312 - val_accuracy: 0.7292\n",
            "Epoch 213/1200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4444 - accuracy: 0.7882 - val_loss: 0.5312 - val_accuracy: 0.7292\n",
            "Epoch 214/1200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4442 - accuracy: 0.7865 - val_loss: 0.5312 - val_accuracy: 0.7240\n",
            "Epoch 215/1200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4439 - accuracy: 0.7865 - val_loss: 0.5314 - val_accuracy: 0.7292\n",
            "Epoch 216/1200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4439 - accuracy: 0.7865 - val_loss: 0.5314 - val_accuracy: 0.7292\n",
            "Epoch 217/1200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4438 - accuracy: 0.7917 - val_loss: 0.5313 - val_accuracy: 0.7292\n",
            "Epoch 218/1200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4435 - accuracy: 0.7917 - val_loss: 0.5314 - val_accuracy: 0.7292\n",
            "Epoch 219/1200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4435 - accuracy: 0.7882 - val_loss: 0.5313 - val_accuracy: 0.7240\n",
            "Epoch 220/1200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4431 - accuracy: 0.7917 - val_loss: 0.5314 - val_accuracy: 0.7240\n",
            "Epoch 221/1200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4428 - accuracy: 0.7882 - val_loss: 0.5314 - val_accuracy: 0.7240\n",
            "Epoch 222/1200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4427 - accuracy: 0.7899 - val_loss: 0.5315 - val_accuracy: 0.7292\n",
            "Epoch 223/1200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4428 - accuracy: 0.7882 - val_loss: 0.5315 - val_accuracy: 0.7292\n",
            "Epoch 224/1200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4424 - accuracy: 0.7917 - val_loss: 0.5315 - val_accuracy: 0.7292\n",
            "Epoch 225/1200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4425 - accuracy: 0.7847 - val_loss: 0.5314 - val_accuracy: 0.7240\n",
            "Epoch 226/1200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4421 - accuracy: 0.7882 - val_loss: 0.5315 - val_accuracy: 0.7240\n",
            "Epoch 227/1200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4422 - accuracy: 0.7882 - val_loss: 0.5313 - val_accuracy: 0.7240\n",
            "Epoch 228/1200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4419 - accuracy: 0.7847 - val_loss: 0.5315 - val_accuracy: 0.7240\n",
            "Epoch 229/1200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4418 - accuracy: 0.7899 - val_loss: 0.5316 - val_accuracy: 0.7292\n",
            "Epoch 230/1200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4415 - accuracy: 0.7917 - val_loss: 0.5317 - val_accuracy: 0.7292\n",
            "Epoch 231/1200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4414 - accuracy: 0.7865 - val_loss: 0.5317 - val_accuracy: 0.7240\n",
            "Epoch 232/1200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4413 - accuracy: 0.7882 - val_loss: 0.5317 - val_accuracy: 0.7240\n",
            "Epoch 233/1200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4412 - accuracy: 0.7899 - val_loss: 0.5316 - val_accuracy: 0.7240\n",
            "Epoch 234/1200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4408 - accuracy: 0.7865 - val_loss: 0.5317 - val_accuracy: 0.7240\n",
            "Epoch 235/1200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4408 - accuracy: 0.7847 - val_loss: 0.5318 - val_accuracy: 0.7240\n",
            "Epoch 236/1200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4408 - accuracy: 0.7899 - val_loss: 0.5318 - val_accuracy: 0.7240\n",
            "Epoch 237/1200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4405 - accuracy: 0.7882 - val_loss: 0.5319 - val_accuracy: 0.7240\n",
            "Epoch 238/1200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4402 - accuracy: 0.7882 - val_loss: 0.5317 - val_accuracy: 0.7240\n",
            "Epoch 239/1200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4401 - accuracy: 0.7847 - val_loss: 0.5319 - val_accuracy: 0.7240\n",
            "Epoch 240/1200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4401 - accuracy: 0.7847 - val_loss: 0.5318 - val_accuracy: 0.7240\n",
            "Epoch 241/1200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4399 - accuracy: 0.7865 - val_loss: 0.5318 - val_accuracy: 0.7292\n",
            "Epoch 242/1200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4395 - accuracy: 0.7847 - val_loss: 0.5318 - val_accuracy: 0.7344\n",
            "Epoch 243/1200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4394 - accuracy: 0.7847 - val_loss: 0.5318 - val_accuracy: 0.7344\n",
            "Epoch 244/1200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4394 - accuracy: 0.7847 - val_loss: 0.5318 - val_accuracy: 0.7344\n",
            "Epoch 245/1200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4391 - accuracy: 0.7847 - val_loss: 0.5317 - val_accuracy: 0.7344\n",
            "Epoch 246/1200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4390 - accuracy: 0.7847 - val_loss: 0.5316 - val_accuracy: 0.7344\n",
            "Epoch 247/1200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4388 - accuracy: 0.7847 - val_loss: 0.5317 - val_accuracy: 0.7344\n",
            "Epoch 248/1200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4386 - accuracy: 0.7830 - val_loss: 0.5317 - val_accuracy: 0.7344\n",
            "Epoch 249/1200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4385 - accuracy: 0.7847 - val_loss: 0.5317 - val_accuracy: 0.7344\n",
            "Epoch 250/1200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4386 - accuracy: 0.7795 - val_loss: 0.5319 - val_accuracy: 0.7396\n",
            "Epoch 251/1200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4380 - accuracy: 0.7830 - val_loss: 0.5319 - val_accuracy: 0.7396\n",
            "Epoch 252/1200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4380 - accuracy: 0.7830 - val_loss: 0.5319 - val_accuracy: 0.7396\n",
            "Epoch 253/1200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4377 - accuracy: 0.7882 - val_loss: 0.5317 - val_accuracy: 0.7396\n",
            "Epoch 254/1200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4376 - accuracy: 0.7795 - val_loss: 0.5318 - val_accuracy: 0.7396\n",
            "Epoch 255/1200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4375 - accuracy: 0.7865 - val_loss: 0.5318 - val_accuracy: 0.7396\n",
            "Epoch 256/1200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4372 - accuracy: 0.7882 - val_loss: 0.5316 - val_accuracy: 0.7396\n",
            "Epoch 257/1200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4368 - accuracy: 0.7812 - val_loss: 0.5318 - val_accuracy: 0.7344\n",
            "Epoch 258/1200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4369 - accuracy: 0.7830 - val_loss: 0.5318 - val_accuracy: 0.7396\n",
            "Epoch 259/1200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4367 - accuracy: 0.7847 - val_loss: 0.5318 - val_accuracy: 0.7396\n",
            "Epoch 260/1200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4366 - accuracy: 0.7812 - val_loss: 0.5318 - val_accuracy: 0.7396\n",
            "Epoch 261/1200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4364 - accuracy: 0.7830 - val_loss: 0.5319 - val_accuracy: 0.7396\n",
            "Epoch 262/1200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4363 - accuracy: 0.7847 - val_loss: 0.5320 - val_accuracy: 0.7396\n",
            "Epoch 263/1200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4360 - accuracy: 0.7812 - val_loss: 0.5321 - val_accuracy: 0.7396\n",
            "Epoch 264/1200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4360 - accuracy: 0.7847 - val_loss: 0.5320 - val_accuracy: 0.7396\n",
            "Epoch 265/1200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4357 - accuracy: 0.7830 - val_loss: 0.5322 - val_accuracy: 0.7396\n",
            "Epoch 266/1200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4355 - accuracy: 0.7812 - val_loss: 0.5323 - val_accuracy: 0.7396\n",
            "Epoch 267/1200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4353 - accuracy: 0.7899 - val_loss: 0.5323 - val_accuracy: 0.7448\n",
            "Epoch 268/1200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4352 - accuracy: 0.7865 - val_loss: 0.5326 - val_accuracy: 0.7448\n",
            "Epoch 269/1200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4352 - accuracy: 0.7882 - val_loss: 0.5327 - val_accuracy: 0.7448\n",
            "Epoch 270/1200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4348 - accuracy: 0.7917 - val_loss: 0.5325 - val_accuracy: 0.7396\n",
            "Epoch 271/1200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4346 - accuracy: 0.7917 - val_loss: 0.5325 - val_accuracy: 0.7396\n",
            "Epoch 272/1200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4347 - accuracy: 0.7899 - val_loss: 0.5326 - val_accuracy: 0.7396\n",
            "Epoch 273/1200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4344 - accuracy: 0.7899 - val_loss: 0.5327 - val_accuracy: 0.7396\n",
            "Epoch 274/1200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4343 - accuracy: 0.7951 - val_loss: 0.5328 - val_accuracy: 0.7396\n",
            "Epoch 275/1200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4340 - accuracy: 0.7917 - val_loss: 0.5330 - val_accuracy: 0.7500\n",
            "Epoch 276/1200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4337 - accuracy: 0.7917 - val_loss: 0.5331 - val_accuracy: 0.7500\n",
            "Epoch 277/1200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4337 - accuracy: 0.7917 - val_loss: 0.5332 - val_accuracy: 0.7500\n",
            "Epoch 278/1200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4334 - accuracy: 0.7917 - val_loss: 0.5333 - val_accuracy: 0.7500\n",
            "Epoch 279/1200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4334 - accuracy: 0.7917 - val_loss: 0.5335 - val_accuracy: 0.7500\n",
            "Epoch 280/1200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4333 - accuracy: 0.7899 - val_loss: 0.5336 - val_accuracy: 0.7500\n",
            "Epoch 281/1200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4331 - accuracy: 0.7951 - val_loss: 0.5338 - val_accuracy: 0.7500\n",
            "Epoch 282/1200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4330 - accuracy: 0.7969 - val_loss: 0.5338 - val_accuracy: 0.7500\n",
            "Epoch 283/1200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4329 - accuracy: 0.7951 - val_loss: 0.5340 - val_accuracy: 0.7500\n",
            "Epoch 284/1200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4327 - accuracy: 0.7986 - val_loss: 0.5342 - val_accuracy: 0.7500\n",
            "Epoch 285/1200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4324 - accuracy: 0.7934 - val_loss: 0.5340 - val_accuracy: 0.7448\n",
            "Epoch 286/1200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4322 - accuracy: 0.7934 - val_loss: 0.5340 - val_accuracy: 0.7448\n",
            "Epoch 287/1200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4320 - accuracy: 0.8003 - val_loss: 0.5341 - val_accuracy: 0.7500\n",
            "Epoch 288/1200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4318 - accuracy: 0.7969 - val_loss: 0.5342 - val_accuracy: 0.7500\n",
            "Epoch 289/1200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4317 - accuracy: 0.7969 - val_loss: 0.5344 - val_accuracy: 0.7500\n",
            "Epoch 290/1200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4317 - accuracy: 0.8003 - val_loss: 0.5344 - val_accuracy: 0.7500\n",
            "Epoch 291/1200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4317 - accuracy: 0.8003 - val_loss: 0.5346 - val_accuracy: 0.7500\n",
            "Epoch 292/1200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4312 - accuracy: 0.8021 - val_loss: 0.5346 - val_accuracy: 0.7500\n",
            "Epoch 293/1200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4313 - accuracy: 0.8003 - val_loss: 0.5345 - val_accuracy: 0.7500\n",
            "Epoch 294/1200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4309 - accuracy: 0.8003 - val_loss: 0.5345 - val_accuracy: 0.7500\n",
            "Epoch 295/1200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4310 - accuracy: 0.8021 - val_loss: 0.5345 - val_accuracy: 0.7500\n",
            "Epoch 296/1200\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4306 - accuracy: 0.8038 - val_loss: 0.5347 - val_accuracy: 0.7500\n",
            "Epoch 297/1200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4305 - accuracy: 0.8021 - val_loss: 0.5347 - val_accuracy: 0.7500\n",
            "Epoch 298/1200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4303 - accuracy: 0.7986 - val_loss: 0.5348 - val_accuracy: 0.7500\n",
            "Epoch 299/1200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4301 - accuracy: 0.8021 - val_loss: 0.5348 - val_accuracy: 0.7500\n",
            "Epoch 300/1200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4300 - accuracy: 0.8073 - val_loss: 0.5350 - val_accuracy: 0.7500\n",
            "Epoch 301/1200\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4299 - accuracy: 0.8003 - val_loss: 0.5351 - val_accuracy: 0.7500\n",
            "Epoch 302/1200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4296 - accuracy: 0.8021 - val_loss: 0.5352 - val_accuracy: 0.7500\n",
            "Epoch 303/1200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4295 - accuracy: 0.8038 - val_loss: 0.5353 - val_accuracy: 0.7500\n",
            "Epoch 304/1200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4294 - accuracy: 0.8073 - val_loss: 0.5354 - val_accuracy: 0.7500\n",
            "Epoch 305/1200\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.4293 - accuracy: 0.8038 - val_loss: 0.5353 - val_accuracy: 0.7500\n",
            "Epoch 306/1200\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.4290 - accuracy: 0.8003 - val_loss: 0.5354 - val_accuracy: 0.7500\n",
            "Epoch 307/1200\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4287 - accuracy: 0.8021 - val_loss: 0.5354 - val_accuracy: 0.7500\n",
            "Epoch 308/1200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4286 - accuracy: 0.8073 - val_loss: 0.5354 - val_accuracy: 0.7500\n",
            "Epoch 309/1200\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.4285 - accuracy: 0.8056 - val_loss: 0.5356 - val_accuracy: 0.7500\n",
            "Epoch 310/1200\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.4285 - accuracy: 0.8056 - val_loss: 0.5354 - val_accuracy: 0.7552\n",
            "Epoch 311/1200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4282 - accuracy: 0.8038 - val_loss: 0.5354 - val_accuracy: 0.7552\n",
            "Epoch 312/1200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4279 - accuracy: 0.8090 - val_loss: 0.5357 - val_accuracy: 0.7500\n",
            "Epoch 313/1200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4278 - accuracy: 0.8073 - val_loss: 0.5355 - val_accuracy: 0.7552\n",
            "Epoch 314/1200\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.4278 - accuracy: 0.8142 - val_loss: 0.5357 - val_accuracy: 0.7500\n",
            "Epoch 315/1200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4275 - accuracy: 0.8056 - val_loss: 0.5359 - val_accuracy: 0.7500\n",
            "Epoch 316/1200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4277 - accuracy: 0.8073 - val_loss: 0.5360 - val_accuracy: 0.7500\n",
            "Epoch 317/1200\n",
            "18/18 [==============================] - 0s 12ms/step - loss: 0.4272 - accuracy: 0.8108 - val_loss: 0.5360 - val_accuracy: 0.7500\n",
            "Epoch 318/1200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4270 - accuracy: 0.8090 - val_loss: 0.5362 - val_accuracy: 0.7448\n",
            "Epoch 319/1200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4269 - accuracy: 0.8073 - val_loss: 0.5363 - val_accuracy: 0.7448\n",
            "Epoch 320/1200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4268 - accuracy: 0.8056 - val_loss: 0.5362 - val_accuracy: 0.7500\n",
            "Epoch 321/1200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4267 - accuracy: 0.8073 - val_loss: 0.5362 - val_accuracy: 0.7500\n",
            "Epoch 322/1200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4267 - accuracy: 0.8090 - val_loss: 0.5362 - val_accuracy: 0.7500\n",
            "Epoch 323/1200\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4263 - accuracy: 0.8056 - val_loss: 0.5361 - val_accuracy: 0.7500\n",
            "Epoch 324/1200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4265 - accuracy: 0.8073 - val_loss: 0.5362 - val_accuracy: 0.7500\n",
            "Epoch 325/1200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4260 - accuracy: 0.8108 - val_loss: 0.5364 - val_accuracy: 0.7500\n",
            "Epoch 326/1200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4258 - accuracy: 0.8108 - val_loss: 0.5366 - val_accuracy: 0.7500\n",
            "Epoch 327/1200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4256 - accuracy: 0.8090 - val_loss: 0.5366 - val_accuracy: 0.7500\n",
            "Epoch 328/1200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4253 - accuracy: 0.8090 - val_loss: 0.5364 - val_accuracy: 0.7500\n",
            "Epoch 329/1200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4252 - accuracy: 0.8142 - val_loss: 0.5366 - val_accuracy: 0.7500\n",
            "Epoch 330/1200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4250 - accuracy: 0.8125 - val_loss: 0.5368 - val_accuracy: 0.7500\n",
            "Epoch 331/1200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4250 - accuracy: 0.8073 - val_loss: 0.5368 - val_accuracy: 0.7500\n",
            "Epoch 332/1200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4248 - accuracy: 0.8108 - val_loss: 0.5369 - val_accuracy: 0.7500\n",
            "Epoch 333/1200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4248 - accuracy: 0.8090 - val_loss: 0.5370 - val_accuracy: 0.7500\n",
            "Epoch 334/1200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4245 - accuracy: 0.8090 - val_loss: 0.5372 - val_accuracy: 0.7552\n",
            "Epoch 335/1200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4245 - accuracy: 0.8090 - val_loss: 0.5371 - val_accuracy: 0.7552\n",
            "Epoch 336/1200\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4242 - accuracy: 0.8160 - val_loss: 0.5371 - val_accuracy: 0.7552\n",
            "Epoch 337/1200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4241 - accuracy: 0.8125 - val_loss: 0.5371 - val_accuracy: 0.7552\n",
            "Epoch 338/1200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4242 - accuracy: 0.8073 - val_loss: 0.5372 - val_accuracy: 0.7552\n",
            "Epoch 339/1200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4238 - accuracy: 0.8125 - val_loss: 0.5374 - val_accuracy: 0.7552\n",
            "Epoch 340/1200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4239 - accuracy: 0.8142 - val_loss: 0.5376 - val_accuracy: 0.7552\n",
            "Epoch 341/1200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4235 - accuracy: 0.8125 - val_loss: 0.5378 - val_accuracy: 0.7552\n",
            "Epoch 342/1200\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4233 - accuracy: 0.8142 - val_loss: 0.5381 - val_accuracy: 0.7552\n",
            "Epoch 343/1200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4231 - accuracy: 0.8125 - val_loss: 0.5379 - val_accuracy: 0.7552\n",
            "Epoch 344/1200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4233 - accuracy: 0.8125 - val_loss: 0.5381 - val_accuracy: 0.7552\n",
            "Epoch 345/1200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4228 - accuracy: 0.8142 - val_loss: 0.5382 - val_accuracy: 0.7552\n",
            "Epoch 346/1200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4226 - accuracy: 0.8125 - val_loss: 0.5383 - val_accuracy: 0.7552\n",
            "Epoch 347/1200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4227 - accuracy: 0.8125 - val_loss: 0.5386 - val_accuracy: 0.7500\n",
            "Epoch 348/1200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4230 - accuracy: 0.8073 - val_loss: 0.5386 - val_accuracy: 0.7500\n",
            "Epoch 349/1200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4226 - accuracy: 0.8073 - val_loss: 0.5386 - val_accuracy: 0.7500\n",
            "Epoch 350/1200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4222 - accuracy: 0.8108 - val_loss: 0.5388 - val_accuracy: 0.7500\n",
            "Epoch 351/1200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4221 - accuracy: 0.8073 - val_loss: 0.5390 - val_accuracy: 0.7500\n",
            "Epoch 352/1200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4219 - accuracy: 0.8125 - val_loss: 0.5388 - val_accuracy: 0.7448\n",
            "Epoch 353/1200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4215 - accuracy: 0.8090 - val_loss: 0.5391 - val_accuracy: 0.7448\n",
            "Epoch 354/1200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4217 - accuracy: 0.8090 - val_loss: 0.5391 - val_accuracy: 0.7448\n",
            "Epoch 355/1200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4217 - accuracy: 0.8073 - val_loss: 0.5395 - val_accuracy: 0.7552\n",
            "Epoch 356/1200\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4210 - accuracy: 0.8090 - val_loss: 0.5392 - val_accuracy: 0.7448\n",
            "Epoch 357/1200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4209 - accuracy: 0.8073 - val_loss: 0.5391 - val_accuracy: 0.7448\n",
            "Epoch 358/1200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4209 - accuracy: 0.8073 - val_loss: 0.5389 - val_accuracy: 0.7500\n",
            "Epoch 359/1200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4208 - accuracy: 0.8090 - val_loss: 0.5389 - val_accuracy: 0.7500\n",
            "Epoch 360/1200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4206 - accuracy: 0.8038 - val_loss: 0.5388 - val_accuracy: 0.7500\n",
            "Epoch 361/1200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4208 - accuracy: 0.8073 - val_loss: 0.5390 - val_accuracy: 0.7500\n",
            "Epoch 362/1200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4202 - accuracy: 0.8090 - val_loss: 0.5388 - val_accuracy: 0.7500\n",
            "Epoch 363/1200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4203 - accuracy: 0.8056 - val_loss: 0.5388 - val_accuracy: 0.7500\n",
            "Epoch 364/1200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4200 - accuracy: 0.8090 - val_loss: 0.5389 - val_accuracy: 0.7500\n",
            "Epoch 365/1200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4199 - accuracy: 0.8090 - val_loss: 0.5391 - val_accuracy: 0.7500\n",
            "Epoch 366/1200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4195 - accuracy: 0.8090 - val_loss: 0.5391 - val_accuracy: 0.7500\n",
            "Epoch 367/1200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4194 - accuracy: 0.8056 - val_loss: 0.5388 - val_accuracy: 0.7500\n",
            "Epoch 368/1200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4194 - accuracy: 0.8073 - val_loss: 0.5387 - val_accuracy: 0.7500\n",
            "Epoch 369/1200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4190 - accuracy: 0.8073 - val_loss: 0.5385 - val_accuracy: 0.7500\n",
            "Epoch 370/1200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4189 - accuracy: 0.8038 - val_loss: 0.5388 - val_accuracy: 0.7500\n",
            "Epoch 371/1200\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4187 - accuracy: 0.8073 - val_loss: 0.5389 - val_accuracy: 0.7500\n",
            "Epoch 372/1200\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4185 - accuracy: 0.8073 - val_loss: 0.5386 - val_accuracy: 0.7500\n",
            "Epoch 373/1200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4183 - accuracy: 0.8056 - val_loss: 0.5385 - val_accuracy: 0.7448\n",
            "Epoch 374/1200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4181 - accuracy: 0.8090 - val_loss: 0.5386 - val_accuracy: 0.7500\n",
            "Epoch 375/1200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4182 - accuracy: 0.8073 - val_loss: 0.5385 - val_accuracy: 0.7500\n",
            "Epoch 376/1200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4180 - accuracy: 0.8073 - val_loss: 0.5387 - val_accuracy: 0.7500\n",
            "Epoch 377/1200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4179 - accuracy: 0.8090 - val_loss: 0.5387 - val_accuracy: 0.7500\n",
            "Epoch 378/1200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4176 - accuracy: 0.8038 - val_loss: 0.5388 - val_accuracy: 0.7500\n",
            "Epoch 379/1200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4177 - accuracy: 0.8056 - val_loss: 0.5390 - val_accuracy: 0.7396\n",
            "Epoch 380/1200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4172 - accuracy: 0.8073 - val_loss: 0.5387 - val_accuracy: 0.7500\n",
            "Epoch 381/1200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4173 - accuracy: 0.8038 - val_loss: 0.5389 - val_accuracy: 0.7448\n",
            "Epoch 382/1200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4169 - accuracy: 0.8073 - val_loss: 0.5389 - val_accuracy: 0.7448\n",
            "Epoch 383/1200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4170 - accuracy: 0.8056 - val_loss: 0.5391 - val_accuracy: 0.7396\n",
            "Epoch 384/1200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4170 - accuracy: 0.8073 - val_loss: 0.5391 - val_accuracy: 0.7396\n",
            "Epoch 385/1200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4168 - accuracy: 0.8073 - val_loss: 0.5390 - val_accuracy: 0.7448\n",
            "Epoch 386/1200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4165 - accuracy: 0.8056 - val_loss: 0.5388 - val_accuracy: 0.7448\n",
            "Epoch 387/1200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4164 - accuracy: 0.8056 - val_loss: 0.5389 - val_accuracy: 0.7448\n",
            "Epoch 388/1200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4160 - accuracy: 0.8056 - val_loss: 0.5388 - val_accuracy: 0.7448\n",
            "Epoch 389/1200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4160 - accuracy: 0.8038 - val_loss: 0.5393 - val_accuracy: 0.7448\n",
            "Epoch 390/1200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4156 - accuracy: 0.8073 - val_loss: 0.5389 - val_accuracy: 0.7448\n",
            "Epoch 391/1200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4157 - accuracy: 0.8056 - val_loss: 0.5389 - val_accuracy: 0.7448\n",
            "Epoch 392/1200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4154 - accuracy: 0.8090 - val_loss: 0.5393 - val_accuracy: 0.7500\n",
            "Epoch 393/1200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4154 - accuracy: 0.8073 - val_loss: 0.5394 - val_accuracy: 0.7500\n",
            "Epoch 394/1200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4152 - accuracy: 0.8021 - val_loss: 0.5395 - val_accuracy: 0.7448\n",
            "Epoch 395/1200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4152 - accuracy: 0.8125 - val_loss: 0.5396 - val_accuracy: 0.7448\n",
            "Epoch 396/1200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4149 - accuracy: 0.8056 - val_loss: 0.5391 - val_accuracy: 0.7448\n",
            "Epoch 397/1200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4148 - accuracy: 0.8073 - val_loss: 0.5391 - val_accuracy: 0.7448\n",
            "Epoch 398/1200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4146 - accuracy: 0.8073 - val_loss: 0.5388 - val_accuracy: 0.7448\n",
            "Epoch 399/1200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4143 - accuracy: 0.8056 - val_loss: 0.5391 - val_accuracy: 0.7448\n",
            "Epoch 400/1200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4141 - accuracy: 0.8038 - val_loss: 0.5390 - val_accuracy: 0.7448\n",
            "Epoch 401/1200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4145 - accuracy: 0.8038 - val_loss: 0.5389 - val_accuracy: 0.7448\n",
            "Epoch 402/1200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4139 - accuracy: 0.8038 - val_loss: 0.5386 - val_accuracy: 0.7448\n",
            "Epoch 403/1200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4136 - accuracy: 0.8108 - val_loss: 0.5379 - val_accuracy: 0.7448\n",
            "Epoch 404/1200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4134 - accuracy: 0.8090 - val_loss: 0.5381 - val_accuracy: 0.7448\n",
            "Epoch 405/1200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4132 - accuracy: 0.8038 - val_loss: 0.5378 - val_accuracy: 0.7448\n",
            "Epoch 406/1200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4129 - accuracy: 0.8038 - val_loss: 0.5380 - val_accuracy: 0.7448\n",
            "Epoch 407/1200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4129 - accuracy: 0.8056 - val_loss: 0.5380 - val_accuracy: 0.7448\n",
            "Epoch 408/1200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4125 - accuracy: 0.8056 - val_loss: 0.5376 - val_accuracy: 0.7448\n",
            "Epoch 409/1200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4122 - accuracy: 0.8073 - val_loss: 0.5376 - val_accuracy: 0.7448\n",
            "Epoch 410/1200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4123 - accuracy: 0.8073 - val_loss: 0.5374 - val_accuracy: 0.7448\n",
            "Epoch 411/1200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4121 - accuracy: 0.8056 - val_loss: 0.5376 - val_accuracy: 0.7448\n",
            "Epoch 412/1200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4118 - accuracy: 0.8073 - val_loss: 0.5381 - val_accuracy: 0.7448\n",
            "Epoch 413/1200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4116 - accuracy: 0.8073 - val_loss: 0.5380 - val_accuracy: 0.7448\n",
            "Epoch 414/1200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4114 - accuracy: 0.8073 - val_loss: 0.5383 - val_accuracy: 0.7448\n",
            "Epoch 415/1200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4113 - accuracy: 0.8021 - val_loss: 0.5383 - val_accuracy: 0.7448\n",
            "Epoch 416/1200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4112 - accuracy: 0.8056 - val_loss: 0.5383 - val_accuracy: 0.7448\n",
            "Epoch 417/1200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4110 - accuracy: 0.8073 - val_loss: 0.5384 - val_accuracy: 0.7448\n",
            "Epoch 418/1200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4109 - accuracy: 0.8056 - val_loss: 0.5386 - val_accuracy: 0.7448\n",
            "Epoch 419/1200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4107 - accuracy: 0.8090 - val_loss: 0.5386 - val_accuracy: 0.7448\n",
            "Epoch 420/1200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4108 - accuracy: 0.8073 - val_loss: 0.5387 - val_accuracy: 0.7448\n",
            "Epoch 421/1200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4104 - accuracy: 0.8090 - val_loss: 0.5387 - val_accuracy: 0.7448\n",
            "Epoch 422/1200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4103 - accuracy: 0.8073 - val_loss: 0.5387 - val_accuracy: 0.7448\n",
            "Epoch 423/1200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4105 - accuracy: 0.8056 - val_loss: 0.5386 - val_accuracy: 0.7448\n",
            "Epoch 424/1200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4102 - accuracy: 0.8056 - val_loss: 0.5391 - val_accuracy: 0.7448\n",
            "Epoch 425/1200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4098 - accuracy: 0.8090 - val_loss: 0.5392 - val_accuracy: 0.7448\n",
            "Epoch 426/1200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4096 - accuracy: 0.8090 - val_loss: 0.5398 - val_accuracy: 0.7448\n",
            "Epoch 427/1200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4093 - accuracy: 0.8073 - val_loss: 0.5398 - val_accuracy: 0.7448\n",
            "Epoch 428/1200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4091 - accuracy: 0.8090 - val_loss: 0.5406 - val_accuracy: 0.7396\n",
            "Epoch 429/1200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4090 - accuracy: 0.8108 - val_loss: 0.5408 - val_accuracy: 0.7396\n",
            "Epoch 430/1200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4089 - accuracy: 0.8073 - val_loss: 0.5406 - val_accuracy: 0.7396\n",
            "Epoch 431/1200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4085 - accuracy: 0.8073 - val_loss: 0.5403 - val_accuracy: 0.7448\n",
            "Epoch 432/1200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4084 - accuracy: 0.8056 - val_loss: 0.5410 - val_accuracy: 0.7396\n",
            "Epoch 433/1200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4083 - accuracy: 0.8056 - val_loss: 0.5413 - val_accuracy: 0.7396\n",
            "Epoch 434/1200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4082 - accuracy: 0.8038 - val_loss: 0.5412 - val_accuracy: 0.7396\n",
            "Epoch 435/1200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4080 - accuracy: 0.8090 - val_loss: 0.5411 - val_accuracy: 0.7344\n",
            "Epoch 436/1200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4080 - accuracy: 0.8073 - val_loss: 0.5409 - val_accuracy: 0.7344\n",
            "Epoch 437/1200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4075 - accuracy: 0.8073 - val_loss: 0.5414 - val_accuracy: 0.7344\n",
            "Epoch 438/1200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4074 - accuracy: 0.8125 - val_loss: 0.5422 - val_accuracy: 0.7344\n",
            "Epoch 439/1200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4075 - accuracy: 0.8056 - val_loss: 0.5422 - val_accuracy: 0.7344\n",
            "Epoch 440/1200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4072 - accuracy: 0.8090 - val_loss: 0.5424 - val_accuracy: 0.7344\n",
            "Epoch 441/1200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4066 - accuracy: 0.8108 - val_loss: 0.5426 - val_accuracy: 0.7344\n",
            "Epoch 442/1200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4070 - accuracy: 0.8073 - val_loss: 0.5425 - val_accuracy: 0.7344\n",
            "Epoch 443/1200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4066 - accuracy: 0.8056 - val_loss: 0.5428 - val_accuracy: 0.7344\n",
            "Epoch 444/1200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4064 - accuracy: 0.8090 - val_loss: 0.5423 - val_accuracy: 0.7344\n",
            "Epoch 445/1200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4061 - accuracy: 0.8090 - val_loss: 0.5429 - val_accuracy: 0.7344\n",
            "Epoch 446/1200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4058 - accuracy: 0.8073 - val_loss: 0.5433 - val_accuracy: 0.7344\n",
            "Epoch 447/1200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4059 - accuracy: 0.8056 - val_loss: 0.5436 - val_accuracy: 0.7344\n",
            "Epoch 448/1200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4055 - accuracy: 0.8056 - val_loss: 0.5431 - val_accuracy: 0.7344\n",
            "Epoch 449/1200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4057 - accuracy: 0.8090 - val_loss: 0.5436 - val_accuracy: 0.7344\n",
            "Epoch 450/1200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4051 - accuracy: 0.8073 - val_loss: 0.5435 - val_accuracy: 0.7344\n",
            "Epoch 451/1200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4051 - accuracy: 0.8056 - val_loss: 0.5433 - val_accuracy: 0.7344\n",
            "Epoch 452/1200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4051 - accuracy: 0.8090 - val_loss: 0.5431 - val_accuracy: 0.7344\n",
            "Epoch 453/1200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4045 - accuracy: 0.8090 - val_loss: 0.5433 - val_accuracy: 0.7344\n",
            "Epoch 454/1200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4044 - accuracy: 0.8125 - val_loss: 0.5435 - val_accuracy: 0.7344\n",
            "Epoch 455/1200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4040 - accuracy: 0.8090 - val_loss: 0.5441 - val_accuracy: 0.7344\n",
            "Epoch 456/1200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4041 - accuracy: 0.8108 - val_loss: 0.5444 - val_accuracy: 0.7344\n",
            "Epoch 457/1200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4039 - accuracy: 0.8090 - val_loss: 0.5441 - val_accuracy: 0.7344\n",
            "Epoch 458/1200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4042 - accuracy: 0.8073 - val_loss: 0.5440 - val_accuracy: 0.7344\n",
            "Epoch 459/1200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4038 - accuracy: 0.8108 - val_loss: 0.5442 - val_accuracy: 0.7344\n",
            "Epoch 460/1200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4033 - accuracy: 0.8125 - val_loss: 0.5442 - val_accuracy: 0.7344\n",
            "Epoch 461/1200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4032 - accuracy: 0.8142 - val_loss: 0.5442 - val_accuracy: 0.7344\n",
            "Epoch 462/1200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4034 - accuracy: 0.8125 - val_loss: 0.5440 - val_accuracy: 0.7344\n",
            "Epoch 463/1200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4027 - accuracy: 0.8125 - val_loss: 0.5446 - val_accuracy: 0.7344\n",
            "Epoch 464/1200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4028 - accuracy: 0.8125 - val_loss: 0.5446 - val_accuracy: 0.7344\n",
            "Epoch 465/1200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4026 - accuracy: 0.8177 - val_loss: 0.5440 - val_accuracy: 0.7396\n",
            "Epoch 466/1200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4023 - accuracy: 0.8125 - val_loss: 0.5439 - val_accuracy: 0.7396\n",
            "Epoch 467/1200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4021 - accuracy: 0.8108 - val_loss: 0.5444 - val_accuracy: 0.7396\n",
            "Epoch 468/1200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4018 - accuracy: 0.8142 - val_loss: 0.5445 - val_accuracy: 0.7396\n",
            "Epoch 469/1200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4019 - accuracy: 0.8125 - val_loss: 0.5447 - val_accuracy: 0.7396\n",
            "Epoch 470/1200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4018 - accuracy: 0.8142 - val_loss: 0.5453 - val_accuracy: 0.7396\n",
            "Epoch 471/1200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4014 - accuracy: 0.8142 - val_loss: 0.5450 - val_accuracy: 0.7396\n",
            "Epoch 472/1200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4013 - accuracy: 0.8177 - val_loss: 0.5451 - val_accuracy: 0.7396\n",
            "Epoch 473/1200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4011 - accuracy: 0.8125 - val_loss: 0.5459 - val_accuracy: 0.7396\n",
            "Epoch 474/1200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4010 - accuracy: 0.8142 - val_loss: 0.5455 - val_accuracy: 0.7396\n",
            "Epoch 475/1200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4009 - accuracy: 0.8160 - val_loss: 0.5467 - val_accuracy: 0.7344\n",
            "Epoch 476/1200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4007 - accuracy: 0.8142 - val_loss: 0.5467 - val_accuracy: 0.7396\n",
            "Epoch 477/1200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4006 - accuracy: 0.8160 - val_loss: 0.5460 - val_accuracy: 0.7396\n",
            "Epoch 478/1200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4001 - accuracy: 0.8160 - val_loss: 0.5466 - val_accuracy: 0.7396\n",
            "Epoch 479/1200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4004 - accuracy: 0.8125 - val_loss: 0.5463 - val_accuracy: 0.7396\n",
            "Epoch 480/1200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3999 - accuracy: 0.8160 - val_loss: 0.5467 - val_accuracy: 0.7396\n",
            "Epoch 481/1200\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3999 - accuracy: 0.8160 - val_loss: 0.5470 - val_accuracy: 0.7396\n",
            "Epoch 482/1200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.3997 - accuracy: 0.8125 - val_loss: 0.5464 - val_accuracy: 0.7396\n",
            "Epoch 483/1200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3996 - accuracy: 0.8177 - val_loss: 0.5466 - val_accuracy: 0.7396\n",
            "Epoch 484/1200\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.3993 - accuracy: 0.8160 - val_loss: 0.5473 - val_accuracy: 0.7396\n",
            "Epoch 485/1200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3994 - accuracy: 0.8177 - val_loss: 0.5471 - val_accuracy: 0.7396\n",
            "Epoch 486/1200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3999 - accuracy: 0.8194 - val_loss: 0.5474 - val_accuracy: 0.7396\n",
            "Epoch 487/1200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3987 - accuracy: 0.8160 - val_loss: 0.5472 - val_accuracy: 0.7396\n",
            "Epoch 488/1200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.3988 - accuracy: 0.8212 - val_loss: 0.5478 - val_accuracy: 0.7396\n",
            "Epoch 489/1200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3986 - accuracy: 0.8142 - val_loss: 0.5479 - val_accuracy: 0.7396\n",
            "Epoch 490/1200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3986 - accuracy: 0.8177 - val_loss: 0.5477 - val_accuracy: 0.7396\n",
            "Epoch 491/1200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3985 - accuracy: 0.8177 - val_loss: 0.5474 - val_accuracy: 0.7396\n",
            "Epoch 492/1200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3984 - accuracy: 0.8212 - val_loss: 0.5475 - val_accuracy: 0.7344\n",
            "Epoch 493/1200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3982 - accuracy: 0.8212 - val_loss: 0.5475 - val_accuracy: 0.7344\n",
            "Epoch 494/1200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3983 - accuracy: 0.8177 - val_loss: 0.5478 - val_accuracy: 0.7344\n",
            "Epoch 495/1200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3987 - accuracy: 0.8229 - val_loss: 0.5482 - val_accuracy: 0.7396\n",
            "Epoch 496/1200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3976 - accuracy: 0.8194 - val_loss: 0.5480 - val_accuracy: 0.7344\n",
            "Epoch 497/1200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3977 - accuracy: 0.8212 - val_loss: 0.5482 - val_accuracy: 0.7396\n",
            "Epoch 498/1200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3974 - accuracy: 0.8247 - val_loss: 0.5477 - val_accuracy: 0.7344\n",
            "Epoch 499/1200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3976 - accuracy: 0.8212 - val_loss: 0.5490 - val_accuracy: 0.7396\n",
            "Epoch 500/1200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3974 - accuracy: 0.8177 - val_loss: 0.5483 - val_accuracy: 0.7344\n",
            "Epoch 501/1200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3972 - accuracy: 0.8212 - val_loss: 0.5489 - val_accuracy: 0.7344\n",
            "Epoch 502/1200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3969 - accuracy: 0.8229 - val_loss: 0.5490 - val_accuracy: 0.7344\n",
            "Epoch 503/1200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.3969 - accuracy: 0.8212 - val_loss: 0.5501 - val_accuracy: 0.7396\n",
            "Epoch 504/1200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3968 - accuracy: 0.8247 - val_loss: 0.5499 - val_accuracy: 0.7396\n",
            "Epoch 505/1200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3970 - accuracy: 0.8212 - val_loss: 0.5494 - val_accuracy: 0.7396\n",
            "Epoch 506/1200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3965 - accuracy: 0.8247 - val_loss: 0.5498 - val_accuracy: 0.7344\n",
            "Epoch 507/1200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3964 - accuracy: 0.8194 - val_loss: 0.5503 - val_accuracy: 0.7344\n",
            "Epoch 508/1200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3965 - accuracy: 0.8264 - val_loss: 0.5488 - val_accuracy: 0.7396\n",
            "Epoch 509/1200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3961 - accuracy: 0.8194 - val_loss: 0.5497 - val_accuracy: 0.7344\n",
            "Epoch 510/1200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3959 - accuracy: 0.8229 - val_loss: 0.5494 - val_accuracy: 0.7344\n",
            "Epoch 511/1200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3960 - accuracy: 0.8194 - val_loss: 0.5501 - val_accuracy: 0.7344\n",
            "Epoch 512/1200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3960 - accuracy: 0.8247 - val_loss: 0.5499 - val_accuracy: 0.7344\n",
            "Epoch 513/1200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3954 - accuracy: 0.8247 - val_loss: 0.5502 - val_accuracy: 0.7292\n",
            "Epoch 514/1200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3954 - accuracy: 0.8212 - val_loss: 0.5512 - val_accuracy: 0.7292\n",
            "Epoch 515/1200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3954 - accuracy: 0.8212 - val_loss: 0.5511 - val_accuracy: 0.7292\n",
            "Epoch 516/1200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3954 - accuracy: 0.8229 - val_loss: 0.5511 - val_accuracy: 0.7292\n",
            "Epoch 517/1200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3955 - accuracy: 0.8247 - val_loss: 0.5506 - val_accuracy: 0.7344\n",
            "Epoch 518/1200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3950 - accuracy: 0.8229 - val_loss: 0.5519 - val_accuracy: 0.7292\n",
            "Epoch 519/1200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.3945 - accuracy: 0.8229 - val_loss: 0.5523 - val_accuracy: 0.7292\n",
            "Epoch 520/1200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3948 - accuracy: 0.8264 - val_loss: 0.5520 - val_accuracy: 0.7292\n",
            "Epoch 521/1200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3946 - accuracy: 0.8212 - val_loss: 0.5522 - val_accuracy: 0.7292\n",
            "Epoch 522/1200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3946 - accuracy: 0.8229 - val_loss: 0.5531 - val_accuracy: 0.7344\n",
            "Epoch 523/1200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.3941 - accuracy: 0.8247 - val_loss: 0.5527 - val_accuracy: 0.7292\n",
            "Epoch 524/1200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3942 - accuracy: 0.8212 - val_loss: 0.5533 - val_accuracy: 0.7344\n",
            "Epoch 525/1200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3939 - accuracy: 0.8264 - val_loss: 0.5528 - val_accuracy: 0.7292\n",
            "Epoch 526/1200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3936 - accuracy: 0.8194 - val_loss: 0.5541 - val_accuracy: 0.7292\n",
            "Epoch 527/1200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3937 - accuracy: 0.8264 - val_loss: 0.5534 - val_accuracy: 0.7344\n",
            "Epoch 528/1200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3933 - accuracy: 0.8247 - val_loss: 0.5538 - val_accuracy: 0.7292\n",
            "Epoch 529/1200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3935 - accuracy: 0.8281 - val_loss: 0.5538 - val_accuracy: 0.7344\n",
            "Epoch 530/1200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3936 - accuracy: 0.8212 - val_loss: 0.5531 - val_accuracy: 0.7344\n",
            "Epoch 531/1200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3931 - accuracy: 0.8194 - val_loss: 0.5536 - val_accuracy: 0.7344\n",
            "Epoch 532/1200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3928 - accuracy: 0.8229 - val_loss: 0.5545 - val_accuracy: 0.7344\n",
            "Epoch 533/1200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3928 - accuracy: 0.8212 - val_loss: 0.5552 - val_accuracy: 0.7292\n",
            "Epoch 534/1200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3927 - accuracy: 0.8247 - val_loss: 0.5552 - val_accuracy: 0.7292\n",
            "Epoch 535/1200\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3924 - accuracy: 0.8247 - val_loss: 0.5544 - val_accuracy: 0.7396\n",
            "Epoch 536/1200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3920 - accuracy: 0.8229 - val_loss: 0.5554 - val_accuracy: 0.7292\n",
            "Epoch 537/1200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3923 - accuracy: 0.8229 - val_loss: 0.5555 - val_accuracy: 0.7292\n",
            "Epoch 538/1200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3919 - accuracy: 0.8247 - val_loss: 0.5570 - val_accuracy: 0.7292\n",
            "Epoch 539/1200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3920 - accuracy: 0.8212 - val_loss: 0.5561 - val_accuracy: 0.7292\n",
            "Epoch 540/1200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3917 - accuracy: 0.8229 - val_loss: 0.5557 - val_accuracy: 0.7396\n",
            "Epoch 541/1200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3916 - accuracy: 0.8247 - val_loss: 0.5555 - val_accuracy: 0.7292\n",
            "Epoch 542/1200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3915 - accuracy: 0.8229 - val_loss: 0.5560 - val_accuracy: 0.7344\n",
            "Epoch 543/1200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3921 - accuracy: 0.8247 - val_loss: 0.5555 - val_accuracy: 0.7448\n",
            "Epoch 544/1200\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3914 - accuracy: 0.8229 - val_loss: 0.5564 - val_accuracy: 0.7396\n",
            "Epoch 545/1200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3910 - accuracy: 0.8229 - val_loss: 0.5559 - val_accuracy: 0.7448\n",
            "Epoch 546/1200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3908 - accuracy: 0.8229 - val_loss: 0.5560 - val_accuracy: 0.7396\n",
            "Epoch 547/1200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3905 - accuracy: 0.8229 - val_loss: 0.5572 - val_accuracy: 0.7396\n",
            "Epoch 548/1200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3904 - accuracy: 0.8264 - val_loss: 0.5579 - val_accuracy: 0.7344\n",
            "Epoch 549/1200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3913 - accuracy: 0.8229 - val_loss: 0.5573 - val_accuracy: 0.7396\n",
            "Epoch 550/1200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3902 - accuracy: 0.8229 - val_loss: 0.5570 - val_accuracy: 0.7396\n",
            "Epoch 551/1200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3902 - accuracy: 0.8247 - val_loss: 0.5576 - val_accuracy: 0.7396\n",
            "Epoch 552/1200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3900 - accuracy: 0.8229 - val_loss: 0.5582 - val_accuracy: 0.7344\n",
            "Epoch 553/1200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3904 - accuracy: 0.8229 - val_loss: 0.5586 - val_accuracy: 0.7344\n",
            "Epoch 554/1200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.3900 - accuracy: 0.8212 - val_loss: 0.5576 - val_accuracy: 0.7396\n",
            "Epoch 555/1200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3897 - accuracy: 0.8264 - val_loss: 0.5568 - val_accuracy: 0.7396\n",
            "Epoch 556/1200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3895 - accuracy: 0.8247 - val_loss: 0.5586 - val_accuracy: 0.7396\n",
            "Epoch 557/1200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3892 - accuracy: 0.8229 - val_loss: 0.5590 - val_accuracy: 0.7396\n",
            "Epoch 558/1200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3893 - accuracy: 0.8264 - val_loss: 0.5588 - val_accuracy: 0.7396\n",
            "Epoch 559/1200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3893 - accuracy: 0.8247 - val_loss: 0.5591 - val_accuracy: 0.7396\n",
            "Epoch 560/1200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3890 - accuracy: 0.8229 - val_loss: 0.5595 - val_accuracy: 0.7396\n",
            "Epoch 561/1200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3894 - accuracy: 0.8264 - val_loss: 0.5585 - val_accuracy: 0.7396\n",
            "Epoch 562/1200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3886 - accuracy: 0.8229 - val_loss: 0.5591 - val_accuracy: 0.7396\n",
            "Epoch 563/1200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3887 - accuracy: 0.8264 - val_loss: 0.5601 - val_accuracy: 0.7344\n",
            "Epoch 564/1200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3887 - accuracy: 0.8247 - val_loss: 0.5598 - val_accuracy: 0.7396\n",
            "Epoch 565/1200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3885 - accuracy: 0.8229 - val_loss: 0.5594 - val_accuracy: 0.7396\n",
            "Epoch 566/1200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3884 - accuracy: 0.8229 - val_loss: 0.5589 - val_accuracy: 0.7396\n",
            "Epoch 567/1200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3883 - accuracy: 0.8247 - val_loss: 0.5591 - val_accuracy: 0.7396\n",
            "Epoch 568/1200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3883 - accuracy: 0.8229 - val_loss: 0.5593 - val_accuracy: 0.7396\n",
            "Epoch 569/1200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3882 - accuracy: 0.8212 - val_loss: 0.5591 - val_accuracy: 0.7396\n",
            "Epoch 570/1200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3880 - accuracy: 0.8229 - val_loss: 0.5597 - val_accuracy: 0.7396\n",
            "Epoch 571/1200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3878 - accuracy: 0.8229 - val_loss: 0.5592 - val_accuracy: 0.7396\n",
            "Epoch 572/1200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3878 - accuracy: 0.8247 - val_loss: 0.5598 - val_accuracy: 0.7396\n",
            "Epoch 573/1200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3880 - accuracy: 0.8229 - val_loss: 0.5598 - val_accuracy: 0.7396\n",
            "Epoch 574/1200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3874 - accuracy: 0.8229 - val_loss: 0.5621 - val_accuracy: 0.7396\n",
            "Epoch 575/1200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3874 - accuracy: 0.8281 - val_loss: 0.5610 - val_accuracy: 0.7396\n",
            "Epoch 576/1200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3877 - accuracy: 0.8212 - val_loss: 0.5606 - val_accuracy: 0.7396\n",
            "Epoch 577/1200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3872 - accuracy: 0.8264 - val_loss: 0.5612 - val_accuracy: 0.7396\n",
            "Epoch 578/1200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3878 - accuracy: 0.8247 - val_loss: 0.5616 - val_accuracy: 0.7396\n",
            "Epoch 579/1200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3869 - accuracy: 0.8247 - val_loss: 0.5615 - val_accuracy: 0.7396\n",
            "Epoch 580/1200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3868 - accuracy: 0.8247 - val_loss: 0.5630 - val_accuracy: 0.7344\n",
            "Epoch 581/1200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3866 - accuracy: 0.8264 - val_loss: 0.5629 - val_accuracy: 0.7396\n",
            "Epoch 582/1200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3867 - accuracy: 0.8264 - val_loss: 0.5627 - val_accuracy: 0.7396\n",
            "Epoch 583/1200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3868 - accuracy: 0.8264 - val_loss: 0.5622 - val_accuracy: 0.7396\n",
            "Epoch 584/1200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3864 - accuracy: 0.8247 - val_loss: 0.5616 - val_accuracy: 0.7396\n",
            "Epoch 585/1200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3865 - accuracy: 0.8264 - val_loss: 0.5615 - val_accuracy: 0.7396\n",
            "Epoch 586/1200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3864 - accuracy: 0.8316 - val_loss: 0.5620 - val_accuracy: 0.7396\n",
            "Epoch 587/1200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3860 - accuracy: 0.8247 - val_loss: 0.5620 - val_accuracy: 0.7396\n",
            "Epoch 588/1200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3858 - accuracy: 0.8299 - val_loss: 0.5633 - val_accuracy: 0.7396\n",
            "Epoch 589/1200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3862 - accuracy: 0.8264 - val_loss: 0.5631 - val_accuracy: 0.7396\n",
            "Epoch 590/1200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3858 - accuracy: 0.8264 - val_loss: 0.5622 - val_accuracy: 0.7396\n",
            "Epoch 591/1200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3857 - accuracy: 0.8316 - val_loss: 0.5636 - val_accuracy: 0.7396\n",
            "Epoch 592/1200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3858 - accuracy: 0.8264 - val_loss: 0.5639 - val_accuracy: 0.7396\n",
            "Epoch 593/1200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3859 - accuracy: 0.8264 - val_loss: 0.5632 - val_accuracy: 0.7396\n",
            "Epoch 594/1200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3857 - accuracy: 0.8264 - val_loss: 0.5648 - val_accuracy: 0.7344\n",
            "Epoch 595/1200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3853 - accuracy: 0.8316 - val_loss: 0.5650 - val_accuracy: 0.7344\n",
            "Epoch 596/1200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3854 - accuracy: 0.8281 - val_loss: 0.5649 - val_accuracy: 0.7344\n",
            "Epoch 597/1200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3854 - accuracy: 0.8247 - val_loss: 0.5643 - val_accuracy: 0.7396\n",
            "Epoch 598/1200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3851 - accuracy: 0.8316 - val_loss: 0.5639 - val_accuracy: 0.7396\n",
            "Epoch 599/1200\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.3849 - accuracy: 0.8281 - val_loss: 0.5650 - val_accuracy: 0.7396\n",
            "Epoch 600/1200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3848 - accuracy: 0.8299 - val_loss: 0.5647 - val_accuracy: 0.7396\n",
            "Epoch 601/1200\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.3847 - accuracy: 0.8281 - val_loss: 0.5650 - val_accuracy: 0.7396\n",
            "Epoch 602/1200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3849 - accuracy: 0.8316 - val_loss: 0.5651 - val_accuracy: 0.7396\n",
            "Epoch 603/1200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3847 - accuracy: 0.8316 - val_loss: 0.5658 - val_accuracy: 0.7396\n",
            "Epoch 604/1200\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3845 - accuracy: 0.8229 - val_loss: 0.5667 - val_accuracy: 0.7344\n",
            "Epoch 605/1200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3843 - accuracy: 0.8316 - val_loss: 0.5667 - val_accuracy: 0.7396\n",
            "Epoch 606/1200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3847 - accuracy: 0.8247 - val_loss: 0.5671 - val_accuracy: 0.7396\n",
            "Epoch 607/1200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3844 - accuracy: 0.8281 - val_loss: 0.5671 - val_accuracy: 0.7396\n",
            "Epoch 608/1200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3843 - accuracy: 0.8299 - val_loss: 0.5660 - val_accuracy: 0.7396\n",
            "Epoch 609/1200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.3839 - accuracy: 0.8281 - val_loss: 0.5678 - val_accuracy: 0.7344\n",
            "Epoch 610/1200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3837 - accuracy: 0.8333 - val_loss: 0.5668 - val_accuracy: 0.7396\n",
            "Epoch 611/1200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3844 - accuracy: 0.8299 - val_loss: 0.5670 - val_accuracy: 0.7344\n",
            "Epoch 612/1200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.3843 - accuracy: 0.8281 - val_loss: 0.5663 - val_accuracy: 0.7396\n",
            "Epoch 613/1200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3835 - accuracy: 0.8281 - val_loss: 0.5672 - val_accuracy: 0.7344\n",
            "Epoch 614/1200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.3838 - accuracy: 0.8316 - val_loss: 0.5671 - val_accuracy: 0.7396\n",
            "Epoch 615/1200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.3838 - accuracy: 0.8316 - val_loss: 0.5674 - val_accuracy: 0.7396\n",
            "Epoch 616/1200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.3835 - accuracy: 0.8316 - val_loss: 0.5664 - val_accuracy: 0.7396\n",
            "Epoch 617/1200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3833 - accuracy: 0.8299 - val_loss: 0.5675 - val_accuracy: 0.7396\n",
            "Epoch 618/1200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.3833 - accuracy: 0.8299 - val_loss: 0.5680 - val_accuracy: 0.7396\n",
            "Epoch 619/1200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.3835 - accuracy: 0.8299 - val_loss: 0.5679 - val_accuracy: 0.7396\n",
            "Epoch 620/1200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3830 - accuracy: 0.8316 - val_loss: 0.5695 - val_accuracy: 0.7344\n",
            "Epoch 621/1200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.3831 - accuracy: 0.8333 - val_loss: 0.5698 - val_accuracy: 0.7344\n",
            "Epoch 622/1200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3831 - accuracy: 0.8333 - val_loss: 0.5689 - val_accuracy: 0.7344\n",
            "Epoch 623/1200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3827 - accuracy: 0.8299 - val_loss: 0.5686 - val_accuracy: 0.7396\n",
            "Epoch 624/1200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3831 - accuracy: 0.8385 - val_loss: 0.5699 - val_accuracy: 0.7344\n",
            "Epoch 625/1200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3827 - accuracy: 0.8299 - val_loss: 0.5689 - val_accuracy: 0.7396\n",
            "Epoch 626/1200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3823 - accuracy: 0.8333 - val_loss: 0.5694 - val_accuracy: 0.7344\n",
            "Epoch 627/1200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.3826 - accuracy: 0.8316 - val_loss: 0.5680 - val_accuracy: 0.7448\n",
            "Epoch 628/1200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3823 - accuracy: 0.8316 - val_loss: 0.5688 - val_accuracy: 0.7448\n",
            "Epoch 629/1200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.3822 - accuracy: 0.8316 - val_loss: 0.5702 - val_accuracy: 0.7344\n",
            "Epoch 630/1200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3823 - accuracy: 0.8316 - val_loss: 0.5694 - val_accuracy: 0.7448\n",
            "Epoch 631/1200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.3820 - accuracy: 0.8299 - val_loss: 0.5698 - val_accuracy: 0.7396\n",
            "Epoch 632/1200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.3817 - accuracy: 0.8299 - val_loss: 0.5682 - val_accuracy: 0.7448\n",
            "Epoch 633/1200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3820 - accuracy: 0.8333 - val_loss: 0.5686 - val_accuracy: 0.7448\n",
            "Epoch 634/1200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.3825 - accuracy: 0.8351 - val_loss: 0.5699 - val_accuracy: 0.7344\n",
            "Epoch 635/1200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.3817 - accuracy: 0.8281 - val_loss: 0.5687 - val_accuracy: 0.7448\n",
            "Epoch 636/1200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3813 - accuracy: 0.8299 - val_loss: 0.5691 - val_accuracy: 0.7448\n",
            "Epoch 637/1200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3816 - accuracy: 0.8351 - val_loss: 0.5701 - val_accuracy: 0.7448\n",
            "Epoch 638/1200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3813 - accuracy: 0.8333 - val_loss: 0.5697 - val_accuracy: 0.7448\n",
            "Epoch 639/1200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3814 - accuracy: 0.8333 - val_loss: 0.5696 - val_accuracy: 0.7396\n",
            "Epoch 640/1200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3817 - accuracy: 0.8333 - val_loss: 0.5709 - val_accuracy: 0.7396\n",
            "Epoch 641/1200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.3814 - accuracy: 0.8316 - val_loss: 0.5713 - val_accuracy: 0.7396\n",
            "Epoch 642/1200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.3811 - accuracy: 0.8351 - val_loss: 0.5711 - val_accuracy: 0.7396\n",
            "Epoch 643/1200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3814 - accuracy: 0.8316 - val_loss: 0.5705 - val_accuracy: 0.7396\n",
            "Epoch 644/1200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3814 - accuracy: 0.8351 - val_loss: 0.5710 - val_accuracy: 0.7344\n",
            "Epoch 645/1200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3807 - accuracy: 0.8316 - val_loss: 0.5713 - val_accuracy: 0.7396\n",
            "Epoch 646/1200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3804 - accuracy: 0.8316 - val_loss: 0.5714 - val_accuracy: 0.7396\n",
            "Epoch 647/1200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3812 - accuracy: 0.8299 - val_loss: 0.5717 - val_accuracy: 0.7396\n",
            "Epoch 648/1200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3807 - accuracy: 0.8333 - val_loss: 0.5730 - val_accuracy: 0.7292\n",
            "Epoch 649/1200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3805 - accuracy: 0.8316 - val_loss: 0.5723 - val_accuracy: 0.7396\n",
            "Epoch 650/1200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3801 - accuracy: 0.8299 - val_loss: 0.5700 - val_accuracy: 0.7396\n",
            "Epoch 651/1200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3806 - accuracy: 0.8299 - val_loss: 0.5709 - val_accuracy: 0.7396\n",
            "Epoch 652/1200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3802 - accuracy: 0.8351 - val_loss: 0.5722 - val_accuracy: 0.7396\n",
            "Epoch 653/1200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3802 - accuracy: 0.8333 - val_loss: 0.5716 - val_accuracy: 0.7396\n",
            "Epoch 654/1200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.3801 - accuracy: 0.8333 - val_loss: 0.5720 - val_accuracy: 0.7396\n",
            "Epoch 655/1200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.3801 - accuracy: 0.8351 - val_loss: 0.5726 - val_accuracy: 0.7396\n",
            "Epoch 656/1200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3813 - accuracy: 0.8316 - val_loss: 0.5731 - val_accuracy: 0.7396\n",
            "Epoch 657/1200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.3801 - accuracy: 0.8316 - val_loss: 0.5720 - val_accuracy: 0.7396\n",
            "Epoch 658/1200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.3796 - accuracy: 0.8333 - val_loss: 0.5725 - val_accuracy: 0.7396\n",
            "Epoch 659/1200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3796 - accuracy: 0.8316 - val_loss: 0.5722 - val_accuracy: 0.7396\n",
            "Epoch 660/1200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3795 - accuracy: 0.8351 - val_loss: 0.5724 - val_accuracy: 0.7396\n",
            "Epoch 661/1200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3791 - accuracy: 0.8351 - val_loss: 0.5722 - val_accuracy: 0.7396\n",
            "Epoch 662/1200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.3795 - accuracy: 0.8351 - val_loss: 0.5718 - val_accuracy: 0.7396\n",
            "Epoch 663/1200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3792 - accuracy: 0.8351 - val_loss: 0.5729 - val_accuracy: 0.7396\n",
            "Epoch 664/1200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.3794 - accuracy: 0.8316 - val_loss: 0.5735 - val_accuracy: 0.7396\n",
            "Epoch 665/1200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.3791 - accuracy: 0.8333 - val_loss: 0.5726 - val_accuracy: 0.7344\n",
            "Epoch 666/1200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3792 - accuracy: 0.8333 - val_loss: 0.5725 - val_accuracy: 0.7344\n",
            "Epoch 667/1200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3790 - accuracy: 0.8333 - val_loss: 0.5719 - val_accuracy: 0.7344\n",
            "Epoch 668/1200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.3789 - accuracy: 0.8368 - val_loss: 0.5732 - val_accuracy: 0.7396\n",
            "Epoch 669/1200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3790 - accuracy: 0.8333 - val_loss: 0.5741 - val_accuracy: 0.7396\n",
            "Epoch 670/1200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3785 - accuracy: 0.8333 - val_loss: 0.5741 - val_accuracy: 0.7396\n",
            "Epoch 671/1200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3786 - accuracy: 0.8316 - val_loss: 0.5733 - val_accuracy: 0.7344\n",
            "Epoch 672/1200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3783 - accuracy: 0.8368 - val_loss: 0.5734 - val_accuracy: 0.7396\n",
            "Epoch 673/1200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3785 - accuracy: 0.8351 - val_loss: 0.5734 - val_accuracy: 0.7344\n",
            "Epoch 674/1200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3782 - accuracy: 0.8385 - val_loss: 0.5745 - val_accuracy: 0.7344\n",
            "Epoch 675/1200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.3783 - accuracy: 0.8351 - val_loss: 0.5757 - val_accuracy: 0.7344\n",
            "Epoch 676/1200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3782 - accuracy: 0.8316 - val_loss: 0.5735 - val_accuracy: 0.7344\n",
            "Epoch 677/1200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3783 - accuracy: 0.8333 - val_loss: 0.5745 - val_accuracy: 0.7396\n",
            "Epoch 678/1200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3780 - accuracy: 0.8368 - val_loss: 0.5754 - val_accuracy: 0.7344\n",
            "Epoch 679/1200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3777 - accuracy: 0.8316 - val_loss: 0.5755 - val_accuracy: 0.7344\n",
            "Epoch 680/1200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3782 - accuracy: 0.8333 - val_loss: 0.5763 - val_accuracy: 0.7344\n",
            "Epoch 681/1200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.3782 - accuracy: 0.8316 - val_loss: 0.5751 - val_accuracy: 0.7292\n",
            "Epoch 682/1200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3776 - accuracy: 0.8351 - val_loss: 0.5732 - val_accuracy: 0.7292\n",
            "Epoch 683/1200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.3778 - accuracy: 0.8420 - val_loss: 0.5749 - val_accuracy: 0.7292\n",
            "Epoch 684/1200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.3776 - accuracy: 0.8385 - val_loss: 0.5757 - val_accuracy: 0.7292\n",
            "Epoch 685/1200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.3777 - accuracy: 0.8368 - val_loss: 0.5757 - val_accuracy: 0.7292\n",
            "Epoch 686/1200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3773 - accuracy: 0.8351 - val_loss: 0.5757 - val_accuracy: 0.7292\n",
            "Epoch 687/1200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3771 - accuracy: 0.8351 - val_loss: 0.5740 - val_accuracy: 0.7292\n",
            "Epoch 688/1200\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3772 - accuracy: 0.8368 - val_loss: 0.5746 - val_accuracy: 0.7292\n",
            "Epoch 689/1200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3773 - accuracy: 0.8368 - val_loss: 0.5752 - val_accuracy: 0.7292\n",
            "Epoch 690/1200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3770 - accuracy: 0.8368 - val_loss: 0.5760 - val_accuracy: 0.7292\n",
            "Epoch 691/1200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3768 - accuracy: 0.8351 - val_loss: 0.5753 - val_accuracy: 0.7292\n",
            "Epoch 692/1200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3775 - accuracy: 0.8316 - val_loss: 0.5739 - val_accuracy: 0.7292\n",
            "Epoch 693/1200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3772 - accuracy: 0.8351 - val_loss: 0.5745 - val_accuracy: 0.7292\n",
            "Epoch 694/1200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3768 - accuracy: 0.8403 - val_loss: 0.5744 - val_accuracy: 0.7292\n",
            "Epoch 695/1200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3766 - accuracy: 0.8385 - val_loss: 0.5740 - val_accuracy: 0.7344\n",
            "Epoch 696/1200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.3766 - accuracy: 0.8351 - val_loss: 0.5733 - val_accuracy: 0.7396\n",
            "Epoch 697/1200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3769 - accuracy: 0.8368 - val_loss: 0.5740 - val_accuracy: 0.7292\n",
            "Epoch 698/1200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3764 - accuracy: 0.8368 - val_loss: 0.5760 - val_accuracy: 0.7292\n",
            "Epoch 699/1200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3765 - accuracy: 0.8403 - val_loss: 0.5764 - val_accuracy: 0.7292\n",
            "Epoch 700/1200\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.3765 - accuracy: 0.8368 - val_loss: 0.5772 - val_accuracy: 0.7292\n",
            "Epoch 701/1200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3765 - accuracy: 0.8351 - val_loss: 0.5757 - val_accuracy: 0.7292\n",
            "Epoch 702/1200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3760 - accuracy: 0.8316 - val_loss: 0.5741 - val_accuracy: 0.7344\n",
            "Epoch 703/1200\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.3763 - accuracy: 0.8385 - val_loss: 0.5750 - val_accuracy: 0.7292\n",
            "Epoch 704/1200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3758 - accuracy: 0.8385 - val_loss: 0.5756 - val_accuracy: 0.7292\n",
            "Epoch 705/1200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3757 - accuracy: 0.8385 - val_loss: 0.5749 - val_accuracy: 0.7292\n",
            "Epoch 706/1200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3758 - accuracy: 0.8385 - val_loss: 0.5760 - val_accuracy: 0.7292\n",
            "Epoch 707/1200\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.3757 - accuracy: 0.8403 - val_loss: 0.5761 - val_accuracy: 0.7292\n",
            "Epoch 708/1200\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.3757 - accuracy: 0.8351 - val_loss: 0.5754 - val_accuracy: 0.7292\n",
            "Epoch 709/1200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3755 - accuracy: 0.8368 - val_loss: 0.5750 - val_accuracy: 0.7292\n",
            "Epoch 710/1200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3753 - accuracy: 0.8385 - val_loss: 0.5764 - val_accuracy: 0.7292\n",
            "Epoch 711/1200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3752 - accuracy: 0.8351 - val_loss: 0.5749 - val_accuracy: 0.7292\n",
            "Epoch 712/1200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3752 - accuracy: 0.8385 - val_loss: 0.5758 - val_accuracy: 0.7292\n",
            "Epoch 713/1200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3751 - accuracy: 0.8420 - val_loss: 0.5765 - val_accuracy: 0.7292\n",
            "Epoch 714/1200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3747 - accuracy: 0.8299 - val_loss: 0.5745 - val_accuracy: 0.7292\n",
            "Epoch 715/1200\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3751 - accuracy: 0.8368 - val_loss: 0.5745 - val_accuracy: 0.7292\n",
            "Epoch 716/1200\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.3748 - accuracy: 0.8368 - val_loss: 0.5743 - val_accuracy: 0.7292\n",
            "Epoch 717/1200\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.3752 - accuracy: 0.8420 - val_loss: 0.5759 - val_accuracy: 0.7292\n",
            "Epoch 718/1200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3746 - accuracy: 0.8385 - val_loss: 0.5762 - val_accuracy: 0.7292\n",
            "Epoch 719/1200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3751 - accuracy: 0.8385 - val_loss: 0.5754 - val_accuracy: 0.7292\n",
            "Epoch 720/1200\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3740 - accuracy: 0.8438 - val_loss: 0.5760 - val_accuracy: 0.7292\n",
            "Epoch 721/1200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3744 - accuracy: 0.8385 - val_loss: 0.5754 - val_accuracy: 0.7292\n",
            "Epoch 722/1200\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3743 - accuracy: 0.8385 - val_loss: 0.5753 - val_accuracy: 0.7292\n",
            "Epoch 723/1200\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3742 - accuracy: 0.8420 - val_loss: 0.5757 - val_accuracy: 0.7292\n",
            "Epoch 724/1200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3738 - accuracy: 0.8403 - val_loss: 0.5761 - val_accuracy: 0.7292\n",
            "Epoch 725/1200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3743 - accuracy: 0.8438 - val_loss: 0.5768 - val_accuracy: 0.7240\n",
            "Epoch 726/1200\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3740 - accuracy: 0.8403 - val_loss: 0.5771 - val_accuracy: 0.7292\n",
            "Epoch 727/1200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3740 - accuracy: 0.8385 - val_loss: 0.5764 - val_accuracy: 0.7292\n",
            "Epoch 728/1200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3736 - accuracy: 0.8438 - val_loss: 0.5772 - val_accuracy: 0.7240\n",
            "Epoch 729/1200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3735 - accuracy: 0.8420 - val_loss: 0.5783 - val_accuracy: 0.7240\n",
            "Epoch 730/1200\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3738 - accuracy: 0.8351 - val_loss: 0.5771 - val_accuracy: 0.7292\n",
            "Epoch 731/1200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3733 - accuracy: 0.8385 - val_loss: 0.5764 - val_accuracy: 0.7292\n",
            "Epoch 732/1200\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.3731 - accuracy: 0.8385 - val_loss: 0.5774 - val_accuracy: 0.7240\n",
            "Epoch 733/1200\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.3729 - accuracy: 0.8438 - val_loss: 0.5777 - val_accuracy: 0.7240\n",
            "Epoch 734/1200\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3731 - accuracy: 0.8403 - val_loss: 0.5763 - val_accuracy: 0.7240\n",
            "Epoch 735/1200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3731 - accuracy: 0.8420 - val_loss: 0.5767 - val_accuracy: 0.7240\n",
            "Epoch 736/1200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3727 - accuracy: 0.8368 - val_loss: 0.5786 - val_accuracy: 0.7240\n",
            "Epoch 737/1200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3728 - accuracy: 0.8351 - val_loss: 0.5770 - val_accuracy: 0.7240\n",
            "Epoch 738/1200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.3728 - accuracy: 0.8385 - val_loss: 0.5757 - val_accuracy: 0.7344\n",
            "Epoch 739/1200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3736 - accuracy: 0.8438 - val_loss: 0.5762 - val_accuracy: 0.7344\n",
            "Epoch 740/1200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3730 - accuracy: 0.8385 - val_loss: 0.5769 - val_accuracy: 0.7292\n",
            "Epoch 741/1200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3730 - accuracy: 0.8420 - val_loss: 0.5775 - val_accuracy: 0.7240\n",
            "Epoch 742/1200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.3726 - accuracy: 0.8333 - val_loss: 0.5762 - val_accuracy: 0.7344\n",
            "Epoch 743/1200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3724 - accuracy: 0.8403 - val_loss: 0.5790 - val_accuracy: 0.7240\n",
            "Epoch 744/1200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3722 - accuracy: 0.8385 - val_loss: 0.5778 - val_accuracy: 0.7240\n",
            "Epoch 745/1200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3726 - accuracy: 0.8385 - val_loss: 0.5774 - val_accuracy: 0.7240\n",
            "Epoch 746/1200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3720 - accuracy: 0.8368 - val_loss: 0.5791 - val_accuracy: 0.7240\n",
            "Epoch 747/1200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3728 - accuracy: 0.8455 - val_loss: 0.5805 - val_accuracy: 0.7240\n",
            "Epoch 748/1200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.3719 - accuracy: 0.8368 - val_loss: 0.5794 - val_accuracy: 0.7240\n",
            "Epoch 749/1200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3720 - accuracy: 0.8420 - val_loss: 0.5792 - val_accuracy: 0.7240\n",
            "Epoch 750/1200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.3718 - accuracy: 0.8438 - val_loss: 0.5787 - val_accuracy: 0.7240\n",
            "Epoch 751/1200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3716 - accuracy: 0.8385 - val_loss: 0.5786 - val_accuracy: 0.7240\n",
            "Epoch 752/1200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3719 - accuracy: 0.8385 - val_loss: 0.5787 - val_accuracy: 0.7240\n",
            "Epoch 753/1200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3715 - accuracy: 0.8368 - val_loss: 0.5774 - val_accuracy: 0.7344\n",
            "Epoch 754/1200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.3713 - accuracy: 0.8455 - val_loss: 0.5802 - val_accuracy: 0.7240\n",
            "Epoch 755/1200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3712 - accuracy: 0.8385 - val_loss: 0.5798 - val_accuracy: 0.7240\n",
            "Epoch 756/1200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.3712 - accuracy: 0.8403 - val_loss: 0.5802 - val_accuracy: 0.7240\n",
            "Epoch 757/1200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3715 - accuracy: 0.8385 - val_loss: 0.5803 - val_accuracy: 0.7240\n",
            "Epoch 758/1200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3712 - accuracy: 0.8385 - val_loss: 0.5798 - val_accuracy: 0.7292\n",
            "Epoch 759/1200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3709 - accuracy: 0.8368 - val_loss: 0.5786 - val_accuracy: 0.7396\n",
            "Epoch 760/1200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.3713 - accuracy: 0.8368 - val_loss: 0.5789 - val_accuracy: 0.7344\n",
            "Epoch 761/1200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3705 - accuracy: 0.8403 - val_loss: 0.5774 - val_accuracy: 0.7344\n",
            "Epoch 762/1200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.3712 - accuracy: 0.8368 - val_loss: 0.5791 - val_accuracy: 0.7344\n",
            "Epoch 763/1200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3705 - accuracy: 0.8438 - val_loss: 0.5809 - val_accuracy: 0.7240\n",
            "Epoch 764/1200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3709 - accuracy: 0.8420 - val_loss: 0.5815 - val_accuracy: 0.7240\n",
            "Epoch 765/1200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3710 - accuracy: 0.8385 - val_loss: 0.5812 - val_accuracy: 0.7344\n",
            "Epoch 766/1200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3706 - accuracy: 0.8438 - val_loss: 0.5815 - val_accuracy: 0.7240\n",
            "Epoch 767/1200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3704 - accuracy: 0.8385 - val_loss: 0.5805 - val_accuracy: 0.7344\n",
            "Epoch 768/1200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3702 - accuracy: 0.8420 - val_loss: 0.5802 - val_accuracy: 0.7344\n",
            "Epoch 769/1200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.3705 - accuracy: 0.8403 - val_loss: 0.5814 - val_accuracy: 0.7292\n",
            "Epoch 770/1200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3707 - accuracy: 0.8420 - val_loss: 0.5804 - val_accuracy: 0.7344\n",
            "Epoch 771/1200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3702 - accuracy: 0.8385 - val_loss: 0.5813 - val_accuracy: 0.7344\n",
            "Epoch 772/1200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3699 - accuracy: 0.8438 - val_loss: 0.5800 - val_accuracy: 0.7396\n",
            "Epoch 773/1200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3698 - accuracy: 0.8438 - val_loss: 0.5806 - val_accuracy: 0.7396\n",
            "Epoch 774/1200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3702 - accuracy: 0.8420 - val_loss: 0.5808 - val_accuracy: 0.7396\n",
            "Epoch 775/1200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3698 - accuracy: 0.8403 - val_loss: 0.5796 - val_accuracy: 0.7396\n",
            "Epoch 776/1200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3691 - accuracy: 0.8438 - val_loss: 0.5822 - val_accuracy: 0.7344\n",
            "Epoch 777/1200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3699 - accuracy: 0.8420 - val_loss: 0.5808 - val_accuracy: 0.7396\n",
            "Epoch 778/1200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.3698 - accuracy: 0.8420 - val_loss: 0.5789 - val_accuracy: 0.7396\n",
            "Epoch 779/1200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3691 - accuracy: 0.8420 - val_loss: 0.5808 - val_accuracy: 0.7396\n",
            "Epoch 780/1200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.3697 - accuracy: 0.8472 - val_loss: 0.5808 - val_accuracy: 0.7396\n",
            "Epoch 781/1200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3688 - accuracy: 0.8455 - val_loss: 0.5799 - val_accuracy: 0.7396\n",
            "Epoch 782/1200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3691 - accuracy: 0.8403 - val_loss: 0.5805 - val_accuracy: 0.7396\n",
            "Epoch 783/1200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3687 - accuracy: 0.8490 - val_loss: 0.5828 - val_accuracy: 0.7396\n",
            "Epoch 784/1200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3689 - accuracy: 0.8455 - val_loss: 0.5831 - val_accuracy: 0.7344\n",
            "Epoch 785/1200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.3685 - accuracy: 0.8455 - val_loss: 0.5850 - val_accuracy: 0.7240\n",
            "Epoch 786/1200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3682 - accuracy: 0.8438 - val_loss: 0.5816 - val_accuracy: 0.7396\n",
            "Epoch 787/1200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3682 - accuracy: 0.8490 - val_loss: 0.5811 - val_accuracy: 0.7396\n",
            "Epoch 788/1200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.3681 - accuracy: 0.8438 - val_loss: 0.5820 - val_accuracy: 0.7396\n",
            "Epoch 789/1200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3688 - accuracy: 0.8472 - val_loss: 0.5819 - val_accuracy: 0.7448\n",
            "Epoch 790/1200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3679 - accuracy: 0.8524 - val_loss: 0.5825 - val_accuracy: 0.7396\n",
            "Epoch 791/1200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3677 - accuracy: 0.8455 - val_loss: 0.5840 - val_accuracy: 0.7396\n",
            "Epoch 792/1200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.3682 - accuracy: 0.8420 - val_loss: 0.5844 - val_accuracy: 0.7344\n",
            "Epoch 793/1200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3678 - accuracy: 0.8455 - val_loss: 0.5823 - val_accuracy: 0.7448\n",
            "Epoch 794/1200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3683 - accuracy: 0.8524 - val_loss: 0.5834 - val_accuracy: 0.7396\n",
            "Epoch 795/1200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3678 - accuracy: 0.8507 - val_loss: 0.5838 - val_accuracy: 0.7396\n",
            "Epoch 796/1200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3677 - accuracy: 0.8455 - val_loss: 0.5846 - val_accuracy: 0.7344\n",
            "Epoch 797/1200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.3677 - accuracy: 0.8455 - val_loss: 0.5863 - val_accuracy: 0.7292\n",
            "Epoch 798/1200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3678 - accuracy: 0.8507 - val_loss: 0.5839 - val_accuracy: 0.7344\n",
            "Epoch 799/1200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3682 - accuracy: 0.8472 - val_loss: 0.5835 - val_accuracy: 0.7344\n",
            "Epoch 800/1200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3674 - accuracy: 0.8472 - val_loss: 0.5830 - val_accuracy: 0.7344\n",
            "Epoch 801/1200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3677 - accuracy: 0.8472 - val_loss: 0.5836 - val_accuracy: 0.7448\n",
            "Epoch 802/1200\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3673 - accuracy: 0.8490 - val_loss: 0.5840 - val_accuracy: 0.7396\n",
            "Epoch 803/1200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3671 - accuracy: 0.8455 - val_loss: 0.5828 - val_accuracy: 0.7448\n",
            "Epoch 804/1200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3676 - accuracy: 0.8490 - val_loss: 0.5844 - val_accuracy: 0.7396\n",
            "Epoch 805/1200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.3669 - accuracy: 0.8438 - val_loss: 0.5850 - val_accuracy: 0.7448\n",
            "Epoch 806/1200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.3674 - accuracy: 0.8438 - val_loss: 0.5834 - val_accuracy: 0.7448\n",
            "Epoch 807/1200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3669 - accuracy: 0.8472 - val_loss: 0.5850 - val_accuracy: 0.7396\n",
            "Epoch 808/1200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3667 - accuracy: 0.8490 - val_loss: 0.5834 - val_accuracy: 0.7448\n",
            "Epoch 809/1200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3670 - accuracy: 0.8490 - val_loss: 0.5851 - val_accuracy: 0.7396\n",
            "Epoch 810/1200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3668 - accuracy: 0.8472 - val_loss: 0.5856 - val_accuracy: 0.7448\n",
            "Epoch 811/1200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3667 - accuracy: 0.8490 - val_loss: 0.5863 - val_accuracy: 0.7396\n",
            "Epoch 812/1200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3665 - accuracy: 0.8472 - val_loss: 0.5869 - val_accuracy: 0.7396\n",
            "Epoch 813/1200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3662 - accuracy: 0.8490 - val_loss: 0.5864 - val_accuracy: 0.7396\n",
            "Epoch 814/1200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3659 - accuracy: 0.8472 - val_loss: 0.5858 - val_accuracy: 0.7396\n",
            "Epoch 815/1200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.3661 - accuracy: 0.8472 - val_loss: 0.5866 - val_accuracy: 0.7396\n",
            "Epoch 816/1200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3659 - accuracy: 0.8472 - val_loss: 0.5882 - val_accuracy: 0.7396\n",
            "Epoch 817/1200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3666 - accuracy: 0.8472 - val_loss: 0.5875 - val_accuracy: 0.7396\n",
            "Epoch 818/1200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3661 - accuracy: 0.8490 - val_loss: 0.5874 - val_accuracy: 0.7396\n",
            "Epoch 819/1200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3661 - accuracy: 0.8438 - val_loss: 0.5853 - val_accuracy: 0.7448\n",
            "Epoch 820/1200\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3661 - accuracy: 0.8455 - val_loss: 0.5868 - val_accuracy: 0.7396\n",
            "Epoch 821/1200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3656 - accuracy: 0.8455 - val_loss: 0.5871 - val_accuracy: 0.7396\n",
            "Epoch 822/1200\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.3658 - accuracy: 0.8472 - val_loss: 0.5848 - val_accuracy: 0.7448\n",
            "Epoch 823/1200\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3659 - accuracy: 0.8490 - val_loss: 0.5861 - val_accuracy: 0.7448\n",
            "Epoch 824/1200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3652 - accuracy: 0.8472 - val_loss: 0.5899 - val_accuracy: 0.7344\n",
            "Epoch 825/1200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3654 - accuracy: 0.8420 - val_loss: 0.5866 - val_accuracy: 0.7448\n",
            "Epoch 826/1200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3657 - accuracy: 0.8455 - val_loss: 0.5861 - val_accuracy: 0.7448\n",
            "Epoch 827/1200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3647 - accuracy: 0.8472 - val_loss: 0.5878 - val_accuracy: 0.7396\n",
            "Epoch 828/1200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3650 - accuracy: 0.8455 - val_loss: 0.5850 - val_accuracy: 0.7448\n",
            "Epoch 829/1200\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.3648 - accuracy: 0.8455 - val_loss: 0.5870 - val_accuracy: 0.7448\n",
            "Epoch 830/1200\n",
            "18/18 [==============================] - 0s 12ms/step - loss: 0.3648 - accuracy: 0.8438 - val_loss: 0.5851 - val_accuracy: 0.7448\n",
            "Epoch 831/1200\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3645 - accuracy: 0.8472 - val_loss: 0.5880 - val_accuracy: 0.7396\n",
            "Epoch 832/1200\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3648 - accuracy: 0.8455 - val_loss: 0.5863 - val_accuracy: 0.7396\n",
            "Epoch 833/1200\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.3648 - accuracy: 0.8438 - val_loss: 0.5837 - val_accuracy: 0.7448\n",
            "Epoch 834/1200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3645 - accuracy: 0.8455 - val_loss: 0.5865 - val_accuracy: 0.7448\n",
            "Epoch 835/1200\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.3634 - accuracy: 0.8438 - val_loss: 0.5853 - val_accuracy: 0.7448\n",
            "Epoch 836/1200\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.3635 - accuracy: 0.8438 - val_loss: 0.5858 - val_accuracy: 0.7448\n",
            "Epoch 837/1200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3635 - accuracy: 0.8438 - val_loss: 0.5859 - val_accuracy: 0.7500\n",
            "Epoch 838/1200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3639 - accuracy: 0.8403 - val_loss: 0.5864 - val_accuracy: 0.7448\n",
            "Epoch 839/1200\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.3627 - accuracy: 0.8438 - val_loss: 0.5867 - val_accuracy: 0.7448\n",
            "Epoch 840/1200\n",
            "18/18 [==============================] - 0s 14ms/step - loss: 0.3629 - accuracy: 0.8455 - val_loss: 0.5841 - val_accuracy: 0.7500\n",
            "Epoch 841/1200\n",
            "18/18 [==============================] - 0s 12ms/step - loss: 0.3634 - accuracy: 0.8455 - val_loss: 0.5854 - val_accuracy: 0.7448\n",
            "Epoch 842/1200\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.3632 - accuracy: 0.8455 - val_loss: 0.5873 - val_accuracy: 0.7500\n",
            "Epoch 843/1200\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.3632 - accuracy: 0.8455 - val_loss: 0.5876 - val_accuracy: 0.7448\n",
            "Epoch 844/1200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3626 - accuracy: 0.8455 - val_loss: 0.5856 - val_accuracy: 0.7500\n",
            "Epoch 845/1200\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3623 - accuracy: 0.8490 - val_loss: 0.5861 - val_accuracy: 0.7500\n",
            "Epoch 846/1200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3624 - accuracy: 0.8472 - val_loss: 0.5854 - val_accuracy: 0.7500\n",
            "Epoch 847/1200\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3626 - accuracy: 0.8472 - val_loss: 0.5854 - val_accuracy: 0.7500\n",
            "Epoch 848/1200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3625 - accuracy: 0.8490 - val_loss: 0.5854 - val_accuracy: 0.7500\n",
            "Epoch 849/1200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3621 - accuracy: 0.8455 - val_loss: 0.5883 - val_accuracy: 0.7500\n",
            "Epoch 850/1200\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3617 - accuracy: 0.8438 - val_loss: 0.5899 - val_accuracy: 0.7500\n",
            "Epoch 851/1200\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3619 - accuracy: 0.8472 - val_loss: 0.5901 - val_accuracy: 0.7500\n",
            "Epoch 852/1200\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3618 - accuracy: 0.8438 - val_loss: 0.5881 - val_accuracy: 0.7500\n",
            "Epoch 853/1200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3613 - accuracy: 0.8455 - val_loss: 0.5917 - val_accuracy: 0.7500\n",
            "Epoch 854/1200\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3613 - accuracy: 0.8420 - val_loss: 0.5935 - val_accuracy: 0.7552\n",
            "Epoch 855/1200\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3618 - accuracy: 0.8455 - val_loss: 0.5893 - val_accuracy: 0.7500\n",
            "Epoch 856/1200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3613 - accuracy: 0.8472 - val_loss: 0.5909 - val_accuracy: 0.7500\n",
            "Epoch 857/1200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3614 - accuracy: 0.8472 - val_loss: 0.5918 - val_accuracy: 0.7500\n",
            "Epoch 858/1200\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3617 - accuracy: 0.8438 - val_loss: 0.5912 - val_accuracy: 0.7500\n",
            "Epoch 859/1200\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3611 - accuracy: 0.8438 - val_loss: 0.5899 - val_accuracy: 0.7500\n",
            "Epoch 860/1200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3610 - accuracy: 0.8455 - val_loss: 0.5925 - val_accuracy: 0.7500\n",
            "Epoch 861/1200\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3614 - accuracy: 0.8438 - val_loss: 0.5916 - val_accuracy: 0.7500\n",
            "Epoch 862/1200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3609 - accuracy: 0.8438 - val_loss: 0.5946 - val_accuracy: 0.7448\n",
            "Epoch 863/1200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3611 - accuracy: 0.8438 - val_loss: 0.5964 - val_accuracy: 0.7500\n",
            "Epoch 864/1200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3601 - accuracy: 0.8420 - val_loss: 0.5907 - val_accuracy: 0.7500\n",
            "Epoch 865/1200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3604 - accuracy: 0.8438 - val_loss: 0.5946 - val_accuracy: 0.7500\n",
            "Epoch 866/1200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3602 - accuracy: 0.8420 - val_loss: 0.5943 - val_accuracy: 0.7500\n",
            "Epoch 867/1200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3605 - accuracy: 0.8438 - val_loss: 0.5949 - val_accuracy: 0.7552\n",
            "Epoch 868/1200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3602 - accuracy: 0.8438 - val_loss: 0.5924 - val_accuracy: 0.7500\n",
            "Epoch 869/1200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3602 - accuracy: 0.8438 - val_loss: 0.5940 - val_accuracy: 0.7500\n",
            "Epoch 870/1200\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3605 - accuracy: 0.8420 - val_loss: 0.5947 - val_accuracy: 0.7500\n",
            "Epoch 871/1200\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.3601 - accuracy: 0.8438 - val_loss: 0.5937 - val_accuracy: 0.7500\n",
            "Epoch 872/1200\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.3608 - accuracy: 0.8420 - val_loss: 0.5980 - val_accuracy: 0.7604\n",
            "Epoch 873/1200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3594 - accuracy: 0.8438 - val_loss: 0.5950 - val_accuracy: 0.7500\n",
            "Epoch 874/1200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3600 - accuracy: 0.8455 - val_loss: 0.5960 - val_accuracy: 0.7500\n",
            "Epoch 875/1200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.3599 - accuracy: 0.8472 - val_loss: 0.5977 - val_accuracy: 0.7552\n",
            "Epoch 876/1200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3605 - accuracy: 0.8472 - val_loss: 0.5959 - val_accuracy: 0.7500\n",
            "Epoch 877/1200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3598 - accuracy: 0.8420 - val_loss: 0.5973 - val_accuracy: 0.7604\n",
            "Epoch 878/1200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3591 - accuracy: 0.8455 - val_loss: 0.5984 - val_accuracy: 0.7604\n",
            "Epoch 879/1200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3600 - accuracy: 0.8438 - val_loss: 0.5979 - val_accuracy: 0.7552\n",
            "Epoch 880/1200\n",
            "18/18 [==============================] - 0s 18ms/step - loss: 0.3599 - accuracy: 0.8438 - val_loss: 0.5961 - val_accuracy: 0.7500\n",
            "Epoch 881/1200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3596 - accuracy: 0.8438 - val_loss: 0.5967 - val_accuracy: 0.7500\n",
            "Epoch 882/1200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3591 - accuracy: 0.8455 - val_loss: 0.5976 - val_accuracy: 0.7552\n",
            "Epoch 883/1200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3595 - accuracy: 0.8438 - val_loss: 0.5977 - val_accuracy: 0.7604\n",
            "Epoch 884/1200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3586 - accuracy: 0.8438 - val_loss: 0.5988 - val_accuracy: 0.7604\n",
            "Epoch 885/1200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3593 - accuracy: 0.8438 - val_loss: 0.6004 - val_accuracy: 0.7604\n",
            "Epoch 886/1200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3594 - accuracy: 0.8438 - val_loss: 0.5979 - val_accuracy: 0.7552\n",
            "Epoch 887/1200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3593 - accuracy: 0.8438 - val_loss: 0.5994 - val_accuracy: 0.7604\n",
            "Epoch 888/1200\n",
            "18/18 [==============================] - 0s 17ms/step - loss: 0.3586 - accuracy: 0.8438 - val_loss: 0.6011 - val_accuracy: 0.7552\n",
            "Epoch 889/1200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3583 - accuracy: 0.8438 - val_loss: 0.5999 - val_accuracy: 0.7552\n",
            "Epoch 890/1200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.3582 - accuracy: 0.8472 - val_loss: 0.6040 - val_accuracy: 0.7604\n",
            "Epoch 891/1200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3591 - accuracy: 0.8403 - val_loss: 0.6030 - val_accuracy: 0.7552\n",
            "Epoch 892/1200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.3583 - accuracy: 0.8403 - val_loss: 0.6005 - val_accuracy: 0.7604\n",
            "Epoch 893/1200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3582 - accuracy: 0.8438 - val_loss: 0.6022 - val_accuracy: 0.7604\n",
            "Epoch 894/1200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3584 - accuracy: 0.8438 - val_loss: 0.6024 - val_accuracy: 0.7552\n",
            "Epoch 895/1200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.3584 - accuracy: 0.8472 - val_loss: 0.6040 - val_accuracy: 0.7552\n",
            "Epoch 896/1200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.3579 - accuracy: 0.8438 - val_loss: 0.6026 - val_accuracy: 0.7552\n",
            "Epoch 897/1200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3586 - accuracy: 0.8472 - val_loss: 0.6007 - val_accuracy: 0.7552\n",
            "Epoch 898/1200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3580 - accuracy: 0.8455 - val_loss: 0.6017 - val_accuracy: 0.7552\n",
            "Epoch 899/1200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.3578 - accuracy: 0.8472 - val_loss: 0.6029 - val_accuracy: 0.7552\n",
            "Epoch 900/1200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3582 - accuracy: 0.8403 - val_loss: 0.6009 - val_accuracy: 0.7552\n",
            "Epoch 901/1200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3577 - accuracy: 0.8472 - val_loss: 0.6050 - val_accuracy: 0.7500\n",
            "Epoch 902/1200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3573 - accuracy: 0.8455 - val_loss: 0.6019 - val_accuracy: 0.7604\n",
            "Epoch 903/1200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3579 - accuracy: 0.8438 - val_loss: 0.6024 - val_accuracy: 0.7604\n",
            "Epoch 904/1200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3574 - accuracy: 0.8472 - val_loss: 0.6018 - val_accuracy: 0.7656\n",
            "Epoch 905/1200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3576 - accuracy: 0.8438 - val_loss: 0.6051 - val_accuracy: 0.7656\n",
            "Epoch 906/1200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3573 - accuracy: 0.8438 - val_loss: 0.6063 - val_accuracy: 0.7552\n",
            "Epoch 907/1200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3573 - accuracy: 0.8455 - val_loss: 0.6049 - val_accuracy: 0.7552\n",
            "Epoch 908/1200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3580 - accuracy: 0.8455 - val_loss: 0.6063 - val_accuracy: 0.7500\n",
            "Epoch 909/1200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3570 - accuracy: 0.8455 - val_loss: 0.6094 - val_accuracy: 0.7552\n",
            "Epoch 910/1200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3583 - accuracy: 0.8420 - val_loss: 0.6056 - val_accuracy: 0.7656\n",
            "Epoch 911/1200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3567 - accuracy: 0.8455 - val_loss: 0.6024 - val_accuracy: 0.7552\n",
            "Epoch 912/1200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3570 - accuracy: 0.8490 - val_loss: 0.6048 - val_accuracy: 0.7604\n",
            "Epoch 913/1200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.3571 - accuracy: 0.8438 - val_loss: 0.6067 - val_accuracy: 0.7604\n",
            "Epoch 914/1200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3571 - accuracy: 0.8455 - val_loss: 0.6079 - val_accuracy: 0.7552\n",
            "Epoch 915/1200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3570 - accuracy: 0.8490 - val_loss: 0.6105 - val_accuracy: 0.7552\n",
            "Epoch 916/1200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.3570 - accuracy: 0.8403 - val_loss: 0.6074 - val_accuracy: 0.7552\n",
            "Epoch 917/1200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3566 - accuracy: 0.8472 - val_loss: 0.6082 - val_accuracy: 0.7552\n",
            "Epoch 918/1200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3563 - accuracy: 0.8438 - val_loss: 0.6080 - val_accuracy: 0.7656\n",
            "Epoch 919/1200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3562 - accuracy: 0.8490 - val_loss: 0.6110 - val_accuracy: 0.7552\n",
            "Epoch 920/1200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.3564 - accuracy: 0.8420 - val_loss: 0.6090 - val_accuracy: 0.7604\n",
            "Epoch 921/1200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3563 - accuracy: 0.8490 - val_loss: 0.6076 - val_accuracy: 0.7604\n",
            "Epoch 922/1200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3562 - accuracy: 0.8507 - val_loss: 0.6088 - val_accuracy: 0.7552\n",
            "Epoch 923/1200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.3566 - accuracy: 0.8455 - val_loss: 0.6109 - val_accuracy: 0.7604\n",
            "Epoch 924/1200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3560 - accuracy: 0.8438 - val_loss: 0.6117 - val_accuracy: 0.7656\n",
            "Epoch 925/1200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3564 - accuracy: 0.8472 - val_loss: 0.6089 - val_accuracy: 0.7604\n",
            "Epoch 926/1200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3557 - accuracy: 0.8472 - val_loss: 0.6107 - val_accuracy: 0.7552\n",
            "Epoch 927/1200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3560 - accuracy: 0.8455 - val_loss: 0.6102 - val_accuracy: 0.7604\n",
            "Epoch 928/1200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3559 - accuracy: 0.8420 - val_loss: 0.6077 - val_accuracy: 0.7604\n",
            "Epoch 929/1200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3566 - accuracy: 0.8472 - val_loss: 0.6096 - val_accuracy: 0.7604\n",
            "Epoch 930/1200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3562 - accuracy: 0.8490 - val_loss: 0.6119 - val_accuracy: 0.7604\n",
            "Epoch 931/1200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3558 - accuracy: 0.8490 - val_loss: 0.6155 - val_accuracy: 0.7604\n",
            "Epoch 932/1200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3562 - accuracy: 0.8472 - val_loss: 0.6130 - val_accuracy: 0.7604\n",
            "Epoch 933/1200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3562 - accuracy: 0.8455 - val_loss: 0.6095 - val_accuracy: 0.7604\n",
            "Epoch 934/1200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3550 - accuracy: 0.8524 - val_loss: 0.6136 - val_accuracy: 0.7604\n",
            "Epoch 935/1200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3557 - accuracy: 0.8490 - val_loss: 0.6135 - val_accuracy: 0.7552\n",
            "Epoch 936/1200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3554 - accuracy: 0.8455 - val_loss: 0.6106 - val_accuracy: 0.7552\n",
            "Epoch 937/1200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3554 - accuracy: 0.8420 - val_loss: 0.6127 - val_accuracy: 0.7604\n",
            "Epoch 938/1200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3557 - accuracy: 0.8524 - val_loss: 0.6134 - val_accuracy: 0.7604\n",
            "Epoch 939/1200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3555 - accuracy: 0.8455 - val_loss: 0.6135 - val_accuracy: 0.7552\n",
            "Epoch 940/1200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3554 - accuracy: 0.8490 - val_loss: 0.6161 - val_accuracy: 0.7552\n",
            "Epoch 941/1200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3556 - accuracy: 0.8490 - val_loss: 0.6168 - val_accuracy: 0.7604\n",
            "Epoch 942/1200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3554 - accuracy: 0.8438 - val_loss: 0.6148 - val_accuracy: 0.7552\n",
            "Epoch 943/1200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3566 - accuracy: 0.8472 - val_loss: 0.6158 - val_accuracy: 0.7604\n",
            "Epoch 944/1200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3556 - accuracy: 0.8455 - val_loss: 0.6144 - val_accuracy: 0.7552\n",
            "Epoch 945/1200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3555 - accuracy: 0.8490 - val_loss: 0.6156 - val_accuracy: 0.7552\n",
            "Epoch 946/1200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.3554 - accuracy: 0.8455 - val_loss: 0.6130 - val_accuracy: 0.7604\n",
            "Epoch 947/1200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3556 - accuracy: 0.8490 - val_loss: 0.6129 - val_accuracy: 0.7604\n",
            "Epoch 948/1200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3552 - accuracy: 0.8524 - val_loss: 0.6123 - val_accuracy: 0.7604\n",
            "Epoch 949/1200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3552 - accuracy: 0.8403 - val_loss: 0.6124 - val_accuracy: 0.7656\n",
            "Epoch 950/1200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3553 - accuracy: 0.8455 - val_loss: 0.6155 - val_accuracy: 0.7604\n",
            "Epoch 951/1200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3555 - accuracy: 0.8507 - val_loss: 0.6168 - val_accuracy: 0.7604\n",
            "Epoch 952/1200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3548 - accuracy: 0.8455 - val_loss: 0.6153 - val_accuracy: 0.7604\n",
            "Epoch 953/1200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3550 - accuracy: 0.8455 - val_loss: 0.6164 - val_accuracy: 0.7604\n",
            "Epoch 954/1200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3550 - accuracy: 0.8455 - val_loss: 0.6176 - val_accuracy: 0.7604\n",
            "Epoch 955/1200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3553 - accuracy: 0.8472 - val_loss: 0.6166 - val_accuracy: 0.7604\n",
            "Epoch 956/1200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3549 - accuracy: 0.8455 - val_loss: 0.6165 - val_accuracy: 0.7552\n",
            "Epoch 957/1200\n",
            "18/18 [==============================] - 0s 23ms/step - loss: 0.3552 - accuracy: 0.8472 - val_loss: 0.6146 - val_accuracy: 0.7656\n",
            "Epoch 958/1200\n",
            "18/18 [==============================] - 0s 20ms/step - loss: 0.3557 - accuracy: 0.8455 - val_loss: 0.6137 - val_accuracy: 0.7656\n",
            "Epoch 959/1200\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.3554 - accuracy: 0.8472 - val_loss: 0.6167 - val_accuracy: 0.7656\n",
            "Epoch 960/1200\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.3551 - accuracy: 0.8455 - val_loss: 0.6169 - val_accuracy: 0.7604\n",
            "Epoch 961/1200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3549 - accuracy: 0.8472 - val_loss: 0.6144 - val_accuracy: 0.7656\n",
            "Epoch 962/1200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3545 - accuracy: 0.8507 - val_loss: 0.6187 - val_accuracy: 0.7604\n",
            "Epoch 963/1200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3550 - accuracy: 0.8524 - val_loss: 0.6160 - val_accuracy: 0.7604\n",
            "Epoch 964/1200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3540 - accuracy: 0.8490 - val_loss: 0.6166 - val_accuracy: 0.7604\n",
            "Epoch 965/1200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.3543 - accuracy: 0.8472 - val_loss: 0.6174 - val_accuracy: 0.7604\n",
            "Epoch 966/1200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3551 - accuracy: 0.8507 - val_loss: 0.6194 - val_accuracy: 0.7604\n",
            "Epoch 967/1200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3544 - accuracy: 0.8455 - val_loss: 0.6189 - val_accuracy: 0.7604\n",
            "Epoch 968/1200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3545 - accuracy: 0.8559 - val_loss: 0.6202 - val_accuracy: 0.7604\n",
            "Epoch 969/1200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3550 - accuracy: 0.8490 - val_loss: 0.6187 - val_accuracy: 0.7604\n",
            "Epoch 970/1200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.3549 - accuracy: 0.8490 - val_loss: 0.6162 - val_accuracy: 0.7604\n",
            "Epoch 971/1200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3544 - accuracy: 0.8507 - val_loss: 0.6167 - val_accuracy: 0.7656\n",
            "Epoch 972/1200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3540 - accuracy: 0.8472 - val_loss: 0.6161 - val_accuracy: 0.7656\n",
            "Epoch 973/1200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3541 - accuracy: 0.8490 - val_loss: 0.6197 - val_accuracy: 0.7656\n",
            "Epoch 974/1200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.3550 - accuracy: 0.8472 - val_loss: 0.6165 - val_accuracy: 0.7604\n",
            "Epoch 975/1200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3549 - accuracy: 0.8524 - val_loss: 0.6213 - val_accuracy: 0.7604\n",
            "Epoch 976/1200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.3549 - accuracy: 0.8490 - val_loss: 0.6181 - val_accuracy: 0.7604\n",
            "Epoch 977/1200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3542 - accuracy: 0.8490 - val_loss: 0.6214 - val_accuracy: 0.7604\n",
            "Epoch 978/1200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.3544 - accuracy: 0.8524 - val_loss: 0.6205 - val_accuracy: 0.7604\n",
            "Epoch 979/1200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3544 - accuracy: 0.8524 - val_loss: 0.6182 - val_accuracy: 0.7656\n",
            "Epoch 980/1200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3534 - accuracy: 0.8524 - val_loss: 0.6229 - val_accuracy: 0.7604\n",
            "Epoch 981/1200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3549 - accuracy: 0.8507 - val_loss: 0.6203 - val_accuracy: 0.7604\n",
            "Epoch 982/1200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3541 - accuracy: 0.8507 - val_loss: 0.6210 - val_accuracy: 0.7604\n",
            "Epoch 983/1200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3537 - accuracy: 0.8542 - val_loss: 0.6200 - val_accuracy: 0.7656\n",
            "Epoch 984/1200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.3549 - accuracy: 0.8490 - val_loss: 0.6211 - val_accuracy: 0.7656\n",
            "Epoch 985/1200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3544 - accuracy: 0.8490 - val_loss: 0.6209 - val_accuracy: 0.7552\n",
            "Epoch 986/1200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.3542 - accuracy: 0.8455 - val_loss: 0.6250 - val_accuracy: 0.7604\n",
            "Epoch 987/1200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3540 - accuracy: 0.8524 - val_loss: 0.6210 - val_accuracy: 0.7656\n",
            "Epoch 988/1200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3536 - accuracy: 0.8472 - val_loss: 0.6222 - val_accuracy: 0.7656\n",
            "Epoch 989/1200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3540 - accuracy: 0.8490 - val_loss: 0.6221 - val_accuracy: 0.7656\n",
            "Epoch 990/1200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3542 - accuracy: 0.8490 - val_loss: 0.6212 - val_accuracy: 0.7656\n",
            "Epoch 991/1200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3541 - accuracy: 0.8542 - val_loss: 0.6237 - val_accuracy: 0.7604\n",
            "Epoch 992/1200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.3534 - accuracy: 0.8507 - val_loss: 0.6255 - val_accuracy: 0.7604\n",
            "Epoch 993/1200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3539 - accuracy: 0.8524 - val_loss: 0.6234 - val_accuracy: 0.7604\n",
            "Epoch 994/1200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3534 - accuracy: 0.8472 - val_loss: 0.6266 - val_accuracy: 0.7552\n",
            "Epoch 995/1200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3539 - accuracy: 0.8490 - val_loss: 0.6197 - val_accuracy: 0.7604\n",
            "Epoch 996/1200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3543 - accuracy: 0.8490 - val_loss: 0.6190 - val_accuracy: 0.7604\n",
            "Epoch 997/1200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3536 - accuracy: 0.8542 - val_loss: 0.6232 - val_accuracy: 0.7656\n",
            "Epoch 998/1200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3539 - accuracy: 0.8542 - val_loss: 0.6227 - val_accuracy: 0.7656\n",
            "Epoch 999/1200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3536 - accuracy: 0.8542 - val_loss: 0.6244 - val_accuracy: 0.7604\n",
            "Epoch 1000/1200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3544 - accuracy: 0.8524 - val_loss: 0.6215 - val_accuracy: 0.7656\n",
            "Epoch 1001/1200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3536 - accuracy: 0.8507 - val_loss: 0.6247 - val_accuracy: 0.7604\n",
            "Epoch 1002/1200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3539 - accuracy: 0.8507 - val_loss: 0.6224 - val_accuracy: 0.7656\n",
            "Epoch 1003/1200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3536 - accuracy: 0.8542 - val_loss: 0.6231 - val_accuracy: 0.7656\n",
            "Epoch 1004/1200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3535 - accuracy: 0.8524 - val_loss: 0.6215 - val_accuracy: 0.7656\n",
            "Epoch 1005/1200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.3532 - accuracy: 0.8490 - val_loss: 0.6290 - val_accuracy: 0.7604\n",
            "Epoch 1006/1200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3541 - accuracy: 0.8490 - val_loss: 0.6267 - val_accuracy: 0.7656\n",
            "Epoch 1007/1200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3540 - accuracy: 0.8524 - val_loss: 0.6255 - val_accuracy: 0.7604\n",
            "Epoch 1008/1200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.3536 - accuracy: 0.8472 - val_loss: 0.6243 - val_accuracy: 0.7604\n",
            "Epoch 1009/1200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3536 - accuracy: 0.8542 - val_loss: 0.6244 - val_accuracy: 0.7656\n",
            "Epoch 1010/1200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3532 - accuracy: 0.8490 - val_loss: 0.6251 - val_accuracy: 0.7656\n",
            "Epoch 1011/1200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3536 - accuracy: 0.8472 - val_loss: 0.6252 - val_accuracy: 0.7656\n",
            "Epoch 1012/1200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3532 - accuracy: 0.8507 - val_loss: 0.6271 - val_accuracy: 0.7656\n",
            "Epoch 1013/1200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3537 - accuracy: 0.8490 - val_loss: 0.6244 - val_accuracy: 0.7656\n",
            "Epoch 1014/1200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3528 - accuracy: 0.8524 - val_loss: 0.6274 - val_accuracy: 0.7604\n",
            "Epoch 1015/1200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3533 - accuracy: 0.8524 - val_loss: 0.6242 - val_accuracy: 0.7656\n",
            "Epoch 1016/1200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3535 - accuracy: 0.8542 - val_loss: 0.6281 - val_accuracy: 0.7656\n",
            "Epoch 1017/1200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3534 - accuracy: 0.8507 - val_loss: 0.6282 - val_accuracy: 0.7604\n",
            "Epoch 1018/1200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3532 - accuracy: 0.8507 - val_loss: 0.6236 - val_accuracy: 0.7604\n",
            "Epoch 1019/1200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.3530 - accuracy: 0.8542 - val_loss: 0.6241 - val_accuracy: 0.7656\n",
            "Epoch 1020/1200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3534 - accuracy: 0.8524 - val_loss: 0.6263 - val_accuracy: 0.7656\n",
            "Epoch 1021/1200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3535 - accuracy: 0.8507 - val_loss: 0.6262 - val_accuracy: 0.7656\n",
            "Epoch 1022/1200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.3529 - accuracy: 0.8542 - val_loss: 0.6240 - val_accuracy: 0.7656\n",
            "Epoch 1023/1200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3527 - accuracy: 0.8542 - val_loss: 0.6271 - val_accuracy: 0.7604\n",
            "Epoch 1024/1200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.3530 - accuracy: 0.8524 - val_loss: 0.6255 - val_accuracy: 0.7656\n",
            "Epoch 1025/1200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3529 - accuracy: 0.8490 - val_loss: 0.6255 - val_accuracy: 0.7656\n",
            "Epoch 1026/1200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3528 - accuracy: 0.8542 - val_loss: 0.6268 - val_accuracy: 0.7604\n",
            "Epoch 1027/1200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3530 - accuracy: 0.8524 - val_loss: 0.6242 - val_accuracy: 0.7656\n",
            "Epoch 1028/1200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3527 - accuracy: 0.8507 - val_loss: 0.6282 - val_accuracy: 0.7656\n",
            "Epoch 1029/1200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3528 - accuracy: 0.8524 - val_loss: 0.6274 - val_accuracy: 0.7656\n",
            "Epoch 1030/1200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3533 - accuracy: 0.8490 - val_loss: 0.6313 - val_accuracy: 0.7604\n",
            "Epoch 1031/1200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3530 - accuracy: 0.8507 - val_loss: 0.6284 - val_accuracy: 0.7656\n",
            "Epoch 1032/1200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3523 - accuracy: 0.8542 - val_loss: 0.6307 - val_accuracy: 0.7604\n",
            "Epoch 1033/1200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3533 - accuracy: 0.8524 - val_loss: 0.6272 - val_accuracy: 0.7656\n",
            "Epoch 1034/1200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3520 - accuracy: 0.8542 - val_loss: 0.6274 - val_accuracy: 0.7656\n",
            "Epoch 1035/1200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3522 - accuracy: 0.8524 - val_loss: 0.6321 - val_accuracy: 0.7656\n",
            "Epoch 1036/1200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3540 - accuracy: 0.8507 - val_loss: 0.6293 - val_accuracy: 0.7656\n",
            "Epoch 1037/1200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3530 - accuracy: 0.8507 - val_loss: 0.6277 - val_accuracy: 0.7656\n",
            "Epoch 1038/1200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3525 - accuracy: 0.8524 - val_loss: 0.6283 - val_accuracy: 0.7656\n",
            "Epoch 1039/1200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3526 - accuracy: 0.8559 - val_loss: 0.6270 - val_accuracy: 0.7656\n",
            "Epoch 1040/1200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3520 - accuracy: 0.8472 - val_loss: 0.6334 - val_accuracy: 0.7552\n",
            "Epoch 1041/1200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3526 - accuracy: 0.8524 - val_loss: 0.6282 - val_accuracy: 0.7656\n",
            "Epoch 1042/1200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3526 - accuracy: 0.8542 - val_loss: 0.6295 - val_accuracy: 0.7656\n",
            "Epoch 1043/1200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3523 - accuracy: 0.8524 - val_loss: 0.6312 - val_accuracy: 0.7656\n",
            "Epoch 1044/1200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3517 - accuracy: 0.8524 - val_loss: 0.6323 - val_accuracy: 0.7656\n",
            "Epoch 1045/1200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3529 - accuracy: 0.8542 - val_loss: 0.6311 - val_accuracy: 0.7604\n",
            "Epoch 1046/1200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3524 - accuracy: 0.8524 - val_loss: 0.6282 - val_accuracy: 0.7656\n",
            "Epoch 1047/1200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3523 - accuracy: 0.8524 - val_loss: 0.6321 - val_accuracy: 0.7656\n",
            "Epoch 1048/1200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3531 - accuracy: 0.8542 - val_loss: 0.6303 - val_accuracy: 0.7604\n",
            "Epoch 1049/1200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3522 - accuracy: 0.8507 - val_loss: 0.6309 - val_accuracy: 0.7604\n",
            "Epoch 1050/1200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.3525 - accuracy: 0.8490 - val_loss: 0.6279 - val_accuracy: 0.7656\n",
            "Epoch 1051/1200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3525 - accuracy: 0.8524 - val_loss: 0.6277 - val_accuracy: 0.7656\n",
            "Epoch 1052/1200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3525 - accuracy: 0.8542 - val_loss: 0.6321 - val_accuracy: 0.7708\n",
            "Epoch 1053/1200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3523 - accuracy: 0.8524 - val_loss: 0.6281 - val_accuracy: 0.7604\n",
            "Epoch 1054/1200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3520 - accuracy: 0.8524 - val_loss: 0.6307 - val_accuracy: 0.7656\n",
            "Epoch 1055/1200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3523 - accuracy: 0.8542 - val_loss: 0.6318 - val_accuracy: 0.7708\n",
            "Epoch 1056/1200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.3523 - accuracy: 0.8524 - val_loss: 0.6316 - val_accuracy: 0.7656\n",
            "Epoch 1057/1200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.3530 - accuracy: 0.8559 - val_loss: 0.6318 - val_accuracy: 0.7656\n",
            "Epoch 1058/1200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3520 - accuracy: 0.8507 - val_loss: 0.6314 - val_accuracy: 0.7604\n",
            "Epoch 1059/1200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3529 - accuracy: 0.8507 - val_loss: 0.6300 - val_accuracy: 0.7604\n",
            "Epoch 1060/1200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3526 - accuracy: 0.8507 - val_loss: 0.6282 - val_accuracy: 0.7604\n",
            "Epoch 1061/1200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3525 - accuracy: 0.8524 - val_loss: 0.6317 - val_accuracy: 0.7656\n",
            "Epoch 1062/1200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.3518 - accuracy: 0.8507 - val_loss: 0.6343 - val_accuracy: 0.7708\n",
            "Epoch 1063/1200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3525 - accuracy: 0.8490 - val_loss: 0.6325 - val_accuracy: 0.7708\n",
            "Epoch 1064/1200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3518 - accuracy: 0.8507 - val_loss: 0.6295 - val_accuracy: 0.7604\n",
            "Epoch 1065/1200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3522 - accuracy: 0.8559 - val_loss: 0.6321 - val_accuracy: 0.7656\n",
            "Epoch 1066/1200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3525 - accuracy: 0.8542 - val_loss: 0.6309 - val_accuracy: 0.7656\n",
            "Epoch 1067/1200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3522 - accuracy: 0.8542 - val_loss: 0.6319 - val_accuracy: 0.7656\n",
            "Epoch 1068/1200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3517 - accuracy: 0.8524 - val_loss: 0.6313 - val_accuracy: 0.7656\n",
            "Epoch 1069/1200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3512 - accuracy: 0.8472 - val_loss: 0.6278 - val_accuracy: 0.7656\n",
            "Epoch 1070/1200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.3519 - accuracy: 0.8559 - val_loss: 0.6284 - val_accuracy: 0.7656\n",
            "Epoch 1071/1200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.3523 - accuracy: 0.8507 - val_loss: 0.6301 - val_accuracy: 0.7604\n",
            "Epoch 1072/1200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3524 - accuracy: 0.8455 - val_loss: 0.6345 - val_accuracy: 0.7708\n",
            "Epoch 1073/1200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3509 - accuracy: 0.8542 - val_loss: 0.6402 - val_accuracy: 0.7604\n",
            "Epoch 1074/1200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3508 - accuracy: 0.8490 - val_loss: 0.6302 - val_accuracy: 0.7604\n",
            "Epoch 1075/1200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.3522 - accuracy: 0.8524 - val_loss: 0.6385 - val_accuracy: 0.7708\n",
            "Epoch 1076/1200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3514 - accuracy: 0.8507 - val_loss: 0.6375 - val_accuracy: 0.7656\n",
            "Epoch 1077/1200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3518 - accuracy: 0.8559 - val_loss: 0.6392 - val_accuracy: 0.7656\n",
            "Epoch 1078/1200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3517 - accuracy: 0.8542 - val_loss: 0.6347 - val_accuracy: 0.7656\n",
            "Epoch 1079/1200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3516 - accuracy: 0.8542 - val_loss: 0.6377 - val_accuracy: 0.7656\n",
            "Epoch 1080/1200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3511 - accuracy: 0.8594 - val_loss: 0.6325 - val_accuracy: 0.7604\n",
            "Epoch 1081/1200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3500 - accuracy: 0.8524 - val_loss: 0.6429 - val_accuracy: 0.7656\n",
            "Epoch 1082/1200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3514 - accuracy: 0.8507 - val_loss: 0.6354 - val_accuracy: 0.7656\n",
            "Epoch 1083/1200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3518 - accuracy: 0.8559 - val_loss: 0.6321 - val_accuracy: 0.7604\n",
            "Epoch 1084/1200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3505 - accuracy: 0.8524 - val_loss: 0.6317 - val_accuracy: 0.7708\n",
            "Epoch 1085/1200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3510 - accuracy: 0.8542 - val_loss: 0.6312 - val_accuracy: 0.7604\n",
            "Epoch 1086/1200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3515 - accuracy: 0.8542 - val_loss: 0.6323 - val_accuracy: 0.7656\n",
            "Epoch 1087/1200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3508 - accuracy: 0.8490 - val_loss: 0.6370 - val_accuracy: 0.7708\n",
            "Epoch 1088/1200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.3515 - accuracy: 0.8542 - val_loss: 0.6384 - val_accuracy: 0.7708\n",
            "Epoch 1089/1200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3518 - accuracy: 0.8507 - val_loss: 0.6356 - val_accuracy: 0.7708\n",
            "Epoch 1090/1200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3507 - accuracy: 0.8576 - val_loss: 0.6368 - val_accuracy: 0.7760\n",
            "Epoch 1091/1200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3513 - accuracy: 0.8507 - val_loss: 0.6377 - val_accuracy: 0.7708\n",
            "Epoch 1092/1200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3508 - accuracy: 0.8490 - val_loss: 0.6344 - val_accuracy: 0.7656\n",
            "Epoch 1093/1200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3504 - accuracy: 0.8576 - val_loss: 0.6313 - val_accuracy: 0.7604\n",
            "Epoch 1094/1200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3516 - accuracy: 0.8455 - val_loss: 0.6365 - val_accuracy: 0.7656\n",
            "Epoch 1095/1200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3515 - accuracy: 0.8472 - val_loss: 0.6350 - val_accuracy: 0.7656\n",
            "Epoch 1096/1200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3515 - accuracy: 0.8507 - val_loss: 0.6368 - val_accuracy: 0.7708\n",
            "Epoch 1097/1200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3514 - accuracy: 0.8507 - val_loss: 0.6366 - val_accuracy: 0.7760\n",
            "Epoch 1098/1200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3507 - accuracy: 0.8524 - val_loss: 0.6343 - val_accuracy: 0.7656\n",
            "Epoch 1099/1200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3515 - accuracy: 0.8576 - val_loss: 0.6346 - val_accuracy: 0.7656\n",
            "Epoch 1100/1200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3509 - accuracy: 0.8559 - val_loss: 0.6360 - val_accuracy: 0.7708\n",
            "Epoch 1101/1200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3508 - accuracy: 0.8524 - val_loss: 0.6377 - val_accuracy: 0.7708\n",
            "Epoch 1102/1200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3509 - accuracy: 0.8542 - val_loss: 0.6363 - val_accuracy: 0.7708\n",
            "Epoch 1103/1200\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.3507 - accuracy: 0.8507 - val_loss: 0.6328 - val_accuracy: 0.7656\n",
            "Epoch 1104/1200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3519 - accuracy: 0.8542 - val_loss: 0.6342 - val_accuracy: 0.7656\n",
            "Epoch 1105/1200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3515 - accuracy: 0.8524 - val_loss: 0.6354 - val_accuracy: 0.7708\n",
            "Epoch 1106/1200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3504 - accuracy: 0.8576 - val_loss: 0.6374 - val_accuracy: 0.7708\n",
            "Epoch 1107/1200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3508 - accuracy: 0.8507 - val_loss: 0.6331 - val_accuracy: 0.7656\n",
            "Epoch 1108/1200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3510 - accuracy: 0.8542 - val_loss: 0.6359 - val_accuracy: 0.7656\n",
            "Epoch 1109/1200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3502 - accuracy: 0.8490 - val_loss: 0.6370 - val_accuracy: 0.7656\n",
            "Epoch 1110/1200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3502 - accuracy: 0.8542 - val_loss: 0.6390 - val_accuracy: 0.7708\n",
            "Epoch 1111/1200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3510 - accuracy: 0.8507 - val_loss: 0.6392 - val_accuracy: 0.7708\n",
            "Epoch 1112/1200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3510 - accuracy: 0.8524 - val_loss: 0.6342 - val_accuracy: 0.7708\n",
            "Epoch 1113/1200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3500 - accuracy: 0.8507 - val_loss: 0.6395 - val_accuracy: 0.7708\n",
            "Epoch 1114/1200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3509 - accuracy: 0.8524 - val_loss: 0.6368 - val_accuracy: 0.7708\n",
            "Epoch 1115/1200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3503 - accuracy: 0.8559 - val_loss: 0.6344 - val_accuracy: 0.7656\n",
            "Epoch 1116/1200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3508 - accuracy: 0.8507 - val_loss: 0.6396 - val_accuracy: 0.7708\n",
            "Epoch 1117/1200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3508 - accuracy: 0.8507 - val_loss: 0.6349 - val_accuracy: 0.7708\n",
            "Epoch 1118/1200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3509 - accuracy: 0.8490 - val_loss: 0.6377 - val_accuracy: 0.7656\n",
            "Epoch 1119/1200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3500 - accuracy: 0.8490 - val_loss: 0.6345 - val_accuracy: 0.7656\n",
            "Epoch 1120/1200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.3510 - accuracy: 0.8507 - val_loss: 0.6347 - val_accuracy: 0.7656\n",
            "Epoch 1121/1200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.3510 - accuracy: 0.8490 - val_loss: 0.6363 - val_accuracy: 0.7708\n",
            "Epoch 1122/1200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3503 - accuracy: 0.8507 - val_loss: 0.6339 - val_accuracy: 0.7656\n",
            "Epoch 1123/1200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3509 - accuracy: 0.8559 - val_loss: 0.6373 - val_accuracy: 0.7656\n",
            "Epoch 1124/1200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3513 - accuracy: 0.8507 - val_loss: 0.6330 - val_accuracy: 0.7656\n",
            "Epoch 1125/1200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3505 - accuracy: 0.8576 - val_loss: 0.6380 - val_accuracy: 0.7656\n",
            "Epoch 1126/1200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3498 - accuracy: 0.8524 - val_loss: 0.6363 - val_accuracy: 0.7656\n",
            "Epoch 1127/1200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3511 - accuracy: 0.8559 - val_loss: 0.6361 - val_accuracy: 0.7656\n",
            "Epoch 1128/1200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3509 - accuracy: 0.8542 - val_loss: 0.6369 - val_accuracy: 0.7708\n",
            "Epoch 1129/1200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.3497 - accuracy: 0.8472 - val_loss: 0.6415 - val_accuracy: 0.7604\n",
            "Epoch 1130/1200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3503 - accuracy: 0.8507 - val_loss: 0.6340 - val_accuracy: 0.7656\n",
            "Epoch 1131/1200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3504 - accuracy: 0.8542 - val_loss: 0.6345 - val_accuracy: 0.7656\n",
            "Epoch 1132/1200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3509 - accuracy: 0.8524 - val_loss: 0.6362 - val_accuracy: 0.7656\n",
            "Epoch 1133/1200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3506 - accuracy: 0.8559 - val_loss: 0.6391 - val_accuracy: 0.7708\n",
            "Epoch 1134/1200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3499 - accuracy: 0.8542 - val_loss: 0.6346 - val_accuracy: 0.7656\n",
            "Epoch 1135/1200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.3499 - accuracy: 0.8507 - val_loss: 0.6393 - val_accuracy: 0.7708\n",
            "Epoch 1136/1200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.3493 - accuracy: 0.8490 - val_loss: 0.6356 - val_accuracy: 0.7656\n",
            "Epoch 1137/1200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3496 - accuracy: 0.8490 - val_loss: 0.6384 - val_accuracy: 0.7656\n",
            "Epoch 1138/1200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3503 - accuracy: 0.8524 - val_loss: 0.6345 - val_accuracy: 0.7656\n",
            "Epoch 1139/1200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3509 - accuracy: 0.8542 - val_loss: 0.6379 - val_accuracy: 0.7656\n",
            "Epoch 1140/1200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3499 - accuracy: 0.8524 - val_loss: 0.6350 - val_accuracy: 0.7656\n",
            "Epoch 1141/1200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3493 - accuracy: 0.8507 - val_loss: 0.6400 - val_accuracy: 0.7656\n",
            "Epoch 1142/1200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3496 - accuracy: 0.8542 - val_loss: 0.6395 - val_accuracy: 0.7656\n",
            "Epoch 1143/1200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3504 - accuracy: 0.8490 - val_loss: 0.6390 - val_accuracy: 0.7656\n",
            "Epoch 1144/1200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3496 - accuracy: 0.8542 - val_loss: 0.6400 - val_accuracy: 0.7656\n",
            "Epoch 1145/1200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3499 - accuracy: 0.8524 - val_loss: 0.6384 - val_accuracy: 0.7656\n",
            "Epoch 1146/1200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3503 - accuracy: 0.8507 - val_loss: 0.6374 - val_accuracy: 0.7708\n",
            "Epoch 1147/1200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3498 - accuracy: 0.8524 - val_loss: 0.6354 - val_accuracy: 0.7656\n",
            "Epoch 1148/1200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3500 - accuracy: 0.8524 - val_loss: 0.6387 - val_accuracy: 0.7656\n",
            "Epoch 1149/1200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3492 - accuracy: 0.8559 - val_loss: 0.6369 - val_accuracy: 0.7708\n",
            "Epoch 1150/1200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3500 - accuracy: 0.8490 - val_loss: 0.6370 - val_accuracy: 0.7656\n",
            "Epoch 1151/1200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3508 - accuracy: 0.8507 - val_loss: 0.6355 - val_accuracy: 0.7656\n",
            "Epoch 1152/1200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3506 - accuracy: 0.8507 - val_loss: 0.6379 - val_accuracy: 0.7656\n",
            "Epoch 1153/1200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3496 - accuracy: 0.8490 - val_loss: 0.6399 - val_accuracy: 0.7708\n",
            "Epoch 1154/1200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3512 - accuracy: 0.8490 - val_loss: 0.6382 - val_accuracy: 0.7708\n",
            "Epoch 1155/1200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3499 - accuracy: 0.8524 - val_loss: 0.6361 - val_accuracy: 0.7656\n",
            "Epoch 1156/1200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3497 - accuracy: 0.8490 - val_loss: 0.6341 - val_accuracy: 0.7656\n",
            "Epoch 1157/1200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3498 - accuracy: 0.8542 - val_loss: 0.6384 - val_accuracy: 0.7708\n",
            "Epoch 1158/1200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3497 - accuracy: 0.8507 - val_loss: 0.6405 - val_accuracy: 0.7760\n",
            "Epoch 1159/1200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3499 - accuracy: 0.8472 - val_loss: 0.6392 - val_accuracy: 0.7656\n",
            "Epoch 1160/1200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.3488 - accuracy: 0.8524 - val_loss: 0.6372 - val_accuracy: 0.7656\n",
            "Epoch 1161/1200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3489 - accuracy: 0.8455 - val_loss: 0.6423 - val_accuracy: 0.7708\n",
            "Epoch 1162/1200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3490 - accuracy: 0.8542 - val_loss: 0.6361 - val_accuracy: 0.7656\n",
            "Epoch 1163/1200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3505 - accuracy: 0.8490 - val_loss: 0.6374 - val_accuracy: 0.7708\n",
            "Epoch 1164/1200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3491 - accuracy: 0.8524 - val_loss: 0.6397 - val_accuracy: 0.7656\n",
            "Epoch 1165/1200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3499 - accuracy: 0.8524 - val_loss: 0.6391 - val_accuracy: 0.7708\n",
            "Epoch 1166/1200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3496 - accuracy: 0.8576 - val_loss: 0.6394 - val_accuracy: 0.7708\n",
            "Epoch 1167/1200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3488 - accuracy: 0.8507 - val_loss: 0.6400 - val_accuracy: 0.7656\n",
            "Epoch 1168/1200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3495 - accuracy: 0.8594 - val_loss: 0.6430 - val_accuracy: 0.7656\n",
            "Epoch 1169/1200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3496 - accuracy: 0.8542 - val_loss: 0.6383 - val_accuracy: 0.7656\n",
            "Epoch 1170/1200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3502 - accuracy: 0.8490 - val_loss: 0.6401 - val_accuracy: 0.7656\n",
            "Epoch 1171/1200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3489 - accuracy: 0.8524 - val_loss: 0.6373 - val_accuracy: 0.7656\n",
            "Epoch 1172/1200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.3508 - accuracy: 0.8490 - val_loss: 0.6368 - val_accuracy: 0.7656\n",
            "Epoch 1173/1200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3494 - accuracy: 0.8490 - val_loss: 0.6367 - val_accuracy: 0.7656\n",
            "Epoch 1174/1200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3492 - accuracy: 0.8455 - val_loss: 0.6393 - val_accuracy: 0.7708\n",
            "Epoch 1175/1200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.3486 - accuracy: 0.8559 - val_loss: 0.6408 - val_accuracy: 0.7656\n",
            "Epoch 1176/1200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3496 - accuracy: 0.8542 - val_loss: 0.6396 - val_accuracy: 0.7656\n",
            "Epoch 1177/1200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3488 - accuracy: 0.8524 - val_loss: 0.6375 - val_accuracy: 0.7656\n",
            "Epoch 1178/1200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3489 - accuracy: 0.8507 - val_loss: 0.6389 - val_accuracy: 0.7656\n",
            "Epoch 1179/1200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3498 - accuracy: 0.8542 - val_loss: 0.6393 - val_accuracy: 0.7708\n",
            "Epoch 1180/1200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3493 - accuracy: 0.8542 - val_loss: 0.6411 - val_accuracy: 0.7708\n",
            "Epoch 1181/1200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3494 - accuracy: 0.8507 - val_loss: 0.6397 - val_accuracy: 0.7656\n",
            "Epoch 1182/1200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3486 - accuracy: 0.8559 - val_loss: 0.6399 - val_accuracy: 0.7708\n",
            "Epoch 1183/1200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3487 - accuracy: 0.8542 - val_loss: 0.6409 - val_accuracy: 0.7708\n",
            "Epoch 1184/1200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.3494 - accuracy: 0.8559 - val_loss: 0.6383 - val_accuracy: 0.7708\n",
            "Epoch 1185/1200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3492 - accuracy: 0.8524 - val_loss: 0.6394 - val_accuracy: 0.7708\n",
            "Epoch 1186/1200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3496 - accuracy: 0.8524 - val_loss: 0.6415 - val_accuracy: 0.7656\n",
            "Epoch 1187/1200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3483 - accuracy: 0.8490 - val_loss: 0.6354 - val_accuracy: 0.7656\n",
            "Epoch 1188/1200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3492 - accuracy: 0.8542 - val_loss: 0.6387 - val_accuracy: 0.7708\n",
            "Epoch 1189/1200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3488 - accuracy: 0.8524 - val_loss: 0.6424 - val_accuracy: 0.7760\n",
            "Epoch 1190/1200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3485 - accuracy: 0.8542 - val_loss: 0.6402 - val_accuracy: 0.7708\n",
            "Epoch 1191/1200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3488 - accuracy: 0.8542 - val_loss: 0.6431 - val_accuracy: 0.7708\n",
            "Epoch 1192/1200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3485 - accuracy: 0.8524 - val_loss: 0.6385 - val_accuracy: 0.7708\n",
            "Epoch 1193/1200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3498 - accuracy: 0.8507 - val_loss: 0.6388 - val_accuracy: 0.7708\n",
            "Epoch 1194/1200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3479 - accuracy: 0.8507 - val_loss: 0.6386 - val_accuracy: 0.7656\n",
            "Epoch 1195/1200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3499 - accuracy: 0.8542 - val_loss: 0.6400 - val_accuracy: 0.7656\n",
            "Epoch 1196/1200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3486 - accuracy: 0.8472 - val_loss: 0.6445 - val_accuracy: 0.7656\n",
            "Epoch 1197/1200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3498 - accuracy: 0.8542 - val_loss: 0.6408 - val_accuracy: 0.7708\n",
            "Epoch 1198/1200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3488 - accuracy: 0.8490 - val_loss: 0.6415 - val_accuracy: 0.7708\n",
            "Epoch 1199/1200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3489 - accuracy: 0.8524 - val_loss: 0.6419 - val_accuracy: 0.7656\n",
            "Epoch 1200/1200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3487 - accuracy: 0.8455 - val_loss: 0.6382 - val_accuracy: 0.7656\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot the loss and val_loss\n",
        "fig, ax = plt.subplots(figsize=(12, 6))\n",
        "ax.plot(run_hist_4.history[\"loss\"],'r', marker='.', label=\"Train Loss\")\n",
        "ax.plot(run_hist_4.history[\"val_loss\"],'b', marker='.', label=\"Validation Loss\")\n",
        "ax.legend()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 539
        },
        "id": "dNoh9BFoNJOT",
        "outputId": "e5845e49-14bc-485b-985b-03c9b8b21a48"
      },
      "id": "dNoh9BFoNJOT",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x78b818a22e30>"
            ]
          },
          "metadata": {},
          "execution_count": 46
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Interpretation**: Upon changing the network structure with a hidden layer of 3, learning_rate of 0.004 and epochs of 1200, the results shows above that the train loss is decreasing which means  that my model is gradually improving its ability to make predictions on the training data. However, the validation loss is decreasing but suddenly it increased this means that my model was initially learning to generalize well to unseen data, but at a certain point, it started to overfit the validation set or encountered difficulties in further improving its performance. Even though I used a relatively low of learning_rate still the model lead to overfitting, it is because I put a high number of epochs, where the model has more opportunities to memorize the training data, which can lead to overfitting same as sample number 1.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "ETdgM64XNemu"
      },
      "id": "ETdgM64XNemu"
    },
    {
      "cell_type": "markdown",
      "source": [
        "# SAMPLE NUMBER 2."
      ],
      "metadata": {
        "id": "TLsDAlzVSJRm"
      },
      "id": "TLsDAlzVSJRm"
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import confusion_matrix, precision_recall_curve, roc_auc_score, roc_curve, accuracy_score\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "import seaborn as sns\n",
        "\n",
        "%matplotlib inline\n",
        "\n",
        "## Import Keras objects for Deep Learning\n",
        "\n",
        "from keras.models  import Sequential\n",
        "from keras.layers import Input, Dense, Flatten, Dropout, BatchNormalization\n",
        "from keras.optimizers import Adam, SGD, RMSprop\n",
        "\n",
        "# Load the dataset\n",
        "filepath = \"pima-indians-diabetes.csv\"\n",
        "names = [\"times_pregnant\", \"glucose_tolerance_test\", \"blood_pressure\", \"skin_thickness\", \"insulin\",\n",
        "         \"bmi\", \"pedigree_function\", \"age\", \"has_diabetes\"]\n",
        "diabetes_df = pd.read_csv(filepath, names=names)\n",
        "\n",
        "X = diabetes_df.iloc[:, :-1].values\n",
        "y = diabetes_df[\"has_diabetes\"].values\n",
        "\n",
        "# Split the data into 75% for train set and 25% for test set\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=11111)\n",
        "\n",
        "# Normalize the data\n",
        "normalizer = StandardScaler()\n",
        "X_train_norm = normalizer.fit_transform(X_train)\n",
        "X_test_norm = normalizer.transform(X_test)"
      ],
      "metadata": {
        "id": "XNcZlbH1NJM6"
      },
      "id": "XNcZlbH1NJM6",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Learning rate = 0.007\n",
        "- Epochs = 1100\n",
        "- Network structure = 4 hidden layers\n"
      ],
      "metadata": {
        "id": "RS0tRrYTOKmp"
      },
      "id": "RS0tRrYTOKmp"
    },
    {
      "cell_type": "code",
      "source": [
        "model_supple_3  = Sequential([\n",
        "    Dense(5, input_shape=(8,), activation=\"relu\"),\n",
        "    Dense(5, activation=\"relu\"),\n",
        "    Dense(3, activation=\"relu\"),\n",
        "    Dense(1, activation=\"relu\"),\n",
        "    Dense(1, activation=\"sigmoid\")\n",
        "])"
      ],
      "metadata": {
        "id": "8k4-NJj2OBPy"
      },
      "id": "8k4-NJj2OBPy",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_supple_3.compile(SGD(lr = .007), \"binary_crossentropy\", metrics=[\"accuracy\"])\n",
        "run_hist_5 = model_supple_3.fit(X_train_norm, y_train, validation_data=(X_test_norm, y_test), epochs=1100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nYhSNtTsO1QZ",
        "outputId": "60312c9c-1d16-4d38-bfef-174f03199d61"
      },
      "id": "nYhSNtTsO1QZ",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.SGD.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/1100\n",
            "18/18 [==============================] - 1s 13ms/step - loss: 0.6919 - accuracy: 0.6163 - val_loss: 0.6833 - val_accuracy: 0.6667\n",
            "Epoch 2/1100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6869 - accuracy: 0.6615 - val_loss: 0.6793 - val_accuracy: 0.7240\n",
            "Epoch 3/1100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6825 - accuracy: 0.6649 - val_loss: 0.6757 - val_accuracy: 0.7083\n",
            "Epoch 4/1100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6787 - accuracy: 0.6632 - val_loss: 0.6724 - val_accuracy: 0.7188\n",
            "Epoch 5/1100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6751 - accuracy: 0.6753 - val_loss: 0.6693 - val_accuracy: 0.7188\n",
            "Epoch 6/1100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6719 - accuracy: 0.6753 - val_loss: 0.6666 - val_accuracy: 0.7031\n",
            "Epoch 7/1100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6690 - accuracy: 0.6632 - val_loss: 0.6641 - val_accuracy: 0.6875\n",
            "Epoch 8/1100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6662 - accuracy: 0.6597 - val_loss: 0.6617 - val_accuracy: 0.6667\n",
            "Epoch 9/1100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6637 - accuracy: 0.6615 - val_loss: 0.6595 - val_accuracy: 0.6667\n",
            "Epoch 10/1100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6614 - accuracy: 0.6562 - val_loss: 0.6575 - val_accuracy: 0.6667\n",
            "Epoch 11/1100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6593 - accuracy: 0.6510 - val_loss: 0.6556 - val_accuracy: 0.6510\n",
            "Epoch 12/1100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6573 - accuracy: 0.6493 - val_loss: 0.6539 - val_accuracy: 0.6510\n",
            "Epoch 13/1100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6555 - accuracy: 0.6510 - val_loss: 0.6522 - val_accuracy: 0.6510\n",
            "Epoch 14/1100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6537 - accuracy: 0.6510 - val_loss: 0.6507 - val_accuracy: 0.6406\n",
            "Epoch 15/1100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6521 - accuracy: 0.6545 - val_loss: 0.6492 - val_accuracy: 0.6406\n",
            "Epoch 16/1100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6506 - accuracy: 0.6510 - val_loss: 0.6478 - val_accuracy: 0.6406\n",
            "Epoch 17/1100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6492 - accuracy: 0.6510 - val_loss: 0.6465 - val_accuracy: 0.6406\n",
            "Epoch 18/1100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6478 - accuracy: 0.6510 - val_loss: 0.6452 - val_accuracy: 0.6406\n",
            "Epoch 19/1100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6466 - accuracy: 0.6528 - val_loss: 0.6440 - val_accuracy: 0.6406\n",
            "Epoch 20/1100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6454 - accuracy: 0.6510 - val_loss: 0.6429 - val_accuracy: 0.6406\n",
            "Epoch 21/1100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6443 - accuracy: 0.6510 - val_loss: 0.6418 - val_accuracy: 0.6406\n",
            "Epoch 22/1100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6432 - accuracy: 0.6510 - val_loss: 0.6408 - val_accuracy: 0.6406\n",
            "Epoch 23/1100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6422 - accuracy: 0.6510 - val_loss: 0.6398 - val_accuracy: 0.6406\n",
            "Epoch 24/1100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6412 - accuracy: 0.6510 - val_loss: 0.6389 - val_accuracy: 0.6406\n",
            "Epoch 25/1100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6403 - accuracy: 0.6510 - val_loss: 0.6379 - val_accuracy: 0.6406\n",
            "Epoch 26/1100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6394 - accuracy: 0.6528 - val_loss: 0.6370 - val_accuracy: 0.6406\n",
            "Epoch 27/1100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6385 - accuracy: 0.6528 - val_loss: 0.6360 - val_accuracy: 0.6406\n",
            "Epoch 28/1100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6377 - accuracy: 0.6528 - val_loss: 0.6350 - val_accuracy: 0.6406\n",
            "Epoch 29/1100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6367 - accuracy: 0.6528 - val_loss: 0.6339 - val_accuracy: 0.6406\n",
            "Epoch 30/1100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6358 - accuracy: 0.6528 - val_loss: 0.6329 - val_accuracy: 0.6406\n",
            "Epoch 31/1100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6349 - accuracy: 0.6528 - val_loss: 0.6319 - val_accuracy: 0.6406\n",
            "Epoch 32/1100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6340 - accuracy: 0.6528 - val_loss: 0.6308 - val_accuracy: 0.6406\n",
            "Epoch 33/1100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6331 - accuracy: 0.6545 - val_loss: 0.6298 - val_accuracy: 0.6406\n",
            "Epoch 34/1100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6322 - accuracy: 0.6545 - val_loss: 0.6287 - val_accuracy: 0.6406\n",
            "Epoch 35/1100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6312 - accuracy: 0.6545 - val_loss: 0.6276 - val_accuracy: 0.6406\n",
            "Epoch 36/1100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6303 - accuracy: 0.6528 - val_loss: 0.6264 - val_accuracy: 0.6406\n",
            "Epoch 37/1100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6294 - accuracy: 0.6528 - val_loss: 0.6252 - val_accuracy: 0.6458\n",
            "Epoch 38/1100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6283 - accuracy: 0.6528 - val_loss: 0.6239 - val_accuracy: 0.6510\n",
            "Epoch 39/1100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6273 - accuracy: 0.6545 - val_loss: 0.6225 - val_accuracy: 0.6562\n",
            "Epoch 40/1100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6264 - accuracy: 0.6510 - val_loss: 0.6211 - val_accuracy: 0.6667\n",
            "Epoch 41/1100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6252 - accuracy: 0.6510 - val_loss: 0.6196 - val_accuracy: 0.6667\n",
            "Epoch 42/1100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6241 - accuracy: 0.6562 - val_loss: 0.6181 - val_accuracy: 0.6667\n",
            "Epoch 43/1100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6229 - accuracy: 0.6597 - val_loss: 0.6165 - val_accuracy: 0.6719\n",
            "Epoch 44/1100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6218 - accuracy: 0.6615 - val_loss: 0.6149 - val_accuracy: 0.6719\n",
            "Epoch 45/1100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6206 - accuracy: 0.6632 - val_loss: 0.6133 - val_accuracy: 0.6771\n",
            "Epoch 46/1100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6195 - accuracy: 0.6649 - val_loss: 0.6116 - val_accuracy: 0.6771\n",
            "Epoch 47/1100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6182 - accuracy: 0.6684 - val_loss: 0.6099 - val_accuracy: 0.6771\n",
            "Epoch 48/1100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6170 - accuracy: 0.6719 - val_loss: 0.6081 - val_accuracy: 0.6823\n",
            "Epoch 49/1100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6157 - accuracy: 0.6719 - val_loss: 0.6064 - val_accuracy: 0.6823\n",
            "Epoch 50/1100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6144 - accuracy: 0.6701 - val_loss: 0.6045 - val_accuracy: 0.6823\n",
            "Epoch 51/1100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6130 - accuracy: 0.6701 - val_loss: 0.6026 - val_accuracy: 0.6875\n",
            "Epoch 52/1100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6117 - accuracy: 0.6736 - val_loss: 0.6007 - val_accuracy: 0.6927\n",
            "Epoch 53/1100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6104 - accuracy: 0.6753 - val_loss: 0.5987 - val_accuracy: 0.6979\n",
            "Epoch 54/1100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6090 - accuracy: 0.6753 - val_loss: 0.5967 - val_accuracy: 0.7031\n",
            "Epoch 55/1100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6077 - accuracy: 0.6736 - val_loss: 0.5947 - val_accuracy: 0.7083\n",
            "Epoch 56/1100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6062 - accuracy: 0.6823 - val_loss: 0.5926 - val_accuracy: 0.7292\n",
            "Epoch 57/1100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6048 - accuracy: 0.6875 - val_loss: 0.5906 - val_accuracy: 0.7344\n",
            "Epoch 58/1100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6034 - accuracy: 0.6962 - val_loss: 0.5885 - val_accuracy: 0.7344\n",
            "Epoch 59/1100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6020 - accuracy: 0.6997 - val_loss: 0.5864 - val_accuracy: 0.7396\n",
            "Epoch 60/1100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6007 - accuracy: 0.6910 - val_loss: 0.5844 - val_accuracy: 0.7396\n",
            "Epoch 61/1100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5992 - accuracy: 0.6979 - val_loss: 0.5823 - val_accuracy: 0.7396\n",
            "Epoch 62/1100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5979 - accuracy: 0.6997 - val_loss: 0.5802 - val_accuracy: 0.7396\n",
            "Epoch 63/1100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5965 - accuracy: 0.7083 - val_loss: 0.5782 - val_accuracy: 0.7396\n",
            "Epoch 64/1100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5952 - accuracy: 0.7101 - val_loss: 0.5762 - val_accuracy: 0.7344\n",
            "Epoch 65/1100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5939 - accuracy: 0.7101 - val_loss: 0.5743 - val_accuracy: 0.7344\n",
            "Epoch 66/1100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5926 - accuracy: 0.7118 - val_loss: 0.5723 - val_accuracy: 0.7344\n",
            "Epoch 67/1100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5913 - accuracy: 0.7118 - val_loss: 0.5704 - val_accuracy: 0.7344\n",
            "Epoch 68/1100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5901 - accuracy: 0.7118 - val_loss: 0.5685 - val_accuracy: 0.7344\n",
            "Epoch 69/1100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5890 - accuracy: 0.7118 - val_loss: 0.5667 - val_accuracy: 0.7396\n",
            "Epoch 70/1100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5877 - accuracy: 0.7101 - val_loss: 0.5650 - val_accuracy: 0.7448\n",
            "Epoch 71/1100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5866 - accuracy: 0.7153 - val_loss: 0.5633 - val_accuracy: 0.7396\n",
            "Epoch 72/1100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5856 - accuracy: 0.7170 - val_loss: 0.5617 - val_accuracy: 0.7500\n",
            "Epoch 73/1100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5844 - accuracy: 0.7205 - val_loss: 0.5600 - val_accuracy: 0.7552\n",
            "Epoch 74/1100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5834 - accuracy: 0.7188 - val_loss: 0.5584 - val_accuracy: 0.7552\n",
            "Epoch 75/1100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5822 - accuracy: 0.7205 - val_loss: 0.5569 - val_accuracy: 0.7552\n",
            "Epoch 76/1100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5812 - accuracy: 0.7153 - val_loss: 0.5555 - val_accuracy: 0.7552\n",
            "Epoch 77/1100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5802 - accuracy: 0.7222 - val_loss: 0.5540 - val_accuracy: 0.7552\n",
            "Epoch 78/1100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5792 - accuracy: 0.7205 - val_loss: 0.5525 - val_accuracy: 0.7552\n",
            "Epoch 79/1100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5782 - accuracy: 0.7205 - val_loss: 0.5511 - val_accuracy: 0.7552\n",
            "Epoch 80/1100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5772 - accuracy: 0.7188 - val_loss: 0.5499 - val_accuracy: 0.7552\n",
            "Epoch 81/1100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5762 - accuracy: 0.7170 - val_loss: 0.5487 - val_accuracy: 0.7500\n",
            "Epoch 82/1100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5752 - accuracy: 0.7170 - val_loss: 0.5475 - val_accuracy: 0.7500\n",
            "Epoch 83/1100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5742 - accuracy: 0.7205 - val_loss: 0.5463 - val_accuracy: 0.7500\n",
            "Epoch 84/1100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5732 - accuracy: 0.7205 - val_loss: 0.5450 - val_accuracy: 0.7604\n",
            "Epoch 85/1100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5723 - accuracy: 0.7188 - val_loss: 0.5438 - val_accuracy: 0.7604\n",
            "Epoch 86/1100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5713 - accuracy: 0.7222 - val_loss: 0.5428 - val_accuracy: 0.7604\n",
            "Epoch 87/1100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5703 - accuracy: 0.7222 - val_loss: 0.5416 - val_accuracy: 0.7604\n",
            "Epoch 88/1100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5695 - accuracy: 0.7240 - val_loss: 0.5406 - val_accuracy: 0.7604\n",
            "Epoch 89/1100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5688 - accuracy: 0.7205 - val_loss: 0.5395 - val_accuracy: 0.7552\n",
            "Epoch 90/1100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5677 - accuracy: 0.7240 - val_loss: 0.5384 - val_accuracy: 0.7604\n",
            "Epoch 91/1100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5669 - accuracy: 0.7257 - val_loss: 0.5374 - val_accuracy: 0.7656\n",
            "Epoch 92/1100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5660 - accuracy: 0.7257 - val_loss: 0.5365 - val_accuracy: 0.7656\n",
            "Epoch 93/1100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5650 - accuracy: 0.7257 - val_loss: 0.5355 - val_accuracy: 0.7656\n",
            "Epoch 94/1100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5643 - accuracy: 0.7274 - val_loss: 0.5347 - val_accuracy: 0.7656\n",
            "Epoch 95/1100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5634 - accuracy: 0.7240 - val_loss: 0.5337 - val_accuracy: 0.7656\n",
            "Epoch 96/1100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5626 - accuracy: 0.7274 - val_loss: 0.5328 - val_accuracy: 0.7656\n",
            "Epoch 97/1100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5616 - accuracy: 0.7292 - val_loss: 0.5319 - val_accuracy: 0.7760\n",
            "Epoch 98/1100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5608 - accuracy: 0.7309 - val_loss: 0.5310 - val_accuracy: 0.7812\n",
            "Epoch 99/1100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5599 - accuracy: 0.7326 - val_loss: 0.5300 - val_accuracy: 0.7812\n",
            "Epoch 100/1100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5591 - accuracy: 0.7309 - val_loss: 0.5292 - val_accuracy: 0.7812\n",
            "Epoch 101/1100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5581 - accuracy: 0.7292 - val_loss: 0.5284 - val_accuracy: 0.7760\n",
            "Epoch 102/1100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5573 - accuracy: 0.7326 - val_loss: 0.5277 - val_accuracy: 0.7760\n",
            "Epoch 103/1100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5564 - accuracy: 0.7309 - val_loss: 0.5269 - val_accuracy: 0.7708\n",
            "Epoch 104/1100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5557 - accuracy: 0.7309 - val_loss: 0.5261 - val_accuracy: 0.7708\n",
            "Epoch 105/1100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5548 - accuracy: 0.7326 - val_loss: 0.5253 - val_accuracy: 0.7708\n",
            "Epoch 106/1100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5539 - accuracy: 0.7361 - val_loss: 0.5245 - val_accuracy: 0.7708\n",
            "Epoch 107/1100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5531 - accuracy: 0.7326 - val_loss: 0.5236 - val_accuracy: 0.7708\n",
            "Epoch 108/1100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5521 - accuracy: 0.7344 - val_loss: 0.5230 - val_accuracy: 0.7708\n",
            "Epoch 109/1100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5514 - accuracy: 0.7378 - val_loss: 0.5223 - val_accuracy: 0.7760\n",
            "Epoch 110/1100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5507 - accuracy: 0.7344 - val_loss: 0.5215 - val_accuracy: 0.7708\n",
            "Epoch 111/1100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5498 - accuracy: 0.7344 - val_loss: 0.5208 - val_accuracy: 0.7708\n",
            "Epoch 112/1100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5491 - accuracy: 0.7378 - val_loss: 0.5202 - val_accuracy: 0.7708\n",
            "Epoch 113/1100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5482 - accuracy: 0.7361 - val_loss: 0.5196 - val_accuracy: 0.7708\n",
            "Epoch 114/1100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5474 - accuracy: 0.7378 - val_loss: 0.5190 - val_accuracy: 0.7708\n",
            "Epoch 115/1100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5467 - accuracy: 0.7361 - val_loss: 0.5185 - val_accuracy: 0.7760\n",
            "Epoch 116/1100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5459 - accuracy: 0.7344 - val_loss: 0.5179 - val_accuracy: 0.7760\n",
            "Epoch 117/1100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5451 - accuracy: 0.7361 - val_loss: 0.5173 - val_accuracy: 0.7760\n",
            "Epoch 118/1100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5443 - accuracy: 0.7344 - val_loss: 0.5166 - val_accuracy: 0.7760\n",
            "Epoch 119/1100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5438 - accuracy: 0.7361 - val_loss: 0.5161 - val_accuracy: 0.7760\n",
            "Epoch 120/1100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5430 - accuracy: 0.7326 - val_loss: 0.5155 - val_accuracy: 0.7760\n",
            "Epoch 121/1100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5422 - accuracy: 0.7361 - val_loss: 0.5150 - val_accuracy: 0.7708\n",
            "Epoch 122/1100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5414 - accuracy: 0.7361 - val_loss: 0.5145 - val_accuracy: 0.7708\n",
            "Epoch 123/1100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5407 - accuracy: 0.7378 - val_loss: 0.5139 - val_accuracy: 0.7708\n",
            "Epoch 124/1100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5401 - accuracy: 0.7396 - val_loss: 0.5135 - val_accuracy: 0.7708\n",
            "Epoch 125/1100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5392 - accuracy: 0.7413 - val_loss: 0.5128 - val_accuracy: 0.7708\n",
            "Epoch 126/1100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5383 - accuracy: 0.7396 - val_loss: 0.5125 - val_accuracy: 0.7708\n",
            "Epoch 127/1100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5377 - accuracy: 0.7413 - val_loss: 0.5120 - val_accuracy: 0.7708\n",
            "Epoch 128/1100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5367 - accuracy: 0.7431 - val_loss: 0.5116 - val_accuracy: 0.7708\n",
            "Epoch 129/1100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5362 - accuracy: 0.7465 - val_loss: 0.5112 - val_accuracy: 0.7708\n",
            "Epoch 130/1100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5355 - accuracy: 0.7483 - val_loss: 0.5107 - val_accuracy: 0.7708\n",
            "Epoch 131/1100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5344 - accuracy: 0.7517 - val_loss: 0.5103 - val_accuracy: 0.7708\n",
            "Epoch 132/1100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5338 - accuracy: 0.7517 - val_loss: 0.5098 - val_accuracy: 0.7708\n",
            "Epoch 133/1100\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5331 - accuracy: 0.7552 - val_loss: 0.5096 - val_accuracy: 0.7708\n",
            "Epoch 134/1100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5321 - accuracy: 0.7552 - val_loss: 0.5091 - val_accuracy: 0.7708\n",
            "Epoch 135/1100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5315 - accuracy: 0.7552 - val_loss: 0.5088 - val_accuracy: 0.7760\n",
            "Epoch 136/1100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5307 - accuracy: 0.7587 - val_loss: 0.5084 - val_accuracy: 0.7760\n",
            "Epoch 137/1100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5298 - accuracy: 0.7569 - val_loss: 0.5079 - val_accuracy: 0.7812\n",
            "Epoch 138/1100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5291 - accuracy: 0.7569 - val_loss: 0.5075 - val_accuracy: 0.7812\n",
            "Epoch 139/1100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5284 - accuracy: 0.7552 - val_loss: 0.5073 - val_accuracy: 0.7812\n",
            "Epoch 140/1100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5277 - accuracy: 0.7587 - val_loss: 0.5067 - val_accuracy: 0.7812\n",
            "Epoch 141/1100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5268 - accuracy: 0.7569 - val_loss: 0.5063 - val_accuracy: 0.7812\n",
            "Epoch 142/1100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5260 - accuracy: 0.7569 - val_loss: 0.5059 - val_accuracy: 0.7812\n",
            "Epoch 143/1100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5252 - accuracy: 0.7604 - val_loss: 0.5055 - val_accuracy: 0.7812\n",
            "Epoch 144/1100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5245 - accuracy: 0.7569 - val_loss: 0.5051 - val_accuracy: 0.7812\n",
            "Epoch 145/1100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5243 - accuracy: 0.7569 - val_loss: 0.5049 - val_accuracy: 0.7812\n",
            "Epoch 146/1100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5230 - accuracy: 0.7569 - val_loss: 0.5045 - val_accuracy: 0.7812\n",
            "Epoch 147/1100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5224 - accuracy: 0.7569 - val_loss: 0.5042 - val_accuracy: 0.7812\n",
            "Epoch 148/1100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5219 - accuracy: 0.7569 - val_loss: 0.5038 - val_accuracy: 0.7812\n",
            "Epoch 149/1100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5213 - accuracy: 0.7569 - val_loss: 0.5034 - val_accuracy: 0.7812\n",
            "Epoch 150/1100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5205 - accuracy: 0.7569 - val_loss: 0.5029 - val_accuracy: 0.7812\n",
            "Epoch 151/1100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5196 - accuracy: 0.7587 - val_loss: 0.5026 - val_accuracy: 0.7812\n",
            "Epoch 152/1100\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.5190 - accuracy: 0.7622 - val_loss: 0.5022 - val_accuracy: 0.7760\n",
            "Epoch 153/1100\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5184 - accuracy: 0.7622 - val_loss: 0.5020 - val_accuracy: 0.7760\n",
            "Epoch 154/1100\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5175 - accuracy: 0.7622 - val_loss: 0.5017 - val_accuracy: 0.7760\n",
            "Epoch 155/1100\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5170 - accuracy: 0.7639 - val_loss: 0.5014 - val_accuracy: 0.7760\n",
            "Epoch 156/1100\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5163 - accuracy: 0.7656 - val_loss: 0.5012 - val_accuracy: 0.7760\n",
            "Epoch 157/1100\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5157 - accuracy: 0.7708 - val_loss: 0.5010 - val_accuracy: 0.7760\n",
            "Epoch 158/1100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5151 - accuracy: 0.7656 - val_loss: 0.5007 - val_accuracy: 0.7760\n",
            "Epoch 159/1100\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5145 - accuracy: 0.7691 - val_loss: 0.5005 - val_accuracy: 0.7760\n",
            "Epoch 160/1100\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5138 - accuracy: 0.7708 - val_loss: 0.5003 - val_accuracy: 0.7760\n",
            "Epoch 161/1100\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5132 - accuracy: 0.7691 - val_loss: 0.5001 - val_accuracy: 0.7760\n",
            "Epoch 162/1100\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5124 - accuracy: 0.7708 - val_loss: 0.4999 - val_accuracy: 0.7760\n",
            "Epoch 163/1100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5115 - accuracy: 0.7639 - val_loss: 0.4996 - val_accuracy: 0.7760\n",
            "Epoch 164/1100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5109 - accuracy: 0.7743 - val_loss: 0.4993 - val_accuracy: 0.7760\n",
            "Epoch 165/1100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5099 - accuracy: 0.7708 - val_loss: 0.4990 - val_accuracy: 0.7760\n",
            "Epoch 166/1100\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.5093 - accuracy: 0.7708 - val_loss: 0.4988 - val_accuracy: 0.7656\n",
            "Epoch 167/1100\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5082 - accuracy: 0.7726 - val_loss: 0.4985 - val_accuracy: 0.7656\n",
            "Epoch 168/1100\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5074 - accuracy: 0.7760 - val_loss: 0.4983 - val_accuracy: 0.7656\n",
            "Epoch 169/1100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5069 - accuracy: 0.7726 - val_loss: 0.4981 - val_accuracy: 0.7656\n",
            "Epoch 170/1100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5058 - accuracy: 0.7708 - val_loss: 0.4979 - val_accuracy: 0.7656\n",
            "Epoch 171/1100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5049 - accuracy: 0.7708 - val_loss: 0.4978 - val_accuracy: 0.7604\n",
            "Epoch 172/1100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5043 - accuracy: 0.7674 - val_loss: 0.4975 - val_accuracy: 0.7604\n",
            "Epoch 173/1100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5033 - accuracy: 0.7726 - val_loss: 0.4974 - val_accuracy: 0.7604\n",
            "Epoch 174/1100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5026 - accuracy: 0.7708 - val_loss: 0.4972 - val_accuracy: 0.7604\n",
            "Epoch 175/1100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5020 - accuracy: 0.7708 - val_loss: 0.4970 - val_accuracy: 0.7604\n",
            "Epoch 176/1100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5012 - accuracy: 0.7743 - val_loss: 0.4967 - val_accuracy: 0.7604\n",
            "Epoch 177/1100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5007 - accuracy: 0.7726 - val_loss: 0.4965 - val_accuracy: 0.7604\n",
            "Epoch 178/1100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5001 - accuracy: 0.7708 - val_loss: 0.4963 - val_accuracy: 0.7604\n",
            "Epoch 179/1100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4997 - accuracy: 0.7726 - val_loss: 0.4960 - val_accuracy: 0.7604\n",
            "Epoch 180/1100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4988 - accuracy: 0.7726 - val_loss: 0.4959 - val_accuracy: 0.7604\n",
            "Epoch 181/1100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4981 - accuracy: 0.7726 - val_loss: 0.4957 - val_accuracy: 0.7604\n",
            "Epoch 182/1100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4979 - accuracy: 0.7760 - val_loss: 0.4954 - val_accuracy: 0.7604\n",
            "Epoch 183/1100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4971 - accuracy: 0.7743 - val_loss: 0.4951 - val_accuracy: 0.7604\n",
            "Epoch 184/1100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4965 - accuracy: 0.7743 - val_loss: 0.4949 - val_accuracy: 0.7604\n",
            "Epoch 185/1100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4958 - accuracy: 0.7760 - val_loss: 0.4945 - val_accuracy: 0.7604\n",
            "Epoch 186/1100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4956 - accuracy: 0.7760 - val_loss: 0.4943 - val_accuracy: 0.7604\n",
            "Epoch 187/1100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4948 - accuracy: 0.7778 - val_loss: 0.4940 - val_accuracy: 0.7604\n",
            "Epoch 188/1100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4945 - accuracy: 0.7743 - val_loss: 0.4938 - val_accuracy: 0.7604\n",
            "Epoch 189/1100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4937 - accuracy: 0.7760 - val_loss: 0.4937 - val_accuracy: 0.7604\n",
            "Epoch 190/1100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4933 - accuracy: 0.7760 - val_loss: 0.4933 - val_accuracy: 0.7604\n",
            "Epoch 191/1100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4930 - accuracy: 0.7778 - val_loss: 0.4931 - val_accuracy: 0.7604\n",
            "Epoch 192/1100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4925 - accuracy: 0.7743 - val_loss: 0.4929 - val_accuracy: 0.7604\n",
            "Epoch 193/1100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4920 - accuracy: 0.7778 - val_loss: 0.4928 - val_accuracy: 0.7604\n",
            "Epoch 194/1100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4916 - accuracy: 0.7795 - val_loss: 0.4925 - val_accuracy: 0.7604\n",
            "Epoch 195/1100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4910 - accuracy: 0.7830 - val_loss: 0.4923 - val_accuracy: 0.7604\n",
            "Epoch 196/1100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4906 - accuracy: 0.7743 - val_loss: 0.4921 - val_accuracy: 0.7604\n",
            "Epoch 197/1100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4903 - accuracy: 0.7778 - val_loss: 0.4918 - val_accuracy: 0.7604\n",
            "Epoch 198/1100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4898 - accuracy: 0.7743 - val_loss: 0.4916 - val_accuracy: 0.7604\n",
            "Epoch 199/1100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4892 - accuracy: 0.7778 - val_loss: 0.4914 - val_accuracy: 0.7604\n",
            "Epoch 200/1100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4886 - accuracy: 0.7726 - val_loss: 0.4913 - val_accuracy: 0.7604\n",
            "Epoch 201/1100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4884 - accuracy: 0.7778 - val_loss: 0.4910 - val_accuracy: 0.7604\n",
            "Epoch 202/1100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4881 - accuracy: 0.7760 - val_loss: 0.4908 - val_accuracy: 0.7604\n",
            "Epoch 203/1100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4880 - accuracy: 0.7760 - val_loss: 0.4907 - val_accuracy: 0.7604\n",
            "Epoch 204/1100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4877 - accuracy: 0.7778 - val_loss: 0.4906 - val_accuracy: 0.7604\n",
            "Epoch 205/1100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4871 - accuracy: 0.7778 - val_loss: 0.4906 - val_accuracy: 0.7604\n",
            "Epoch 206/1100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4869 - accuracy: 0.7812 - val_loss: 0.4903 - val_accuracy: 0.7604\n",
            "Epoch 207/1100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4864 - accuracy: 0.7778 - val_loss: 0.4901 - val_accuracy: 0.7604\n",
            "Epoch 208/1100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4859 - accuracy: 0.7778 - val_loss: 0.4899 - val_accuracy: 0.7604\n",
            "Epoch 209/1100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4859 - accuracy: 0.7795 - val_loss: 0.4897 - val_accuracy: 0.7604\n",
            "Epoch 210/1100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4855 - accuracy: 0.7795 - val_loss: 0.4895 - val_accuracy: 0.7604\n",
            "Epoch 211/1100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4854 - accuracy: 0.7760 - val_loss: 0.4894 - val_accuracy: 0.7604\n",
            "Epoch 212/1100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4851 - accuracy: 0.7778 - val_loss: 0.4892 - val_accuracy: 0.7604\n",
            "Epoch 213/1100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4846 - accuracy: 0.7795 - val_loss: 0.4890 - val_accuracy: 0.7604\n",
            "Epoch 214/1100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4845 - accuracy: 0.7795 - val_loss: 0.4888 - val_accuracy: 0.7604\n",
            "Epoch 215/1100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4843 - accuracy: 0.7795 - val_loss: 0.4887 - val_accuracy: 0.7604\n",
            "Epoch 216/1100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4841 - accuracy: 0.7795 - val_loss: 0.4885 - val_accuracy: 0.7604\n",
            "Epoch 217/1100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4834 - accuracy: 0.7778 - val_loss: 0.4883 - val_accuracy: 0.7604\n",
            "Epoch 218/1100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4831 - accuracy: 0.7795 - val_loss: 0.4882 - val_accuracy: 0.7604\n",
            "Epoch 219/1100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4829 - accuracy: 0.7795 - val_loss: 0.4880 - val_accuracy: 0.7656\n",
            "Epoch 220/1100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4826 - accuracy: 0.7743 - val_loss: 0.4879 - val_accuracy: 0.7656\n",
            "Epoch 221/1100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4823 - accuracy: 0.7830 - val_loss: 0.4877 - val_accuracy: 0.7656\n",
            "Epoch 222/1100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4821 - accuracy: 0.7812 - val_loss: 0.4876 - val_accuracy: 0.7656\n",
            "Epoch 223/1100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4819 - accuracy: 0.7812 - val_loss: 0.4875 - val_accuracy: 0.7656\n",
            "Epoch 224/1100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4822 - accuracy: 0.7830 - val_loss: 0.4873 - val_accuracy: 0.7604\n",
            "Epoch 225/1100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4812 - accuracy: 0.7812 - val_loss: 0.4872 - val_accuracy: 0.7604\n",
            "Epoch 226/1100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4814 - accuracy: 0.7778 - val_loss: 0.4870 - val_accuracy: 0.7604\n",
            "Epoch 227/1100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4807 - accuracy: 0.7847 - val_loss: 0.4869 - val_accuracy: 0.7604\n",
            "Epoch 228/1100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4807 - accuracy: 0.7812 - val_loss: 0.4868 - val_accuracy: 0.7604\n",
            "Epoch 229/1100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4808 - accuracy: 0.7847 - val_loss: 0.4867 - val_accuracy: 0.7604\n",
            "Epoch 230/1100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4803 - accuracy: 0.7795 - val_loss: 0.4866 - val_accuracy: 0.7604\n",
            "Epoch 231/1100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4801 - accuracy: 0.7830 - val_loss: 0.4865 - val_accuracy: 0.7604\n",
            "Epoch 232/1100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4798 - accuracy: 0.7812 - val_loss: 0.4864 - val_accuracy: 0.7604\n",
            "Epoch 233/1100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4797 - accuracy: 0.7812 - val_loss: 0.4862 - val_accuracy: 0.7604\n",
            "Epoch 234/1100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4795 - accuracy: 0.7812 - val_loss: 0.4862 - val_accuracy: 0.7604\n",
            "Epoch 235/1100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4792 - accuracy: 0.7847 - val_loss: 0.4861 - val_accuracy: 0.7604\n",
            "Epoch 236/1100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4793 - accuracy: 0.7830 - val_loss: 0.4860 - val_accuracy: 0.7604\n",
            "Epoch 237/1100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4791 - accuracy: 0.7847 - val_loss: 0.4860 - val_accuracy: 0.7604\n",
            "Epoch 238/1100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4786 - accuracy: 0.7847 - val_loss: 0.4857 - val_accuracy: 0.7604\n",
            "Epoch 239/1100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4790 - accuracy: 0.7847 - val_loss: 0.4856 - val_accuracy: 0.7604\n",
            "Epoch 240/1100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4783 - accuracy: 0.7865 - val_loss: 0.4856 - val_accuracy: 0.7604\n",
            "Epoch 241/1100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4785 - accuracy: 0.7865 - val_loss: 0.4854 - val_accuracy: 0.7604\n",
            "Epoch 242/1100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4780 - accuracy: 0.7847 - val_loss: 0.4853 - val_accuracy: 0.7604\n",
            "Epoch 243/1100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4777 - accuracy: 0.7847 - val_loss: 0.4851 - val_accuracy: 0.7604\n",
            "Epoch 244/1100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4776 - accuracy: 0.7865 - val_loss: 0.4850 - val_accuracy: 0.7604\n",
            "Epoch 245/1100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4775 - accuracy: 0.7865 - val_loss: 0.4849 - val_accuracy: 0.7604\n",
            "Epoch 246/1100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4772 - accuracy: 0.7882 - val_loss: 0.4847 - val_accuracy: 0.7604\n",
            "Epoch 247/1100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4769 - accuracy: 0.7865 - val_loss: 0.4847 - val_accuracy: 0.7604\n",
            "Epoch 248/1100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4770 - accuracy: 0.7847 - val_loss: 0.4845 - val_accuracy: 0.7604\n",
            "Epoch 249/1100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4764 - accuracy: 0.7865 - val_loss: 0.4843 - val_accuracy: 0.7604\n",
            "Epoch 250/1100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4770 - accuracy: 0.7882 - val_loss: 0.4842 - val_accuracy: 0.7604\n",
            "Epoch 251/1100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4763 - accuracy: 0.7865 - val_loss: 0.4841 - val_accuracy: 0.7604\n",
            "Epoch 252/1100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4765 - accuracy: 0.7847 - val_loss: 0.4841 - val_accuracy: 0.7604\n",
            "Epoch 253/1100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4760 - accuracy: 0.7865 - val_loss: 0.4839 - val_accuracy: 0.7604\n",
            "Epoch 254/1100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4757 - accuracy: 0.7882 - val_loss: 0.4837 - val_accuracy: 0.7604\n",
            "Epoch 255/1100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4759 - accuracy: 0.7847 - val_loss: 0.4836 - val_accuracy: 0.7604\n",
            "Epoch 256/1100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4755 - accuracy: 0.7865 - val_loss: 0.4835 - val_accuracy: 0.7604\n",
            "Epoch 257/1100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4752 - accuracy: 0.7795 - val_loss: 0.4835 - val_accuracy: 0.7656\n",
            "Epoch 258/1100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4750 - accuracy: 0.7917 - val_loss: 0.4833 - val_accuracy: 0.7656\n",
            "Epoch 259/1100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4750 - accuracy: 0.7899 - val_loss: 0.4831 - val_accuracy: 0.7604\n",
            "Epoch 260/1100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4747 - accuracy: 0.7917 - val_loss: 0.4829 - val_accuracy: 0.7604\n",
            "Epoch 261/1100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4747 - accuracy: 0.7882 - val_loss: 0.4829 - val_accuracy: 0.7656\n",
            "Epoch 262/1100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4743 - accuracy: 0.7882 - val_loss: 0.4827 - val_accuracy: 0.7656\n",
            "Epoch 263/1100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4745 - accuracy: 0.7899 - val_loss: 0.4825 - val_accuracy: 0.7656\n",
            "Epoch 264/1100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4741 - accuracy: 0.7899 - val_loss: 0.4825 - val_accuracy: 0.7656\n",
            "Epoch 265/1100\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4740 - accuracy: 0.7882 - val_loss: 0.4824 - val_accuracy: 0.7656\n",
            "Epoch 266/1100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4739 - accuracy: 0.7917 - val_loss: 0.4822 - val_accuracy: 0.7656\n",
            "Epoch 267/1100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4738 - accuracy: 0.7882 - val_loss: 0.4821 - val_accuracy: 0.7656\n",
            "Epoch 268/1100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4737 - accuracy: 0.7830 - val_loss: 0.4820 - val_accuracy: 0.7656\n",
            "Epoch 269/1100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4736 - accuracy: 0.7934 - val_loss: 0.4819 - val_accuracy: 0.7656\n",
            "Epoch 270/1100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4731 - accuracy: 0.7917 - val_loss: 0.4818 - val_accuracy: 0.7656\n",
            "Epoch 271/1100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4731 - accuracy: 0.7882 - val_loss: 0.4818 - val_accuracy: 0.7656\n",
            "Epoch 272/1100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4730 - accuracy: 0.7951 - val_loss: 0.4816 - val_accuracy: 0.7656\n",
            "Epoch 273/1100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4727 - accuracy: 0.7934 - val_loss: 0.4814 - val_accuracy: 0.7656\n",
            "Epoch 274/1100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4726 - accuracy: 0.7830 - val_loss: 0.4814 - val_accuracy: 0.7656\n",
            "Epoch 275/1100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4726 - accuracy: 0.7917 - val_loss: 0.4812 - val_accuracy: 0.7656\n",
            "Epoch 276/1100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4726 - accuracy: 0.7917 - val_loss: 0.4810 - val_accuracy: 0.7656\n",
            "Epoch 277/1100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4725 - accuracy: 0.7899 - val_loss: 0.4810 - val_accuracy: 0.7656\n",
            "Epoch 278/1100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4718 - accuracy: 0.7899 - val_loss: 0.4809 - val_accuracy: 0.7656\n",
            "Epoch 279/1100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4718 - accuracy: 0.7830 - val_loss: 0.4810 - val_accuracy: 0.7604\n",
            "Epoch 280/1100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4716 - accuracy: 0.7934 - val_loss: 0.4808 - val_accuracy: 0.7656\n",
            "Epoch 281/1100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4721 - accuracy: 0.7899 - val_loss: 0.4807 - val_accuracy: 0.7656\n",
            "Epoch 282/1100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4713 - accuracy: 0.7847 - val_loss: 0.4806 - val_accuracy: 0.7656\n",
            "Epoch 283/1100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4711 - accuracy: 0.7934 - val_loss: 0.4805 - val_accuracy: 0.7656\n",
            "Epoch 284/1100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4708 - accuracy: 0.7882 - val_loss: 0.4803 - val_accuracy: 0.7656\n",
            "Epoch 285/1100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4713 - accuracy: 0.7882 - val_loss: 0.4803 - val_accuracy: 0.7656\n",
            "Epoch 286/1100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4706 - accuracy: 0.7934 - val_loss: 0.4802 - val_accuracy: 0.7656\n",
            "Epoch 287/1100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4705 - accuracy: 0.7830 - val_loss: 0.4803 - val_accuracy: 0.7604\n",
            "Epoch 288/1100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4706 - accuracy: 0.7917 - val_loss: 0.4801 - val_accuracy: 0.7656\n",
            "Epoch 289/1100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4701 - accuracy: 0.7934 - val_loss: 0.4800 - val_accuracy: 0.7656\n",
            "Epoch 290/1100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4702 - accuracy: 0.7847 - val_loss: 0.4800 - val_accuracy: 0.7656\n",
            "Epoch 291/1100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4697 - accuracy: 0.7865 - val_loss: 0.4799 - val_accuracy: 0.7656\n",
            "Epoch 292/1100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4698 - accuracy: 0.7986 - val_loss: 0.4798 - val_accuracy: 0.7708\n",
            "Epoch 293/1100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4697 - accuracy: 0.7847 - val_loss: 0.4798 - val_accuracy: 0.7708\n",
            "Epoch 294/1100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4696 - accuracy: 0.7795 - val_loss: 0.4798 - val_accuracy: 0.7656\n",
            "Epoch 295/1100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4692 - accuracy: 0.7899 - val_loss: 0.4797 - val_accuracy: 0.7708\n",
            "Epoch 296/1100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4694 - accuracy: 0.7882 - val_loss: 0.4796 - val_accuracy: 0.7708\n",
            "Epoch 297/1100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4694 - accuracy: 0.7934 - val_loss: 0.4796 - val_accuracy: 0.7708\n",
            "Epoch 298/1100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4690 - accuracy: 0.7882 - val_loss: 0.4795 - val_accuracy: 0.7708\n",
            "Epoch 299/1100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4687 - accuracy: 0.7934 - val_loss: 0.4794 - val_accuracy: 0.7708\n",
            "Epoch 300/1100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4686 - accuracy: 0.7847 - val_loss: 0.4794 - val_accuracy: 0.7708\n",
            "Epoch 301/1100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4687 - accuracy: 0.7882 - val_loss: 0.4793 - val_accuracy: 0.7708\n",
            "Epoch 302/1100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4682 - accuracy: 0.7847 - val_loss: 0.4793 - val_accuracy: 0.7656\n",
            "Epoch 303/1100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4683 - accuracy: 0.7934 - val_loss: 0.4792 - val_accuracy: 0.7708\n",
            "Epoch 304/1100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4683 - accuracy: 0.7865 - val_loss: 0.4792 - val_accuracy: 0.7708\n",
            "Epoch 305/1100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4680 - accuracy: 0.7934 - val_loss: 0.4790 - val_accuracy: 0.7708\n",
            "Epoch 306/1100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4677 - accuracy: 0.7882 - val_loss: 0.4790 - val_accuracy: 0.7708\n",
            "Epoch 307/1100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4675 - accuracy: 0.7899 - val_loss: 0.4789 - val_accuracy: 0.7708\n",
            "Epoch 308/1100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4673 - accuracy: 0.7847 - val_loss: 0.4787 - val_accuracy: 0.7708\n",
            "Epoch 309/1100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4671 - accuracy: 0.7882 - val_loss: 0.4786 - val_accuracy: 0.7708\n",
            "Epoch 310/1100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4671 - accuracy: 0.7865 - val_loss: 0.4786 - val_accuracy: 0.7708\n",
            "Epoch 311/1100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4669 - accuracy: 0.7934 - val_loss: 0.4784 - val_accuracy: 0.7708\n",
            "Epoch 312/1100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4668 - accuracy: 0.7795 - val_loss: 0.4783 - val_accuracy: 0.7708\n",
            "Epoch 313/1100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4667 - accuracy: 0.7865 - val_loss: 0.4782 - val_accuracy: 0.7708\n",
            "Epoch 314/1100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4667 - accuracy: 0.7795 - val_loss: 0.4782 - val_accuracy: 0.7708\n",
            "Epoch 315/1100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4663 - accuracy: 0.7899 - val_loss: 0.4781 - val_accuracy: 0.7708\n",
            "Epoch 316/1100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4664 - accuracy: 0.7882 - val_loss: 0.4778 - val_accuracy: 0.7708\n",
            "Epoch 317/1100\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4660 - accuracy: 0.7830 - val_loss: 0.4777 - val_accuracy: 0.7708\n",
            "Epoch 318/1100\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4661 - accuracy: 0.7899 - val_loss: 0.4776 - val_accuracy: 0.7656\n",
            "Epoch 319/1100\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4659 - accuracy: 0.7934 - val_loss: 0.4774 - val_accuracy: 0.7708\n",
            "Epoch 320/1100\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4659 - accuracy: 0.7847 - val_loss: 0.4773 - val_accuracy: 0.7708\n",
            "Epoch 321/1100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4658 - accuracy: 0.7865 - val_loss: 0.4771 - val_accuracy: 0.7708\n",
            "Epoch 322/1100\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4653 - accuracy: 0.7812 - val_loss: 0.4772 - val_accuracy: 0.7708\n",
            "Epoch 323/1100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4657 - accuracy: 0.7830 - val_loss: 0.4772 - val_accuracy: 0.7708\n",
            "Epoch 324/1100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4652 - accuracy: 0.7899 - val_loss: 0.4772 - val_accuracy: 0.7708\n",
            "Epoch 325/1100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4652 - accuracy: 0.7917 - val_loss: 0.4770 - val_accuracy: 0.7708\n",
            "Epoch 326/1100\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4652 - accuracy: 0.7899 - val_loss: 0.4769 - val_accuracy: 0.7656\n",
            "Epoch 327/1100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4650 - accuracy: 0.7899 - val_loss: 0.4768 - val_accuracy: 0.7708\n",
            "Epoch 328/1100\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4649 - accuracy: 0.7812 - val_loss: 0.4768 - val_accuracy: 0.7708\n",
            "Epoch 329/1100\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4646 - accuracy: 0.7917 - val_loss: 0.4766 - val_accuracy: 0.7708\n",
            "Epoch 330/1100\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4644 - accuracy: 0.7865 - val_loss: 0.4766 - val_accuracy: 0.7760\n",
            "Epoch 331/1100\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4645 - accuracy: 0.7917 - val_loss: 0.4765 - val_accuracy: 0.7708\n",
            "Epoch 332/1100\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4642 - accuracy: 0.7934 - val_loss: 0.4763 - val_accuracy: 0.7708\n",
            "Epoch 333/1100\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.4641 - accuracy: 0.7865 - val_loss: 0.4764 - val_accuracy: 0.7708\n",
            "Epoch 334/1100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4642 - accuracy: 0.7865 - val_loss: 0.4764 - val_accuracy: 0.7708\n",
            "Epoch 335/1100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4638 - accuracy: 0.7812 - val_loss: 0.4765 - val_accuracy: 0.7708\n",
            "Epoch 336/1100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4639 - accuracy: 0.7899 - val_loss: 0.4763 - val_accuracy: 0.7708\n",
            "Epoch 337/1100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4636 - accuracy: 0.7934 - val_loss: 0.4760 - val_accuracy: 0.7708\n",
            "Epoch 338/1100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4636 - accuracy: 0.7934 - val_loss: 0.4760 - val_accuracy: 0.7708\n",
            "Epoch 339/1100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4634 - accuracy: 0.7917 - val_loss: 0.4759 - val_accuracy: 0.7760\n",
            "Epoch 340/1100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4637 - accuracy: 0.7934 - val_loss: 0.4758 - val_accuracy: 0.7760\n",
            "Epoch 341/1100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4631 - accuracy: 0.7847 - val_loss: 0.4758 - val_accuracy: 0.7760\n",
            "Epoch 342/1100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4631 - accuracy: 0.7899 - val_loss: 0.4758 - val_accuracy: 0.7708\n",
            "Epoch 343/1100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4628 - accuracy: 0.7865 - val_loss: 0.4756 - val_accuracy: 0.7760\n",
            "Epoch 344/1100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4631 - accuracy: 0.7865 - val_loss: 0.4756 - val_accuracy: 0.7708\n",
            "Epoch 345/1100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4628 - accuracy: 0.7882 - val_loss: 0.4755 - val_accuracy: 0.7708\n",
            "Epoch 346/1100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4627 - accuracy: 0.7899 - val_loss: 0.4754 - val_accuracy: 0.7812\n",
            "Epoch 347/1100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4624 - accuracy: 0.7899 - val_loss: 0.4753 - val_accuracy: 0.7812\n",
            "Epoch 348/1100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4623 - accuracy: 0.7899 - val_loss: 0.4751 - val_accuracy: 0.7760\n",
            "Epoch 349/1100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4624 - accuracy: 0.7899 - val_loss: 0.4751 - val_accuracy: 0.7760\n",
            "Epoch 350/1100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4620 - accuracy: 0.7865 - val_loss: 0.4752 - val_accuracy: 0.7812\n",
            "Epoch 351/1100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4620 - accuracy: 0.7934 - val_loss: 0.4750 - val_accuracy: 0.7760\n",
            "Epoch 352/1100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4621 - accuracy: 0.7899 - val_loss: 0.4749 - val_accuracy: 0.7812\n",
            "Epoch 353/1100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4618 - accuracy: 0.7917 - val_loss: 0.4748 - val_accuracy: 0.7812\n",
            "Epoch 354/1100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4616 - accuracy: 0.7899 - val_loss: 0.4748 - val_accuracy: 0.7812\n",
            "Epoch 355/1100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4617 - accuracy: 0.7969 - val_loss: 0.4746 - val_accuracy: 0.7760\n",
            "Epoch 356/1100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4615 - accuracy: 0.7865 - val_loss: 0.4747 - val_accuracy: 0.7812\n",
            "Epoch 357/1100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4612 - accuracy: 0.7917 - val_loss: 0.4745 - val_accuracy: 0.7812\n",
            "Epoch 358/1100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4613 - accuracy: 0.7917 - val_loss: 0.4744 - val_accuracy: 0.7760\n",
            "Epoch 359/1100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4609 - accuracy: 0.7899 - val_loss: 0.4744 - val_accuracy: 0.7812\n",
            "Epoch 360/1100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4609 - accuracy: 0.7934 - val_loss: 0.4743 - val_accuracy: 0.7812\n",
            "Epoch 361/1100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4610 - accuracy: 0.7882 - val_loss: 0.4742 - val_accuracy: 0.7812\n",
            "Epoch 362/1100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4609 - accuracy: 0.7951 - val_loss: 0.4741 - val_accuracy: 0.7760\n",
            "Epoch 363/1100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4607 - accuracy: 0.7865 - val_loss: 0.4741 - val_accuracy: 0.7812\n",
            "Epoch 364/1100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4606 - accuracy: 0.7865 - val_loss: 0.4741 - val_accuracy: 0.7812\n",
            "Epoch 365/1100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4604 - accuracy: 0.7934 - val_loss: 0.4740 - val_accuracy: 0.7812\n",
            "Epoch 366/1100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4607 - accuracy: 0.7882 - val_loss: 0.4740 - val_accuracy: 0.7760\n",
            "Epoch 367/1100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4607 - accuracy: 0.7951 - val_loss: 0.4738 - val_accuracy: 0.7812\n",
            "Epoch 368/1100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4603 - accuracy: 0.7917 - val_loss: 0.4738 - val_accuracy: 0.7812\n",
            "Epoch 369/1100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4603 - accuracy: 0.7969 - val_loss: 0.4738 - val_accuracy: 0.7812\n",
            "Epoch 370/1100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4597 - accuracy: 0.7951 - val_loss: 0.4735 - val_accuracy: 0.7708\n",
            "Epoch 371/1100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4598 - accuracy: 0.7882 - val_loss: 0.4736 - val_accuracy: 0.7812\n",
            "Epoch 372/1100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4600 - accuracy: 0.7951 - val_loss: 0.4734 - val_accuracy: 0.7708\n",
            "Epoch 373/1100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4596 - accuracy: 0.7899 - val_loss: 0.4733 - val_accuracy: 0.7708\n",
            "Epoch 374/1100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4595 - accuracy: 0.7882 - val_loss: 0.4733 - val_accuracy: 0.7708\n",
            "Epoch 375/1100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4593 - accuracy: 0.7969 - val_loss: 0.4733 - val_accuracy: 0.7656\n",
            "Epoch 376/1100\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4592 - accuracy: 0.7830 - val_loss: 0.4733 - val_accuracy: 0.7760\n",
            "Epoch 377/1100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4594 - accuracy: 0.7934 - val_loss: 0.4733 - val_accuracy: 0.7812\n",
            "Epoch 378/1100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4593 - accuracy: 0.7934 - val_loss: 0.4732 - val_accuracy: 0.7760\n",
            "Epoch 379/1100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4588 - accuracy: 0.7882 - val_loss: 0.4733 - val_accuracy: 0.7812\n",
            "Epoch 380/1100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4590 - accuracy: 0.7865 - val_loss: 0.4733 - val_accuracy: 0.7812\n",
            "Epoch 381/1100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4587 - accuracy: 0.7847 - val_loss: 0.4734 - val_accuracy: 0.7760\n",
            "Epoch 382/1100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4589 - accuracy: 0.7917 - val_loss: 0.4733 - val_accuracy: 0.7812\n",
            "Epoch 383/1100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4589 - accuracy: 0.7899 - val_loss: 0.4732 - val_accuracy: 0.7812\n",
            "Epoch 384/1100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4585 - accuracy: 0.7934 - val_loss: 0.4730 - val_accuracy: 0.7812\n",
            "Epoch 385/1100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4582 - accuracy: 0.7917 - val_loss: 0.4730 - val_accuracy: 0.7812\n",
            "Epoch 386/1100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4583 - accuracy: 0.7917 - val_loss: 0.4732 - val_accuracy: 0.7760\n",
            "Epoch 387/1100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4583 - accuracy: 0.7969 - val_loss: 0.4730 - val_accuracy: 0.7812\n",
            "Epoch 388/1100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4579 - accuracy: 0.7899 - val_loss: 0.4729 - val_accuracy: 0.7812\n",
            "Epoch 389/1100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4580 - accuracy: 0.7917 - val_loss: 0.4729 - val_accuracy: 0.7812\n",
            "Epoch 390/1100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4580 - accuracy: 0.7865 - val_loss: 0.4730 - val_accuracy: 0.7812\n",
            "Epoch 391/1100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4579 - accuracy: 0.7951 - val_loss: 0.4729 - val_accuracy: 0.7812\n",
            "Epoch 392/1100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4577 - accuracy: 0.7882 - val_loss: 0.4728 - val_accuracy: 0.7812\n",
            "Epoch 393/1100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4581 - accuracy: 0.7934 - val_loss: 0.4728 - val_accuracy: 0.7812\n",
            "Epoch 394/1100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4581 - accuracy: 0.7951 - val_loss: 0.4726 - val_accuracy: 0.7812\n",
            "Epoch 395/1100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4574 - accuracy: 0.7865 - val_loss: 0.4728 - val_accuracy: 0.7812\n",
            "Epoch 396/1100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4575 - accuracy: 0.7951 - val_loss: 0.4726 - val_accuracy: 0.7812\n",
            "Epoch 397/1100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4571 - accuracy: 0.7917 - val_loss: 0.4726 - val_accuracy: 0.7812\n",
            "Epoch 398/1100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4571 - accuracy: 0.7917 - val_loss: 0.4726 - val_accuracy: 0.7812\n",
            "Epoch 399/1100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4572 - accuracy: 0.7917 - val_loss: 0.4725 - val_accuracy: 0.7812\n",
            "Epoch 400/1100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4570 - accuracy: 0.7882 - val_loss: 0.4725 - val_accuracy: 0.7812\n",
            "Epoch 401/1100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4573 - accuracy: 0.7951 - val_loss: 0.4723 - val_accuracy: 0.7812\n",
            "Epoch 402/1100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4573 - accuracy: 0.7934 - val_loss: 0.4723 - val_accuracy: 0.7812\n",
            "Epoch 403/1100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4567 - accuracy: 0.7882 - val_loss: 0.4723 - val_accuracy: 0.7812\n",
            "Epoch 404/1100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4566 - accuracy: 0.7934 - val_loss: 0.4722 - val_accuracy: 0.7760\n",
            "Epoch 405/1100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4564 - accuracy: 0.7882 - val_loss: 0.4721 - val_accuracy: 0.7812\n",
            "Epoch 406/1100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4566 - accuracy: 0.7882 - val_loss: 0.4722 - val_accuracy: 0.7812\n",
            "Epoch 407/1100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4564 - accuracy: 0.7951 - val_loss: 0.4722 - val_accuracy: 0.7812\n",
            "Epoch 408/1100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4564 - accuracy: 0.7917 - val_loss: 0.4721 - val_accuracy: 0.7812\n",
            "Epoch 409/1100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4564 - accuracy: 0.7934 - val_loss: 0.4721 - val_accuracy: 0.7812\n",
            "Epoch 410/1100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4560 - accuracy: 0.7951 - val_loss: 0.4720 - val_accuracy: 0.7812\n",
            "Epoch 411/1100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4560 - accuracy: 0.7969 - val_loss: 0.4720 - val_accuracy: 0.7812\n",
            "Epoch 412/1100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4557 - accuracy: 0.7899 - val_loss: 0.4720 - val_accuracy: 0.7812\n",
            "Epoch 413/1100\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4560 - accuracy: 0.7951 - val_loss: 0.4719 - val_accuracy: 0.7812\n",
            "Epoch 414/1100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4558 - accuracy: 0.7917 - val_loss: 0.4720 - val_accuracy: 0.7812\n",
            "Epoch 415/1100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4557 - accuracy: 0.7882 - val_loss: 0.4720 - val_accuracy: 0.7760\n",
            "Epoch 416/1100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4559 - accuracy: 0.7934 - val_loss: 0.4719 - val_accuracy: 0.7812\n",
            "Epoch 417/1100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4554 - accuracy: 0.7882 - val_loss: 0.4719 - val_accuracy: 0.7812\n",
            "Epoch 418/1100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4554 - accuracy: 0.7934 - val_loss: 0.4718 - val_accuracy: 0.7812\n",
            "Epoch 419/1100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4555 - accuracy: 0.7899 - val_loss: 0.4719 - val_accuracy: 0.7812\n",
            "Epoch 420/1100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4550 - accuracy: 0.7917 - val_loss: 0.4718 - val_accuracy: 0.7812\n",
            "Epoch 421/1100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4554 - accuracy: 0.7882 - val_loss: 0.4718 - val_accuracy: 0.7760\n",
            "Epoch 422/1100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4550 - accuracy: 0.7899 - val_loss: 0.4717 - val_accuracy: 0.7760\n",
            "Epoch 423/1100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4549 - accuracy: 0.7951 - val_loss: 0.4717 - val_accuracy: 0.7708\n",
            "Epoch 424/1100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4550 - accuracy: 0.7795 - val_loss: 0.4717 - val_accuracy: 0.7760\n",
            "Epoch 425/1100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4549 - accuracy: 0.7934 - val_loss: 0.4716 - val_accuracy: 0.7760\n",
            "Epoch 426/1100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4549 - accuracy: 0.7812 - val_loss: 0.4718 - val_accuracy: 0.7812\n",
            "Epoch 427/1100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4545 - accuracy: 0.7865 - val_loss: 0.4717 - val_accuracy: 0.7760\n",
            "Epoch 428/1100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4544 - accuracy: 0.7899 - val_loss: 0.4717 - val_accuracy: 0.7760\n",
            "Epoch 429/1100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4545 - accuracy: 0.7882 - val_loss: 0.4718 - val_accuracy: 0.7760\n",
            "Epoch 430/1100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4541 - accuracy: 0.7934 - val_loss: 0.4716 - val_accuracy: 0.7812\n",
            "Epoch 431/1100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4542 - accuracy: 0.7882 - val_loss: 0.4717 - val_accuracy: 0.7760\n",
            "Epoch 432/1100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4542 - accuracy: 0.7951 - val_loss: 0.4716 - val_accuracy: 0.7760\n",
            "Epoch 433/1100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4542 - accuracy: 0.7882 - val_loss: 0.4716 - val_accuracy: 0.7760\n",
            "Epoch 434/1100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4538 - accuracy: 0.7865 - val_loss: 0.4716 - val_accuracy: 0.7760\n",
            "Epoch 435/1100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4537 - accuracy: 0.7917 - val_loss: 0.4716 - val_accuracy: 0.7760\n",
            "Epoch 436/1100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4538 - accuracy: 0.7812 - val_loss: 0.4718 - val_accuracy: 0.7708\n",
            "Epoch 437/1100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4538 - accuracy: 0.7934 - val_loss: 0.4717 - val_accuracy: 0.7760\n",
            "Epoch 438/1100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4536 - accuracy: 0.7917 - val_loss: 0.4715 - val_accuracy: 0.7760\n",
            "Epoch 439/1100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4536 - accuracy: 0.7917 - val_loss: 0.4715 - val_accuracy: 0.7708\n",
            "Epoch 440/1100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4533 - accuracy: 0.7882 - val_loss: 0.4719 - val_accuracy: 0.7708\n",
            "Epoch 441/1100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4539 - accuracy: 0.7899 - val_loss: 0.4718 - val_accuracy: 0.7760\n",
            "Epoch 442/1100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4533 - accuracy: 0.7882 - val_loss: 0.4716 - val_accuracy: 0.7760\n",
            "Epoch 443/1100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4530 - accuracy: 0.7865 - val_loss: 0.4717 - val_accuracy: 0.7708\n",
            "Epoch 444/1100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4531 - accuracy: 0.7882 - val_loss: 0.4717 - val_accuracy: 0.7760\n",
            "Epoch 445/1100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4538 - accuracy: 0.7899 - val_loss: 0.4716 - val_accuracy: 0.7708\n",
            "Epoch 446/1100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4527 - accuracy: 0.7882 - val_loss: 0.4718 - val_accuracy: 0.7760\n",
            "Epoch 447/1100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4528 - accuracy: 0.7899 - val_loss: 0.4717 - val_accuracy: 0.7708\n",
            "Epoch 448/1100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4526 - accuracy: 0.7899 - val_loss: 0.4717 - val_accuracy: 0.7760\n",
            "Epoch 449/1100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4524 - accuracy: 0.7847 - val_loss: 0.4719 - val_accuracy: 0.7760\n",
            "Epoch 450/1100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4524 - accuracy: 0.7899 - val_loss: 0.4720 - val_accuracy: 0.7708\n",
            "Epoch 451/1100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4530 - accuracy: 0.7917 - val_loss: 0.4719 - val_accuracy: 0.7708\n",
            "Epoch 452/1100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4523 - accuracy: 0.7865 - val_loss: 0.4719 - val_accuracy: 0.7708\n",
            "Epoch 453/1100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4523 - accuracy: 0.7865 - val_loss: 0.4720 - val_accuracy: 0.7708\n",
            "Epoch 454/1100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4522 - accuracy: 0.7899 - val_loss: 0.4718 - val_accuracy: 0.7708\n",
            "Epoch 455/1100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4522 - accuracy: 0.7899 - val_loss: 0.4718 - val_accuracy: 0.7708\n",
            "Epoch 456/1100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4527 - accuracy: 0.7847 - val_loss: 0.4719 - val_accuracy: 0.7708\n",
            "Epoch 457/1100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4520 - accuracy: 0.7865 - val_loss: 0.4719 - val_accuracy: 0.7708\n",
            "Epoch 458/1100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4520 - accuracy: 0.7865 - val_loss: 0.4719 - val_accuracy: 0.7708\n",
            "Epoch 459/1100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4519 - accuracy: 0.7847 - val_loss: 0.4718 - val_accuracy: 0.7708\n",
            "Epoch 460/1100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4516 - accuracy: 0.7865 - val_loss: 0.4717 - val_accuracy: 0.7708\n",
            "Epoch 461/1100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4521 - accuracy: 0.7865 - val_loss: 0.4719 - val_accuracy: 0.7708\n",
            "Epoch 462/1100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4518 - accuracy: 0.7882 - val_loss: 0.4718 - val_accuracy: 0.7708\n",
            "Epoch 463/1100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4515 - accuracy: 0.7899 - val_loss: 0.4718 - val_accuracy: 0.7708\n",
            "Epoch 464/1100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4516 - accuracy: 0.7865 - val_loss: 0.4719 - val_accuracy: 0.7708\n",
            "Epoch 465/1100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4513 - accuracy: 0.7847 - val_loss: 0.4718 - val_accuracy: 0.7760\n",
            "Epoch 466/1100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4513 - accuracy: 0.7899 - val_loss: 0.4718 - val_accuracy: 0.7708\n",
            "Epoch 467/1100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4514 - accuracy: 0.7882 - val_loss: 0.4719 - val_accuracy: 0.7708\n",
            "Epoch 468/1100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4513 - accuracy: 0.7899 - val_loss: 0.4719 - val_accuracy: 0.7708\n",
            "Epoch 469/1100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4513 - accuracy: 0.7865 - val_loss: 0.4722 - val_accuracy: 0.7656\n",
            "Epoch 470/1100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4512 - accuracy: 0.7882 - val_loss: 0.4719 - val_accuracy: 0.7708\n",
            "Epoch 471/1100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4510 - accuracy: 0.7882 - val_loss: 0.4720 - val_accuracy: 0.7708\n",
            "Epoch 472/1100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4510 - accuracy: 0.7882 - val_loss: 0.4720 - val_accuracy: 0.7708\n",
            "Epoch 473/1100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4506 - accuracy: 0.7882 - val_loss: 0.4720 - val_accuracy: 0.7708\n",
            "Epoch 474/1100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4508 - accuracy: 0.7882 - val_loss: 0.4720 - val_accuracy: 0.7708\n",
            "Epoch 475/1100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4509 - accuracy: 0.7847 - val_loss: 0.4723 - val_accuracy: 0.7708\n",
            "Epoch 476/1100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4504 - accuracy: 0.7830 - val_loss: 0.4724 - val_accuracy: 0.7656\n",
            "Epoch 477/1100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4515 - accuracy: 0.7865 - val_loss: 0.4724 - val_accuracy: 0.7708\n",
            "Epoch 478/1100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4509 - accuracy: 0.7882 - val_loss: 0.4722 - val_accuracy: 0.7708\n",
            "Epoch 479/1100\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4504 - accuracy: 0.7882 - val_loss: 0.4723 - val_accuracy: 0.7708\n",
            "Epoch 480/1100\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4504 - accuracy: 0.7865 - val_loss: 0.4724 - val_accuracy: 0.7708\n",
            "Epoch 481/1100\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4500 - accuracy: 0.7865 - val_loss: 0.4723 - val_accuracy: 0.7708\n",
            "Epoch 482/1100\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4505 - accuracy: 0.7882 - val_loss: 0.4725 - val_accuracy: 0.7708\n",
            "Epoch 483/1100\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4503 - accuracy: 0.7847 - val_loss: 0.4725 - val_accuracy: 0.7708\n",
            "Epoch 484/1100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4500 - accuracy: 0.7865 - val_loss: 0.4725 - val_accuracy: 0.7708\n",
            "Epoch 485/1100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4505 - accuracy: 0.7882 - val_loss: 0.4727 - val_accuracy: 0.7656\n",
            "Epoch 486/1100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4499 - accuracy: 0.7882 - val_loss: 0.4724 - val_accuracy: 0.7708\n",
            "Epoch 487/1100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4500 - accuracy: 0.7865 - val_loss: 0.4727 - val_accuracy: 0.7708\n",
            "Epoch 488/1100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4500 - accuracy: 0.7882 - val_loss: 0.4729 - val_accuracy: 0.7656\n",
            "Epoch 489/1100\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4496 - accuracy: 0.7882 - val_loss: 0.4726 - val_accuracy: 0.7708\n",
            "Epoch 490/1100\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4495 - accuracy: 0.7847 - val_loss: 0.4726 - val_accuracy: 0.7656\n",
            "Epoch 491/1100\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4493 - accuracy: 0.7882 - val_loss: 0.4726 - val_accuracy: 0.7708\n",
            "Epoch 492/1100\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4491 - accuracy: 0.7865 - val_loss: 0.4728 - val_accuracy: 0.7656\n",
            "Epoch 493/1100\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4492 - accuracy: 0.7865 - val_loss: 0.4727 - val_accuracy: 0.7656\n",
            "Epoch 494/1100\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4497 - accuracy: 0.7865 - val_loss: 0.4726 - val_accuracy: 0.7656\n",
            "Epoch 495/1100\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4488 - accuracy: 0.7882 - val_loss: 0.4728 - val_accuracy: 0.7656\n",
            "Epoch 496/1100\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4489 - accuracy: 0.7865 - val_loss: 0.4726 - val_accuracy: 0.7708\n",
            "Epoch 497/1100\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4488 - accuracy: 0.7882 - val_loss: 0.4727 - val_accuracy: 0.7708\n",
            "Epoch 498/1100\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4489 - accuracy: 0.7882 - val_loss: 0.4727 - val_accuracy: 0.7656\n",
            "Epoch 499/1100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4491 - accuracy: 0.7934 - val_loss: 0.4724 - val_accuracy: 0.7708\n",
            "Epoch 500/1100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4490 - accuracy: 0.7882 - val_loss: 0.4725 - val_accuracy: 0.7708\n",
            "Epoch 501/1100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4486 - accuracy: 0.7865 - val_loss: 0.4726 - val_accuracy: 0.7708\n",
            "Epoch 502/1100\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4483 - accuracy: 0.7865 - val_loss: 0.4730 - val_accuracy: 0.7656\n",
            "Epoch 503/1100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4483 - accuracy: 0.7847 - val_loss: 0.4727 - val_accuracy: 0.7656\n",
            "Epoch 504/1100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4484 - accuracy: 0.7847 - val_loss: 0.4725 - val_accuracy: 0.7708\n",
            "Epoch 505/1100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4484 - accuracy: 0.7899 - val_loss: 0.4725 - val_accuracy: 0.7708\n",
            "Epoch 506/1100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4483 - accuracy: 0.7882 - val_loss: 0.4725 - val_accuracy: 0.7708\n",
            "Epoch 507/1100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4480 - accuracy: 0.7865 - val_loss: 0.4726 - val_accuracy: 0.7708\n",
            "Epoch 508/1100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4480 - accuracy: 0.7865 - val_loss: 0.4726 - val_accuracy: 0.7708\n",
            "Epoch 509/1100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4477 - accuracy: 0.7882 - val_loss: 0.4728 - val_accuracy: 0.7708\n",
            "Epoch 510/1100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4478 - accuracy: 0.7865 - val_loss: 0.4728 - val_accuracy: 0.7708\n",
            "Epoch 511/1100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4481 - accuracy: 0.7865 - val_loss: 0.4728 - val_accuracy: 0.7708\n",
            "Epoch 512/1100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4475 - accuracy: 0.7899 - val_loss: 0.4726 - val_accuracy: 0.7708\n",
            "Epoch 513/1100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4478 - accuracy: 0.7882 - val_loss: 0.4727 - val_accuracy: 0.7708\n",
            "Epoch 514/1100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4475 - accuracy: 0.7882 - val_loss: 0.4729 - val_accuracy: 0.7656\n",
            "Epoch 515/1100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4477 - accuracy: 0.7830 - val_loss: 0.4726 - val_accuracy: 0.7708\n",
            "Epoch 516/1100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4475 - accuracy: 0.7865 - val_loss: 0.4727 - val_accuracy: 0.7708\n",
            "Epoch 517/1100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4473 - accuracy: 0.7934 - val_loss: 0.4733 - val_accuracy: 0.7760\n",
            "Epoch 518/1100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4475 - accuracy: 0.7882 - val_loss: 0.4728 - val_accuracy: 0.7656\n",
            "Epoch 519/1100\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4474 - accuracy: 0.7865 - val_loss: 0.4729 - val_accuracy: 0.7656\n",
            "Epoch 520/1100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4468 - accuracy: 0.7865 - val_loss: 0.4728 - val_accuracy: 0.7656\n",
            "Epoch 521/1100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4477 - accuracy: 0.7882 - val_loss: 0.4728 - val_accuracy: 0.7656\n",
            "Epoch 522/1100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4471 - accuracy: 0.7865 - val_loss: 0.4729 - val_accuracy: 0.7708\n",
            "Epoch 523/1100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4472 - accuracy: 0.7865 - val_loss: 0.4730 - val_accuracy: 0.7656\n",
            "Epoch 524/1100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4467 - accuracy: 0.7882 - val_loss: 0.4731 - val_accuracy: 0.7656\n",
            "Epoch 525/1100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4467 - accuracy: 0.7847 - val_loss: 0.4727 - val_accuracy: 0.7656\n",
            "Epoch 526/1100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4477 - accuracy: 0.7934 - val_loss: 0.4726 - val_accuracy: 0.7656\n",
            "Epoch 527/1100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4467 - accuracy: 0.7882 - val_loss: 0.4728 - val_accuracy: 0.7656\n",
            "Epoch 528/1100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4469 - accuracy: 0.7882 - val_loss: 0.4727 - val_accuracy: 0.7656\n",
            "Epoch 529/1100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4465 - accuracy: 0.7882 - val_loss: 0.4729 - val_accuracy: 0.7656\n",
            "Epoch 530/1100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4462 - accuracy: 0.7882 - val_loss: 0.4728 - val_accuracy: 0.7656\n",
            "Epoch 531/1100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4464 - accuracy: 0.7899 - val_loss: 0.4726 - val_accuracy: 0.7708\n",
            "Epoch 532/1100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4461 - accuracy: 0.7830 - val_loss: 0.4727 - val_accuracy: 0.7656\n",
            "Epoch 533/1100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4461 - accuracy: 0.7865 - val_loss: 0.4726 - val_accuracy: 0.7656\n",
            "Epoch 534/1100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4458 - accuracy: 0.7882 - val_loss: 0.4726 - val_accuracy: 0.7656\n",
            "Epoch 535/1100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4459 - accuracy: 0.7899 - val_loss: 0.4729 - val_accuracy: 0.7708\n",
            "Epoch 536/1100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4458 - accuracy: 0.7865 - val_loss: 0.4724 - val_accuracy: 0.7708\n",
            "Epoch 537/1100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4457 - accuracy: 0.7899 - val_loss: 0.4727 - val_accuracy: 0.7656\n",
            "Epoch 538/1100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4461 - accuracy: 0.7899 - val_loss: 0.4728 - val_accuracy: 0.7708\n",
            "Epoch 539/1100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4453 - accuracy: 0.7882 - val_loss: 0.4731 - val_accuracy: 0.7760\n",
            "Epoch 540/1100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4458 - accuracy: 0.7882 - val_loss: 0.4732 - val_accuracy: 0.7760\n",
            "Epoch 541/1100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4457 - accuracy: 0.7917 - val_loss: 0.4728 - val_accuracy: 0.7656\n",
            "Epoch 542/1100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4455 - accuracy: 0.7847 - val_loss: 0.4731 - val_accuracy: 0.7760\n",
            "Epoch 543/1100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4457 - accuracy: 0.7882 - val_loss: 0.4727 - val_accuracy: 0.7708\n",
            "Epoch 544/1100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4454 - accuracy: 0.7899 - val_loss: 0.4730 - val_accuracy: 0.7760\n",
            "Epoch 545/1100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4453 - accuracy: 0.7899 - val_loss: 0.4731 - val_accuracy: 0.7760\n",
            "Epoch 546/1100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4452 - accuracy: 0.7882 - val_loss: 0.4728 - val_accuracy: 0.7708\n",
            "Epoch 547/1100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4448 - accuracy: 0.7882 - val_loss: 0.4728 - val_accuracy: 0.7708\n",
            "Epoch 548/1100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4449 - accuracy: 0.7899 - val_loss: 0.4726 - val_accuracy: 0.7656\n",
            "Epoch 549/1100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4447 - accuracy: 0.7882 - val_loss: 0.4725 - val_accuracy: 0.7708\n",
            "Epoch 550/1100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4447 - accuracy: 0.7917 - val_loss: 0.4728 - val_accuracy: 0.7708\n",
            "Epoch 551/1100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4448 - accuracy: 0.7899 - val_loss: 0.4727 - val_accuracy: 0.7708\n",
            "Epoch 552/1100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4445 - accuracy: 0.7917 - val_loss: 0.4730 - val_accuracy: 0.7760\n",
            "Epoch 553/1100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4446 - accuracy: 0.7899 - val_loss: 0.4731 - val_accuracy: 0.7760\n",
            "Epoch 554/1100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4445 - accuracy: 0.7899 - val_loss: 0.4728 - val_accuracy: 0.7656\n",
            "Epoch 555/1100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4442 - accuracy: 0.7934 - val_loss: 0.4731 - val_accuracy: 0.7708\n",
            "Epoch 556/1100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4442 - accuracy: 0.7917 - val_loss: 0.4730 - val_accuracy: 0.7708\n",
            "Epoch 557/1100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4442 - accuracy: 0.7969 - val_loss: 0.4734 - val_accuracy: 0.7760\n",
            "Epoch 558/1100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4448 - accuracy: 0.7917 - val_loss: 0.4733 - val_accuracy: 0.7760\n",
            "Epoch 559/1100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4446 - accuracy: 0.7882 - val_loss: 0.4730 - val_accuracy: 0.7708\n",
            "Epoch 560/1100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4438 - accuracy: 0.7899 - val_loss: 0.4730 - val_accuracy: 0.7708\n",
            "Epoch 561/1100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4437 - accuracy: 0.7917 - val_loss: 0.4738 - val_accuracy: 0.7760\n",
            "Epoch 562/1100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4439 - accuracy: 0.7899 - val_loss: 0.4732 - val_accuracy: 0.7656\n",
            "Epoch 563/1100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4443 - accuracy: 0.7899 - val_loss: 0.4730 - val_accuracy: 0.7656\n",
            "Epoch 564/1100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4434 - accuracy: 0.7899 - val_loss: 0.4730 - val_accuracy: 0.7708\n",
            "Epoch 565/1100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4435 - accuracy: 0.7899 - val_loss: 0.4728 - val_accuracy: 0.7708\n",
            "Epoch 566/1100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4437 - accuracy: 0.7917 - val_loss: 0.4731 - val_accuracy: 0.7708\n",
            "Epoch 567/1100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4439 - accuracy: 0.7934 - val_loss: 0.4731 - val_accuracy: 0.7708\n",
            "Epoch 568/1100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4433 - accuracy: 0.7917 - val_loss: 0.4734 - val_accuracy: 0.7760\n",
            "Epoch 569/1100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4442 - accuracy: 0.7917 - val_loss: 0.4733 - val_accuracy: 0.7708\n",
            "Epoch 570/1100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4441 - accuracy: 0.7899 - val_loss: 0.4732 - val_accuracy: 0.7708\n",
            "Epoch 571/1100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4434 - accuracy: 0.7899 - val_loss: 0.4730 - val_accuracy: 0.7656\n",
            "Epoch 572/1100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4435 - accuracy: 0.7917 - val_loss: 0.4730 - val_accuracy: 0.7708\n",
            "Epoch 573/1100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4429 - accuracy: 0.7899 - val_loss: 0.4737 - val_accuracy: 0.7760\n",
            "Epoch 574/1100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4426 - accuracy: 0.7934 - val_loss: 0.4732 - val_accuracy: 0.7708\n",
            "Epoch 575/1100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4431 - accuracy: 0.7934 - val_loss: 0.4731 - val_accuracy: 0.7708\n",
            "Epoch 576/1100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4426 - accuracy: 0.7917 - val_loss: 0.4735 - val_accuracy: 0.7760\n",
            "Epoch 577/1100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4426 - accuracy: 0.7917 - val_loss: 0.4727 - val_accuracy: 0.7708\n",
            "Epoch 578/1100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4428 - accuracy: 0.7934 - val_loss: 0.4729 - val_accuracy: 0.7708\n",
            "Epoch 579/1100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4429 - accuracy: 0.7934 - val_loss: 0.4730 - val_accuracy: 0.7708\n",
            "Epoch 580/1100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4420 - accuracy: 0.7917 - val_loss: 0.4727 - val_accuracy: 0.7760\n",
            "Epoch 581/1100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4432 - accuracy: 0.7934 - val_loss: 0.4728 - val_accuracy: 0.7708\n",
            "Epoch 582/1100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4419 - accuracy: 0.7951 - val_loss: 0.4729 - val_accuracy: 0.7708\n",
            "Epoch 583/1100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4427 - accuracy: 0.7951 - val_loss: 0.4728 - val_accuracy: 0.7708\n",
            "Epoch 584/1100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4422 - accuracy: 0.7899 - val_loss: 0.4729 - val_accuracy: 0.7708\n",
            "Epoch 585/1100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4418 - accuracy: 0.7917 - val_loss: 0.4727 - val_accuracy: 0.7708\n",
            "Epoch 586/1100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4429 - accuracy: 0.7899 - val_loss: 0.4727 - val_accuracy: 0.7656\n",
            "Epoch 587/1100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4424 - accuracy: 0.7934 - val_loss: 0.4726 - val_accuracy: 0.7708\n",
            "Epoch 588/1100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4424 - accuracy: 0.7882 - val_loss: 0.4727 - val_accuracy: 0.7760\n",
            "Epoch 589/1100\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4421 - accuracy: 0.7917 - val_loss: 0.4731 - val_accuracy: 0.7708\n",
            "Epoch 590/1100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4414 - accuracy: 0.7934 - val_loss: 0.4730 - val_accuracy: 0.7760\n",
            "Epoch 591/1100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4415 - accuracy: 0.7934 - val_loss: 0.4728 - val_accuracy: 0.7708\n",
            "Epoch 592/1100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4420 - accuracy: 0.7951 - val_loss: 0.4727 - val_accuracy: 0.7708\n",
            "Epoch 593/1100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4418 - accuracy: 0.7951 - val_loss: 0.4730 - val_accuracy: 0.7708\n",
            "Epoch 594/1100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4419 - accuracy: 0.7899 - val_loss: 0.4733 - val_accuracy: 0.7656\n",
            "Epoch 595/1100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4409 - accuracy: 0.7899 - val_loss: 0.4727 - val_accuracy: 0.7708\n",
            "Epoch 596/1100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4410 - accuracy: 0.7934 - val_loss: 0.4734 - val_accuracy: 0.7656\n",
            "Epoch 597/1100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4412 - accuracy: 0.7951 - val_loss: 0.4736 - val_accuracy: 0.7656\n",
            "Epoch 598/1100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4413 - accuracy: 0.7917 - val_loss: 0.4732 - val_accuracy: 0.7656\n",
            "Epoch 599/1100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4411 - accuracy: 0.7951 - val_loss: 0.4729 - val_accuracy: 0.7708\n",
            "Epoch 600/1100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4413 - accuracy: 0.7951 - val_loss: 0.4730 - val_accuracy: 0.7760\n",
            "Epoch 601/1100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4409 - accuracy: 0.7951 - val_loss: 0.4734 - val_accuracy: 0.7656\n",
            "Epoch 602/1100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4404 - accuracy: 0.7934 - val_loss: 0.4729 - val_accuracy: 0.7760\n",
            "Epoch 603/1100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4410 - accuracy: 0.7917 - val_loss: 0.4729 - val_accuracy: 0.7656\n",
            "Epoch 604/1100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4402 - accuracy: 0.7951 - val_loss: 0.4735 - val_accuracy: 0.7656\n",
            "Epoch 605/1100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4409 - accuracy: 0.7986 - val_loss: 0.4740 - val_accuracy: 0.7708\n",
            "Epoch 606/1100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4406 - accuracy: 0.7934 - val_loss: 0.4734 - val_accuracy: 0.7656\n",
            "Epoch 607/1100\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4402 - accuracy: 0.7951 - val_loss: 0.4731 - val_accuracy: 0.7656\n",
            "Epoch 608/1100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4399 - accuracy: 0.7969 - val_loss: 0.4732 - val_accuracy: 0.7656\n",
            "Epoch 609/1100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4397 - accuracy: 0.7951 - val_loss: 0.4732 - val_accuracy: 0.7656\n",
            "Epoch 610/1100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4400 - accuracy: 0.7934 - val_loss: 0.4730 - val_accuracy: 0.7708\n",
            "Epoch 611/1100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4404 - accuracy: 0.7951 - val_loss: 0.4734 - val_accuracy: 0.7656\n",
            "Epoch 612/1100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4400 - accuracy: 0.7969 - val_loss: 0.4738 - val_accuracy: 0.7656\n",
            "Epoch 613/1100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4400 - accuracy: 0.7951 - val_loss: 0.4738 - val_accuracy: 0.7604\n",
            "Epoch 614/1100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4400 - accuracy: 0.7986 - val_loss: 0.4733 - val_accuracy: 0.7656\n",
            "Epoch 615/1100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4400 - accuracy: 0.8003 - val_loss: 0.4740 - val_accuracy: 0.7708\n",
            "Epoch 616/1100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4397 - accuracy: 0.7934 - val_loss: 0.4737 - val_accuracy: 0.7604\n",
            "Epoch 617/1100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4395 - accuracy: 0.7951 - val_loss: 0.4732 - val_accuracy: 0.7708\n",
            "Epoch 618/1100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4401 - accuracy: 0.7969 - val_loss: 0.4736 - val_accuracy: 0.7656\n",
            "Epoch 619/1100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4394 - accuracy: 0.7934 - val_loss: 0.4730 - val_accuracy: 0.7656\n",
            "Epoch 620/1100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4397 - accuracy: 0.7951 - val_loss: 0.4730 - val_accuracy: 0.7656\n",
            "Epoch 621/1100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4393 - accuracy: 0.7951 - val_loss: 0.4728 - val_accuracy: 0.7760\n",
            "Epoch 622/1100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4391 - accuracy: 0.7917 - val_loss: 0.4729 - val_accuracy: 0.7604\n",
            "Epoch 623/1100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4392 - accuracy: 0.7934 - val_loss: 0.4725 - val_accuracy: 0.7760\n",
            "Epoch 624/1100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4388 - accuracy: 0.7934 - val_loss: 0.4727 - val_accuracy: 0.7656\n",
            "Epoch 625/1100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4390 - accuracy: 0.7969 - val_loss: 0.4730 - val_accuracy: 0.7656\n",
            "Epoch 626/1100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4385 - accuracy: 0.7951 - val_loss: 0.4732 - val_accuracy: 0.7604\n",
            "Epoch 627/1100\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4389 - accuracy: 0.7934 - val_loss: 0.4729 - val_accuracy: 0.7656\n",
            "Epoch 628/1100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4388 - accuracy: 0.7917 - val_loss: 0.4729 - val_accuracy: 0.7604\n",
            "Epoch 629/1100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4380 - accuracy: 0.7969 - val_loss: 0.4727 - val_accuracy: 0.7708\n",
            "Epoch 630/1100\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4385 - accuracy: 0.7934 - val_loss: 0.4730 - val_accuracy: 0.7708\n",
            "Epoch 631/1100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4384 - accuracy: 0.7917 - val_loss: 0.4728 - val_accuracy: 0.7708\n",
            "Epoch 632/1100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4379 - accuracy: 0.7917 - val_loss: 0.4741 - val_accuracy: 0.7708\n",
            "Epoch 633/1100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4379 - accuracy: 0.7865 - val_loss: 0.4727 - val_accuracy: 0.7656\n",
            "Epoch 634/1100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4379 - accuracy: 0.7969 - val_loss: 0.4727 - val_accuracy: 0.7656\n",
            "Epoch 635/1100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4383 - accuracy: 0.7969 - val_loss: 0.4726 - val_accuracy: 0.7708\n",
            "Epoch 636/1100\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4374 - accuracy: 0.7934 - val_loss: 0.4725 - val_accuracy: 0.7708\n",
            "Epoch 637/1100\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4378 - accuracy: 0.7917 - val_loss: 0.4724 - val_accuracy: 0.7760\n",
            "Epoch 638/1100\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4371 - accuracy: 0.7951 - val_loss: 0.4728 - val_accuracy: 0.7708\n",
            "Epoch 639/1100\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4379 - accuracy: 0.7934 - val_loss: 0.4733 - val_accuracy: 0.7760\n",
            "Epoch 640/1100\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4370 - accuracy: 0.7934 - val_loss: 0.4730 - val_accuracy: 0.7760\n",
            "Epoch 641/1100\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4371 - accuracy: 0.7899 - val_loss: 0.4723 - val_accuracy: 0.7760\n",
            "Epoch 642/1100\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4372 - accuracy: 0.7969 - val_loss: 0.4737 - val_accuracy: 0.7656\n",
            "Epoch 643/1100\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4375 - accuracy: 0.7951 - val_loss: 0.4737 - val_accuracy: 0.7708\n",
            "Epoch 644/1100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4373 - accuracy: 0.7951 - val_loss: 0.4736 - val_accuracy: 0.7708\n",
            "Epoch 645/1100\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4363 - accuracy: 0.7951 - val_loss: 0.4730 - val_accuracy: 0.7760\n",
            "Epoch 646/1100\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4365 - accuracy: 0.7917 - val_loss: 0.4729 - val_accuracy: 0.7760\n",
            "Epoch 647/1100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4366 - accuracy: 0.7934 - val_loss: 0.4730 - val_accuracy: 0.7708\n",
            "Epoch 648/1100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4361 - accuracy: 0.7986 - val_loss: 0.4726 - val_accuracy: 0.7760\n",
            "Epoch 649/1100\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4369 - accuracy: 0.7934 - val_loss: 0.4725 - val_accuracy: 0.7760\n",
            "Epoch 650/1100\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4368 - accuracy: 0.7917 - val_loss: 0.4728 - val_accuracy: 0.7760\n",
            "Epoch 651/1100\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4361 - accuracy: 0.7986 - val_loss: 0.4727 - val_accuracy: 0.7760\n",
            "Epoch 652/1100\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4359 - accuracy: 0.7917 - val_loss: 0.4722 - val_accuracy: 0.7812\n",
            "Epoch 653/1100\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4364 - accuracy: 0.7951 - val_loss: 0.4725 - val_accuracy: 0.7760\n",
            "Epoch 654/1100\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4359 - accuracy: 0.7969 - val_loss: 0.4729 - val_accuracy: 0.7760\n",
            "Epoch 655/1100\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4357 - accuracy: 0.7917 - val_loss: 0.4725 - val_accuracy: 0.7760\n",
            "Epoch 656/1100\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4355 - accuracy: 0.7882 - val_loss: 0.4729 - val_accuracy: 0.7708\n",
            "Epoch 657/1100\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4358 - accuracy: 0.7951 - val_loss: 0.4732 - val_accuracy: 0.7708\n",
            "Epoch 658/1100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4361 - accuracy: 0.7917 - val_loss: 0.4723 - val_accuracy: 0.7760\n",
            "Epoch 659/1100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4354 - accuracy: 0.7882 - val_loss: 0.4715 - val_accuracy: 0.7812\n",
            "Epoch 660/1100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4350 - accuracy: 0.7917 - val_loss: 0.4725 - val_accuracy: 0.7708\n",
            "Epoch 661/1100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4354 - accuracy: 0.7969 - val_loss: 0.4726 - val_accuracy: 0.7708\n",
            "Epoch 662/1100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4354 - accuracy: 0.7934 - val_loss: 0.4729 - val_accuracy: 0.7708\n",
            "Epoch 663/1100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4359 - accuracy: 0.7934 - val_loss: 0.4725 - val_accuracy: 0.7708\n",
            "Epoch 664/1100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4348 - accuracy: 0.7934 - val_loss: 0.4722 - val_accuracy: 0.7708\n",
            "Epoch 665/1100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4345 - accuracy: 0.7899 - val_loss: 0.4716 - val_accuracy: 0.7812\n",
            "Epoch 666/1100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4343 - accuracy: 0.7865 - val_loss: 0.4712 - val_accuracy: 0.7812\n",
            "Epoch 667/1100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4347 - accuracy: 0.7882 - val_loss: 0.4711 - val_accuracy: 0.7812\n",
            "Epoch 668/1100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4342 - accuracy: 0.8003 - val_loss: 0.4711 - val_accuracy: 0.7812\n",
            "Epoch 669/1100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4347 - accuracy: 0.7865 - val_loss: 0.4713 - val_accuracy: 0.7812\n",
            "Epoch 670/1100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4340 - accuracy: 0.7899 - val_loss: 0.4714 - val_accuracy: 0.7760\n",
            "Epoch 671/1100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4340 - accuracy: 0.7934 - val_loss: 0.4713 - val_accuracy: 0.7760\n",
            "Epoch 672/1100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4343 - accuracy: 0.7917 - val_loss: 0.4725 - val_accuracy: 0.7708\n",
            "Epoch 673/1100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4340 - accuracy: 0.7917 - val_loss: 0.4708 - val_accuracy: 0.7760\n",
            "Epoch 674/1100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4334 - accuracy: 0.7951 - val_loss: 0.4712 - val_accuracy: 0.7708\n",
            "Epoch 675/1100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4342 - accuracy: 0.7899 - val_loss: 0.4713 - val_accuracy: 0.7708\n",
            "Epoch 676/1100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4336 - accuracy: 0.7865 - val_loss: 0.4719 - val_accuracy: 0.7760\n",
            "Epoch 677/1100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4337 - accuracy: 0.7882 - val_loss: 0.4714 - val_accuracy: 0.7708\n",
            "Epoch 678/1100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4335 - accuracy: 0.7917 - val_loss: 0.4724 - val_accuracy: 0.7708\n",
            "Epoch 679/1100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4333 - accuracy: 0.7951 - val_loss: 0.4731 - val_accuracy: 0.7708\n",
            "Epoch 680/1100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4332 - accuracy: 0.7934 - val_loss: 0.4725 - val_accuracy: 0.7760\n",
            "Epoch 681/1100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4329 - accuracy: 0.7847 - val_loss: 0.4716 - val_accuracy: 0.7812\n",
            "Epoch 682/1100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4333 - accuracy: 0.7882 - val_loss: 0.4718 - val_accuracy: 0.7760\n",
            "Epoch 683/1100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4338 - accuracy: 0.7899 - val_loss: 0.4712 - val_accuracy: 0.7812\n",
            "Epoch 684/1100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4330 - accuracy: 0.7969 - val_loss: 0.4728 - val_accuracy: 0.7760\n",
            "Epoch 685/1100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4324 - accuracy: 0.7899 - val_loss: 0.4720 - val_accuracy: 0.7708\n",
            "Epoch 686/1100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4326 - accuracy: 0.7969 - val_loss: 0.4729 - val_accuracy: 0.7760\n",
            "Epoch 687/1100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4336 - accuracy: 0.7882 - val_loss: 0.4726 - val_accuracy: 0.7760\n",
            "Epoch 688/1100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4327 - accuracy: 0.7830 - val_loss: 0.4714 - val_accuracy: 0.7760\n",
            "Epoch 689/1100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4333 - accuracy: 0.7934 - val_loss: 0.4711 - val_accuracy: 0.7760\n",
            "Epoch 690/1100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4322 - accuracy: 0.7899 - val_loss: 0.4731 - val_accuracy: 0.7760\n",
            "Epoch 691/1100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4330 - accuracy: 0.7899 - val_loss: 0.4735 - val_accuracy: 0.7760\n",
            "Epoch 692/1100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4322 - accuracy: 0.7899 - val_loss: 0.4728 - val_accuracy: 0.7760\n",
            "Epoch 693/1100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4319 - accuracy: 0.7865 - val_loss: 0.4726 - val_accuracy: 0.7760\n",
            "Epoch 694/1100\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4318 - accuracy: 0.7934 - val_loss: 0.4716 - val_accuracy: 0.7812\n",
            "Epoch 695/1100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4323 - accuracy: 0.7934 - val_loss: 0.4721 - val_accuracy: 0.7708\n",
            "Epoch 696/1100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4325 - accuracy: 0.7934 - val_loss: 0.4720 - val_accuracy: 0.7708\n",
            "Epoch 697/1100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4315 - accuracy: 0.7882 - val_loss: 0.4713 - val_accuracy: 0.7760\n",
            "Epoch 698/1100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4318 - accuracy: 0.7865 - val_loss: 0.4720 - val_accuracy: 0.7760\n",
            "Epoch 699/1100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4317 - accuracy: 0.7847 - val_loss: 0.4723 - val_accuracy: 0.7708\n",
            "Epoch 700/1100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4313 - accuracy: 0.7882 - val_loss: 0.4728 - val_accuracy: 0.7708\n",
            "Epoch 701/1100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4309 - accuracy: 0.7917 - val_loss: 0.4721 - val_accuracy: 0.7708\n",
            "Epoch 702/1100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4312 - accuracy: 0.7917 - val_loss: 0.4731 - val_accuracy: 0.7760\n",
            "Epoch 703/1100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4309 - accuracy: 0.7934 - val_loss: 0.4731 - val_accuracy: 0.7760\n",
            "Epoch 704/1100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4303 - accuracy: 0.7899 - val_loss: 0.4712 - val_accuracy: 0.7760\n",
            "Epoch 705/1100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4309 - accuracy: 0.7882 - val_loss: 0.4719 - val_accuracy: 0.7708\n",
            "Epoch 706/1100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4308 - accuracy: 0.7917 - val_loss: 0.4718 - val_accuracy: 0.7708\n",
            "Epoch 707/1100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4309 - accuracy: 0.7934 - val_loss: 0.4739 - val_accuracy: 0.7760\n",
            "Epoch 708/1100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4305 - accuracy: 0.7865 - val_loss: 0.4722 - val_accuracy: 0.7708\n",
            "Epoch 709/1100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4305 - accuracy: 0.7917 - val_loss: 0.4741 - val_accuracy: 0.7760\n",
            "Epoch 710/1100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4304 - accuracy: 0.7882 - val_loss: 0.4726 - val_accuracy: 0.7708\n",
            "Epoch 711/1100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4308 - accuracy: 0.7969 - val_loss: 0.4723 - val_accuracy: 0.7708\n",
            "Epoch 712/1100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4302 - accuracy: 0.7899 - val_loss: 0.4714 - val_accuracy: 0.7760\n",
            "Epoch 713/1100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4301 - accuracy: 0.7917 - val_loss: 0.4718 - val_accuracy: 0.7708\n",
            "Epoch 714/1100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4307 - accuracy: 0.7917 - val_loss: 0.4723 - val_accuracy: 0.7708\n",
            "Epoch 715/1100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4300 - accuracy: 0.7934 - val_loss: 0.4733 - val_accuracy: 0.7760\n",
            "Epoch 716/1100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4299 - accuracy: 0.7917 - val_loss: 0.4723 - val_accuracy: 0.7708\n",
            "Epoch 717/1100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4296 - accuracy: 0.7934 - val_loss: 0.4707 - val_accuracy: 0.7708\n",
            "Epoch 718/1100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4296 - accuracy: 0.7951 - val_loss: 0.4707 - val_accuracy: 0.7760\n",
            "Epoch 719/1100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4298 - accuracy: 0.7951 - val_loss: 0.4720 - val_accuracy: 0.7760\n",
            "Epoch 720/1100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4298 - accuracy: 0.7882 - val_loss: 0.4714 - val_accuracy: 0.7708\n",
            "Epoch 721/1100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4287 - accuracy: 0.7917 - val_loss: 0.4706 - val_accuracy: 0.7812\n",
            "Epoch 722/1100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4288 - accuracy: 0.7934 - val_loss: 0.4736 - val_accuracy: 0.7760\n",
            "Epoch 723/1100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4299 - accuracy: 0.7934 - val_loss: 0.4718 - val_accuracy: 0.7708\n",
            "Epoch 724/1100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4296 - accuracy: 0.7917 - val_loss: 0.4726 - val_accuracy: 0.7760\n",
            "Epoch 725/1100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4288 - accuracy: 0.7882 - val_loss: 0.4727 - val_accuracy: 0.7708\n",
            "Epoch 726/1100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4307 - accuracy: 0.7865 - val_loss: 0.4725 - val_accuracy: 0.7760\n",
            "Epoch 727/1100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4289 - accuracy: 0.7917 - val_loss: 0.4736 - val_accuracy: 0.7760\n",
            "Epoch 728/1100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4281 - accuracy: 0.7899 - val_loss: 0.4721 - val_accuracy: 0.7708\n",
            "Epoch 729/1100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4287 - accuracy: 0.7899 - val_loss: 0.4712 - val_accuracy: 0.7865\n",
            "Epoch 730/1100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4292 - accuracy: 0.7969 - val_loss: 0.4734 - val_accuracy: 0.7760\n",
            "Epoch 731/1100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4286 - accuracy: 0.7951 - val_loss: 0.4720 - val_accuracy: 0.7812\n",
            "Epoch 732/1100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4287 - accuracy: 0.7934 - val_loss: 0.4722 - val_accuracy: 0.7760\n",
            "Epoch 733/1100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4277 - accuracy: 0.7934 - val_loss: 0.4745 - val_accuracy: 0.7760\n",
            "Epoch 734/1100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4284 - accuracy: 0.7865 - val_loss: 0.4731 - val_accuracy: 0.7760\n",
            "Epoch 735/1100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4278 - accuracy: 0.7951 - val_loss: 0.4703 - val_accuracy: 0.7812\n",
            "Epoch 736/1100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4276 - accuracy: 0.7969 - val_loss: 0.4749 - val_accuracy: 0.7812\n",
            "Epoch 737/1100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4282 - accuracy: 0.7917 - val_loss: 0.4729 - val_accuracy: 0.7760\n",
            "Epoch 738/1100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4276 - accuracy: 0.7899 - val_loss: 0.4713 - val_accuracy: 0.7708\n",
            "Epoch 739/1100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4285 - accuracy: 0.7951 - val_loss: 0.4709 - val_accuracy: 0.7708\n",
            "Epoch 740/1100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4274 - accuracy: 0.7934 - val_loss: 0.4709 - val_accuracy: 0.7708\n",
            "Epoch 741/1100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4274 - accuracy: 0.7951 - val_loss: 0.4704 - val_accuracy: 0.7760\n",
            "Epoch 742/1100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4270 - accuracy: 0.7899 - val_loss: 0.4707 - val_accuracy: 0.7708\n",
            "Epoch 743/1100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4284 - accuracy: 0.7969 - val_loss: 0.4728 - val_accuracy: 0.7760\n",
            "Epoch 744/1100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4272 - accuracy: 0.7934 - val_loss: 0.4721 - val_accuracy: 0.7708\n",
            "Epoch 745/1100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4265 - accuracy: 0.7951 - val_loss: 0.4700 - val_accuracy: 0.7760\n",
            "Epoch 746/1100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4270 - accuracy: 0.7969 - val_loss: 0.4722 - val_accuracy: 0.7708\n",
            "Epoch 747/1100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4276 - accuracy: 0.7899 - val_loss: 0.4713 - val_accuracy: 0.7708\n",
            "Epoch 748/1100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4261 - accuracy: 0.7899 - val_loss: 0.4725 - val_accuracy: 0.7812\n",
            "Epoch 749/1100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4268 - accuracy: 0.7934 - val_loss: 0.4716 - val_accuracy: 0.7708\n",
            "Epoch 750/1100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4259 - accuracy: 0.7934 - val_loss: 0.4748 - val_accuracy: 0.7812\n",
            "Epoch 751/1100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4275 - accuracy: 0.7917 - val_loss: 0.4720 - val_accuracy: 0.7760\n",
            "Epoch 752/1100\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4260 - accuracy: 0.7951 - val_loss: 0.4750 - val_accuracy: 0.7812\n",
            "Epoch 753/1100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4258 - accuracy: 0.7951 - val_loss: 0.4723 - val_accuracy: 0.7708\n",
            "Epoch 754/1100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4267 - accuracy: 0.7917 - val_loss: 0.4718 - val_accuracy: 0.7708\n",
            "Epoch 755/1100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4252 - accuracy: 0.7951 - val_loss: 0.4747 - val_accuracy: 0.7812\n",
            "Epoch 756/1100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4254 - accuracy: 0.7934 - val_loss: 0.4714 - val_accuracy: 0.7708\n",
            "Epoch 757/1100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4266 - accuracy: 0.7934 - val_loss: 0.4720 - val_accuracy: 0.7812\n",
            "Epoch 758/1100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4260 - accuracy: 0.7951 - val_loss: 0.4712 - val_accuracy: 0.7708\n",
            "Epoch 759/1100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4257 - accuracy: 0.7969 - val_loss: 0.4721 - val_accuracy: 0.7812\n",
            "Epoch 760/1100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4257 - accuracy: 0.7969 - val_loss: 0.4740 - val_accuracy: 0.7812\n",
            "Epoch 761/1100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4258 - accuracy: 0.7951 - val_loss: 0.4712 - val_accuracy: 0.7708\n",
            "Epoch 762/1100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4253 - accuracy: 0.7951 - val_loss: 0.4735 - val_accuracy: 0.7812\n",
            "Epoch 763/1100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4250 - accuracy: 0.7917 - val_loss: 0.4758 - val_accuracy: 0.7812\n",
            "Epoch 764/1100\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4254 - accuracy: 0.7899 - val_loss: 0.4730 - val_accuracy: 0.7760\n",
            "Epoch 765/1100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4255 - accuracy: 0.7917 - val_loss: 0.4727 - val_accuracy: 0.7760\n",
            "Epoch 766/1100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4243 - accuracy: 0.7969 - val_loss: 0.4720 - val_accuracy: 0.7760\n",
            "Epoch 767/1100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4246 - accuracy: 0.8021 - val_loss: 0.4717 - val_accuracy: 0.7708\n",
            "Epoch 768/1100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4249 - accuracy: 0.7951 - val_loss: 0.4720 - val_accuracy: 0.7760\n",
            "Epoch 769/1100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4246 - accuracy: 0.7917 - val_loss: 0.4712 - val_accuracy: 0.7708\n",
            "Epoch 770/1100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4243 - accuracy: 0.7917 - val_loss: 0.4725 - val_accuracy: 0.7760\n",
            "Epoch 771/1100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4246 - accuracy: 0.7899 - val_loss: 0.4715 - val_accuracy: 0.7708\n",
            "Epoch 772/1100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4246 - accuracy: 0.7934 - val_loss: 0.4739 - val_accuracy: 0.7812\n",
            "Epoch 773/1100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4237 - accuracy: 0.8003 - val_loss: 0.4737 - val_accuracy: 0.7812\n",
            "Epoch 774/1100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4241 - accuracy: 0.7899 - val_loss: 0.4724 - val_accuracy: 0.7760\n",
            "Epoch 775/1100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4237 - accuracy: 0.7917 - val_loss: 0.4722 - val_accuracy: 0.7812\n",
            "Epoch 776/1100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4238 - accuracy: 0.7934 - val_loss: 0.4711 - val_accuracy: 0.7708\n",
            "Epoch 777/1100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4238 - accuracy: 0.7934 - val_loss: 0.4709 - val_accuracy: 0.7708\n",
            "Epoch 778/1100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4247 - accuracy: 0.7917 - val_loss: 0.4724 - val_accuracy: 0.7760\n",
            "Epoch 779/1100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4236 - accuracy: 0.7951 - val_loss: 0.4743 - val_accuracy: 0.7812\n",
            "Epoch 780/1100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4237 - accuracy: 0.7917 - val_loss: 0.4712 - val_accuracy: 0.7760\n",
            "Epoch 781/1100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4242 - accuracy: 0.7951 - val_loss: 0.4740 - val_accuracy: 0.7812\n",
            "Epoch 782/1100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4228 - accuracy: 0.7917 - val_loss: 0.4714 - val_accuracy: 0.7708\n",
            "Epoch 783/1100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4230 - accuracy: 0.8003 - val_loss: 0.4715 - val_accuracy: 0.7708\n",
            "Epoch 784/1100\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4234 - accuracy: 0.7951 - val_loss: 0.4732 - val_accuracy: 0.7812\n",
            "Epoch 785/1100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4229 - accuracy: 0.7934 - val_loss: 0.4724 - val_accuracy: 0.7708\n",
            "Epoch 786/1100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4230 - accuracy: 0.7951 - val_loss: 0.4728 - val_accuracy: 0.7760\n",
            "Epoch 787/1100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4225 - accuracy: 0.7969 - val_loss: 0.4744 - val_accuracy: 0.7812\n",
            "Epoch 788/1100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4228 - accuracy: 0.7969 - val_loss: 0.4704 - val_accuracy: 0.7760\n",
            "Epoch 789/1100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4235 - accuracy: 0.7934 - val_loss: 0.4704 - val_accuracy: 0.7708\n",
            "Epoch 790/1100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4221 - accuracy: 0.8056 - val_loss: 0.4751 - val_accuracy: 0.7760\n",
            "Epoch 791/1100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4222 - accuracy: 0.7934 - val_loss: 0.4721 - val_accuracy: 0.7708\n",
            "Epoch 792/1100\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4225 - accuracy: 0.7917 - val_loss: 0.4715 - val_accuracy: 0.7708\n",
            "Epoch 793/1100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4219 - accuracy: 0.8038 - val_loss: 0.4749 - val_accuracy: 0.7760\n",
            "Epoch 794/1100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4231 - accuracy: 0.7986 - val_loss: 0.4721 - val_accuracy: 0.7708\n",
            "Epoch 795/1100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4217 - accuracy: 0.7951 - val_loss: 0.4756 - val_accuracy: 0.7760\n",
            "Epoch 796/1100\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4218 - accuracy: 0.7934 - val_loss: 0.4744 - val_accuracy: 0.7760\n",
            "Epoch 797/1100\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4218 - accuracy: 0.7969 - val_loss: 0.4739 - val_accuracy: 0.7656\n",
            "Epoch 798/1100\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4220 - accuracy: 0.7986 - val_loss: 0.4732 - val_accuracy: 0.7656\n",
            "Epoch 799/1100\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4214 - accuracy: 0.7917 - val_loss: 0.4713 - val_accuracy: 0.7708\n",
            "Epoch 800/1100\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4213 - accuracy: 0.7969 - val_loss: 0.4711 - val_accuracy: 0.7708\n",
            "Epoch 801/1100\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4229 - accuracy: 0.8003 - val_loss: 0.4729 - val_accuracy: 0.7656\n",
            "Epoch 802/1100\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4218 - accuracy: 0.8038 - val_loss: 0.4758 - val_accuracy: 0.7760\n",
            "Epoch 803/1100\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4205 - accuracy: 0.7899 - val_loss: 0.4711 - val_accuracy: 0.7708\n",
            "Epoch 804/1100\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4217 - accuracy: 0.8003 - val_loss: 0.4736 - val_accuracy: 0.7656\n",
            "Epoch 805/1100\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4198 - accuracy: 0.7951 - val_loss: 0.4714 - val_accuracy: 0.7708\n",
            "Epoch 806/1100\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4221 - accuracy: 0.8003 - val_loss: 0.4725 - val_accuracy: 0.7708\n",
            "Epoch 807/1100\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4220 - accuracy: 0.8021 - val_loss: 0.4726 - val_accuracy: 0.7708\n",
            "Epoch 808/1100\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4210 - accuracy: 0.8003 - val_loss: 0.4728 - val_accuracy: 0.7604\n",
            "Epoch 809/1100\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4223 - accuracy: 0.7969 - val_loss: 0.4732 - val_accuracy: 0.7604\n",
            "Epoch 810/1100\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4203 - accuracy: 0.7969 - val_loss: 0.4725 - val_accuracy: 0.7708\n",
            "Epoch 811/1100\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4201 - accuracy: 0.7951 - val_loss: 0.4712 - val_accuracy: 0.7760\n",
            "Epoch 812/1100\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4211 - accuracy: 0.8021 - val_loss: 0.4709 - val_accuracy: 0.7760\n",
            "Epoch 813/1100\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4211 - accuracy: 0.7986 - val_loss: 0.4755 - val_accuracy: 0.7708\n",
            "Epoch 814/1100\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4205 - accuracy: 0.7969 - val_loss: 0.4731 - val_accuracy: 0.7656\n",
            "Epoch 815/1100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4197 - accuracy: 0.8003 - val_loss: 0.4751 - val_accuracy: 0.7656\n",
            "Epoch 816/1100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4193 - accuracy: 0.7934 - val_loss: 0.4725 - val_accuracy: 0.7760\n",
            "Epoch 817/1100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4204 - accuracy: 0.8021 - val_loss: 0.4740 - val_accuracy: 0.7656\n",
            "Epoch 818/1100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4203 - accuracy: 0.8003 - val_loss: 0.4746 - val_accuracy: 0.7656\n",
            "Epoch 819/1100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4200 - accuracy: 0.7917 - val_loss: 0.4733 - val_accuracy: 0.7656\n",
            "Epoch 820/1100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4200 - accuracy: 0.8056 - val_loss: 0.4761 - val_accuracy: 0.7656\n",
            "Epoch 821/1100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4199 - accuracy: 0.7969 - val_loss: 0.4739 - val_accuracy: 0.7656\n",
            "Epoch 822/1100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4191 - accuracy: 0.7934 - val_loss: 0.4719 - val_accuracy: 0.7656\n",
            "Epoch 823/1100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4214 - accuracy: 0.7986 - val_loss: 0.4750 - val_accuracy: 0.7604\n",
            "Epoch 824/1100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4201 - accuracy: 0.7986 - val_loss: 0.4758 - val_accuracy: 0.7656\n",
            "Epoch 825/1100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4193 - accuracy: 0.7986 - val_loss: 0.4758 - val_accuracy: 0.7656\n",
            "Epoch 826/1100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4189 - accuracy: 0.7934 - val_loss: 0.4733 - val_accuracy: 0.7656\n",
            "Epoch 827/1100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4193 - accuracy: 0.7969 - val_loss: 0.4748 - val_accuracy: 0.7604\n",
            "Epoch 828/1100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4194 - accuracy: 0.8003 - val_loss: 0.4745 - val_accuracy: 0.7656\n",
            "Epoch 829/1100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4185 - accuracy: 0.8073 - val_loss: 0.4783 - val_accuracy: 0.7708\n",
            "Epoch 830/1100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4195 - accuracy: 0.7986 - val_loss: 0.4771 - val_accuracy: 0.7656\n",
            "Epoch 831/1100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4184 - accuracy: 0.8021 - val_loss: 0.4776 - val_accuracy: 0.7656\n",
            "Epoch 832/1100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4185 - accuracy: 0.8021 - val_loss: 0.4726 - val_accuracy: 0.7760\n",
            "Epoch 833/1100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4187 - accuracy: 0.8021 - val_loss: 0.4739 - val_accuracy: 0.7708\n",
            "Epoch 834/1100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4180 - accuracy: 0.8003 - val_loss: 0.4746 - val_accuracy: 0.7656\n",
            "Epoch 835/1100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4178 - accuracy: 0.8021 - val_loss: 0.4752 - val_accuracy: 0.7656\n",
            "Epoch 836/1100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4187 - accuracy: 0.7969 - val_loss: 0.4765 - val_accuracy: 0.7656\n",
            "Epoch 837/1100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4181 - accuracy: 0.7934 - val_loss: 0.4733 - val_accuracy: 0.7708\n",
            "Epoch 838/1100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4179 - accuracy: 0.8038 - val_loss: 0.4735 - val_accuracy: 0.7656\n",
            "Epoch 839/1100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4181 - accuracy: 0.8021 - val_loss: 0.4735 - val_accuracy: 0.7604\n",
            "Epoch 840/1100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4177 - accuracy: 0.8021 - val_loss: 0.4753 - val_accuracy: 0.7656\n",
            "Epoch 841/1100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4192 - accuracy: 0.8090 - val_loss: 0.4756 - val_accuracy: 0.7656\n",
            "Epoch 842/1100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4177 - accuracy: 0.7934 - val_loss: 0.4718 - val_accuracy: 0.7708\n",
            "Epoch 843/1100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4178 - accuracy: 0.8038 - val_loss: 0.4778 - val_accuracy: 0.7604\n",
            "Epoch 844/1100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4181 - accuracy: 0.8003 - val_loss: 0.4771 - val_accuracy: 0.7604\n",
            "Epoch 845/1100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4172 - accuracy: 0.7934 - val_loss: 0.4748 - val_accuracy: 0.7604\n",
            "Epoch 846/1100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4187 - accuracy: 0.8021 - val_loss: 0.4757 - val_accuracy: 0.7656\n",
            "Epoch 847/1100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4164 - accuracy: 0.8038 - val_loss: 0.4774 - val_accuracy: 0.7656\n",
            "Epoch 848/1100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4169 - accuracy: 0.8003 - val_loss: 0.4747 - val_accuracy: 0.7604\n",
            "Epoch 849/1100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4169 - accuracy: 0.8003 - val_loss: 0.4742 - val_accuracy: 0.7604\n",
            "Epoch 850/1100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4173 - accuracy: 0.7986 - val_loss: 0.4730 - val_accuracy: 0.7604\n",
            "Epoch 851/1100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4172 - accuracy: 0.8056 - val_loss: 0.4754 - val_accuracy: 0.7656\n",
            "Epoch 852/1100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4161 - accuracy: 0.8073 - val_loss: 0.4816 - val_accuracy: 0.7708\n",
            "Epoch 853/1100\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4175 - accuracy: 0.8056 - val_loss: 0.4773 - val_accuracy: 0.7604\n",
            "Epoch 854/1100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4170 - accuracy: 0.8073 - val_loss: 0.4778 - val_accuracy: 0.7604\n",
            "Epoch 855/1100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4186 - accuracy: 0.8003 - val_loss: 0.4777 - val_accuracy: 0.7656\n",
            "Epoch 856/1100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4172 - accuracy: 0.8003 - val_loss: 0.4780 - val_accuracy: 0.7656\n",
            "Epoch 857/1100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4167 - accuracy: 0.8038 - val_loss: 0.4762 - val_accuracy: 0.7604\n",
            "Epoch 858/1100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4171 - accuracy: 0.8038 - val_loss: 0.4765 - val_accuracy: 0.7604\n",
            "Epoch 859/1100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4163 - accuracy: 0.8056 - val_loss: 0.4741 - val_accuracy: 0.7604\n",
            "Epoch 860/1100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4163 - accuracy: 0.8056 - val_loss: 0.4798 - val_accuracy: 0.7708\n",
            "Epoch 861/1100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4177 - accuracy: 0.8003 - val_loss: 0.4794 - val_accuracy: 0.7656\n",
            "Epoch 862/1100\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4159 - accuracy: 0.8056 - val_loss: 0.4804 - val_accuracy: 0.7708\n",
            "Epoch 863/1100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4150 - accuracy: 0.8056 - val_loss: 0.4752 - val_accuracy: 0.7656\n",
            "Epoch 864/1100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4155 - accuracy: 0.8038 - val_loss: 0.4775 - val_accuracy: 0.7760\n",
            "Epoch 865/1100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4155 - accuracy: 0.8056 - val_loss: 0.4735 - val_accuracy: 0.7604\n",
            "Epoch 866/1100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4166 - accuracy: 0.8038 - val_loss: 0.4738 - val_accuracy: 0.7656\n",
            "Epoch 867/1100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4163 - accuracy: 0.8038 - val_loss: 0.4745 - val_accuracy: 0.7604\n",
            "Epoch 868/1100\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4161 - accuracy: 0.8056 - val_loss: 0.4774 - val_accuracy: 0.7604\n",
            "Epoch 869/1100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4161 - accuracy: 0.8056 - val_loss: 0.4749 - val_accuracy: 0.7604\n",
            "Epoch 870/1100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4165 - accuracy: 0.8056 - val_loss: 0.4758 - val_accuracy: 0.7604\n",
            "Epoch 871/1100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4156 - accuracy: 0.8073 - val_loss: 0.4748 - val_accuracy: 0.7604\n",
            "Epoch 872/1100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4164 - accuracy: 0.7986 - val_loss: 0.4769 - val_accuracy: 0.7604\n",
            "Epoch 873/1100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4147 - accuracy: 0.8021 - val_loss: 0.4781 - val_accuracy: 0.7604\n",
            "Epoch 874/1100\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4164 - accuracy: 0.8003 - val_loss: 0.4766 - val_accuracy: 0.7604\n",
            "Epoch 875/1100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4149 - accuracy: 0.8038 - val_loss: 0.4768 - val_accuracy: 0.7656\n",
            "Epoch 876/1100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4153 - accuracy: 0.8090 - val_loss: 0.4777 - val_accuracy: 0.7604\n",
            "Epoch 877/1100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4151 - accuracy: 0.8056 - val_loss: 0.4767 - val_accuracy: 0.7604\n",
            "Epoch 878/1100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4148 - accuracy: 0.8090 - val_loss: 0.4750 - val_accuracy: 0.7708\n",
            "Epoch 879/1100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4140 - accuracy: 0.8073 - val_loss: 0.4794 - val_accuracy: 0.7760\n",
            "Epoch 880/1100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4142 - accuracy: 0.8021 - val_loss: 0.4740 - val_accuracy: 0.7656\n",
            "Epoch 881/1100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4142 - accuracy: 0.8073 - val_loss: 0.4754 - val_accuracy: 0.7656\n",
            "Epoch 882/1100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4140 - accuracy: 0.8073 - val_loss: 0.4747 - val_accuracy: 0.7656\n",
            "Epoch 883/1100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4134 - accuracy: 0.8021 - val_loss: 0.4779 - val_accuracy: 0.7760\n",
            "Epoch 884/1100\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4139 - accuracy: 0.8108 - val_loss: 0.4797 - val_accuracy: 0.7604\n",
            "Epoch 885/1100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4147 - accuracy: 0.8038 - val_loss: 0.4787 - val_accuracy: 0.7604\n",
            "Epoch 886/1100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4138 - accuracy: 0.8056 - val_loss: 0.4774 - val_accuracy: 0.7656\n",
            "Epoch 887/1100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4130 - accuracy: 0.8073 - val_loss: 0.4820 - val_accuracy: 0.7760\n",
            "Epoch 888/1100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4145 - accuracy: 0.8021 - val_loss: 0.4776 - val_accuracy: 0.7656\n",
            "Epoch 889/1100\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4131 - accuracy: 0.8073 - val_loss: 0.4791 - val_accuracy: 0.7708\n",
            "Epoch 890/1100\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4122 - accuracy: 0.8056 - val_loss: 0.4740 - val_accuracy: 0.7656\n",
            "Epoch 891/1100\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4133 - accuracy: 0.8073 - val_loss: 0.4764 - val_accuracy: 0.7708\n",
            "Epoch 892/1100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4132 - accuracy: 0.8038 - val_loss: 0.4765 - val_accuracy: 0.7708\n",
            "Epoch 893/1100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4132 - accuracy: 0.8038 - val_loss: 0.4813 - val_accuracy: 0.7708\n",
            "Epoch 894/1100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4144 - accuracy: 0.8038 - val_loss: 0.4816 - val_accuracy: 0.7760\n",
            "Epoch 895/1100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4119 - accuracy: 0.8090 - val_loss: 0.4754 - val_accuracy: 0.7656\n",
            "Epoch 896/1100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4149 - accuracy: 0.8038 - val_loss: 0.4796 - val_accuracy: 0.7656\n",
            "Epoch 897/1100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4131 - accuracy: 0.8038 - val_loss: 0.4772 - val_accuracy: 0.7708\n",
            "Epoch 898/1100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4128 - accuracy: 0.8108 - val_loss: 0.4764 - val_accuracy: 0.7656\n",
            "Epoch 899/1100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4129 - accuracy: 0.7986 - val_loss: 0.4822 - val_accuracy: 0.7708\n",
            "Epoch 900/1100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4119 - accuracy: 0.8090 - val_loss: 0.4773 - val_accuracy: 0.7656\n",
            "Epoch 901/1100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4122 - accuracy: 0.8038 - val_loss: 0.4780 - val_accuracy: 0.7656\n",
            "Epoch 902/1100\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4121 - accuracy: 0.8108 - val_loss: 0.4788 - val_accuracy: 0.7656\n",
            "Epoch 903/1100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4121 - accuracy: 0.8021 - val_loss: 0.4770 - val_accuracy: 0.7656\n",
            "Epoch 904/1100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4128 - accuracy: 0.8021 - val_loss: 0.4772 - val_accuracy: 0.7656\n",
            "Epoch 905/1100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4142 - accuracy: 0.8038 - val_loss: 0.4796 - val_accuracy: 0.7656\n",
            "Epoch 906/1100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4114 - accuracy: 0.8038 - val_loss: 0.4770 - val_accuracy: 0.7656\n",
            "Epoch 907/1100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4120 - accuracy: 0.8021 - val_loss: 0.4805 - val_accuracy: 0.7604\n",
            "Epoch 908/1100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4111 - accuracy: 0.8038 - val_loss: 0.4784 - val_accuracy: 0.7604\n",
            "Epoch 909/1100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4109 - accuracy: 0.8056 - val_loss: 0.4848 - val_accuracy: 0.7656\n",
            "Epoch 910/1100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4111 - accuracy: 0.8090 - val_loss: 0.4823 - val_accuracy: 0.7708\n",
            "Epoch 911/1100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4106 - accuracy: 0.8108 - val_loss: 0.4776 - val_accuracy: 0.7656\n",
            "Epoch 912/1100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4112 - accuracy: 0.8090 - val_loss: 0.4795 - val_accuracy: 0.7708\n",
            "Epoch 913/1100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4116 - accuracy: 0.8090 - val_loss: 0.4801 - val_accuracy: 0.7708\n",
            "Epoch 914/1100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4111 - accuracy: 0.8056 - val_loss: 0.4788 - val_accuracy: 0.7708\n",
            "Epoch 915/1100\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4108 - accuracy: 0.8073 - val_loss: 0.4811 - val_accuracy: 0.7604\n",
            "Epoch 916/1100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4107 - accuracy: 0.8090 - val_loss: 0.4850 - val_accuracy: 0.7708\n",
            "Epoch 917/1100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4104 - accuracy: 0.8073 - val_loss: 0.4845 - val_accuracy: 0.7760\n",
            "Epoch 918/1100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4110 - accuracy: 0.8090 - val_loss: 0.4802 - val_accuracy: 0.7604\n",
            "Epoch 919/1100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4107 - accuracy: 0.8056 - val_loss: 0.4803 - val_accuracy: 0.7604\n",
            "Epoch 920/1100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4104 - accuracy: 0.8056 - val_loss: 0.4825 - val_accuracy: 0.7604\n",
            "Epoch 921/1100\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4117 - accuracy: 0.8073 - val_loss: 0.4838 - val_accuracy: 0.7760\n",
            "Epoch 922/1100\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4107 - accuracy: 0.8038 - val_loss: 0.4817 - val_accuracy: 0.7656\n",
            "Epoch 923/1100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4113 - accuracy: 0.8073 - val_loss: 0.4778 - val_accuracy: 0.7708\n",
            "Epoch 924/1100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4104 - accuracy: 0.8056 - val_loss: 0.4802 - val_accuracy: 0.7656\n",
            "Epoch 925/1100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4108 - accuracy: 0.8056 - val_loss: 0.4802 - val_accuracy: 0.7604\n",
            "Epoch 926/1100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4095 - accuracy: 0.8056 - val_loss: 0.4836 - val_accuracy: 0.7656\n",
            "Epoch 927/1100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4111 - accuracy: 0.8038 - val_loss: 0.4819 - val_accuracy: 0.7760\n",
            "Epoch 928/1100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4105 - accuracy: 0.8125 - val_loss: 0.4808 - val_accuracy: 0.7708\n",
            "Epoch 929/1100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4098 - accuracy: 0.8073 - val_loss: 0.4890 - val_accuracy: 0.7656\n",
            "Epoch 930/1100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4122 - accuracy: 0.8056 - val_loss: 0.4806 - val_accuracy: 0.7656\n",
            "Epoch 931/1100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4103 - accuracy: 0.8090 - val_loss: 0.4780 - val_accuracy: 0.7604\n",
            "Epoch 932/1100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4110 - accuracy: 0.8056 - val_loss: 0.4811 - val_accuracy: 0.7708\n",
            "Epoch 933/1100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4098 - accuracy: 0.8073 - val_loss: 0.4835 - val_accuracy: 0.7708\n",
            "Epoch 934/1100\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4095 - accuracy: 0.8125 - val_loss: 0.4794 - val_accuracy: 0.7604\n",
            "Epoch 935/1100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4098 - accuracy: 0.8090 - val_loss: 0.4812 - val_accuracy: 0.7604\n",
            "Epoch 936/1100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4101 - accuracy: 0.8021 - val_loss: 0.4840 - val_accuracy: 0.7656\n",
            "Epoch 937/1100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4091 - accuracy: 0.8073 - val_loss: 0.4812 - val_accuracy: 0.7708\n",
            "Epoch 938/1100\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4096 - accuracy: 0.8021 - val_loss: 0.4820 - val_accuracy: 0.7604\n",
            "Epoch 939/1100\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4101 - accuracy: 0.8056 - val_loss: 0.4840 - val_accuracy: 0.7604\n",
            "Epoch 940/1100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4078 - accuracy: 0.8125 - val_loss: 0.4781 - val_accuracy: 0.7708\n",
            "Epoch 941/1100\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4091 - accuracy: 0.8003 - val_loss: 0.4797 - val_accuracy: 0.7760\n",
            "Epoch 942/1100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4092 - accuracy: 0.8090 - val_loss: 0.4806 - val_accuracy: 0.7656\n",
            "Epoch 943/1100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4098 - accuracy: 0.8073 - val_loss: 0.4817 - val_accuracy: 0.7656\n",
            "Epoch 944/1100\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4087 - accuracy: 0.8038 - val_loss: 0.4815 - val_accuracy: 0.7656\n",
            "Epoch 945/1100\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4083 - accuracy: 0.8056 - val_loss: 0.4815 - val_accuracy: 0.7656\n",
            "Epoch 946/1100\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4088 - accuracy: 0.8038 - val_loss: 0.4814 - val_accuracy: 0.7656\n",
            "Epoch 947/1100\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4098 - accuracy: 0.8142 - val_loss: 0.4833 - val_accuracy: 0.7708\n",
            "Epoch 948/1100\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4087 - accuracy: 0.8021 - val_loss: 0.4816 - val_accuracy: 0.7656\n",
            "Epoch 949/1100\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4085 - accuracy: 0.8073 - val_loss: 0.4822 - val_accuracy: 0.7708\n",
            "Epoch 950/1100\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4070 - accuracy: 0.8108 - val_loss: 0.4809 - val_accuracy: 0.7604\n",
            "Epoch 951/1100\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4085 - accuracy: 0.8021 - val_loss: 0.4843 - val_accuracy: 0.7604\n",
            "Epoch 952/1100\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4081 - accuracy: 0.7986 - val_loss: 0.4854 - val_accuracy: 0.7656\n",
            "Epoch 953/1100\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4086 - accuracy: 0.8073 - val_loss: 0.4809 - val_accuracy: 0.7604\n",
            "Epoch 954/1100\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4071 - accuracy: 0.8108 - val_loss: 0.4843 - val_accuracy: 0.7708\n",
            "Epoch 955/1100\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4095 - accuracy: 0.8038 - val_loss: 0.4831 - val_accuracy: 0.7552\n",
            "Epoch 956/1100\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4069 - accuracy: 0.8108 - val_loss: 0.4831 - val_accuracy: 0.7604\n",
            "Epoch 957/1100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4087 - accuracy: 0.8073 - val_loss: 0.4789 - val_accuracy: 0.7604\n",
            "Epoch 958/1100\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4079 - accuracy: 0.8073 - val_loss: 0.4857 - val_accuracy: 0.7656\n",
            "Epoch 959/1100\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4089 - accuracy: 0.8090 - val_loss: 0.4799 - val_accuracy: 0.7604\n",
            "Epoch 960/1100\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4080 - accuracy: 0.8056 - val_loss: 0.4816 - val_accuracy: 0.7656\n",
            "Epoch 961/1100\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4077 - accuracy: 0.8073 - val_loss: 0.4879 - val_accuracy: 0.7604\n",
            "Epoch 962/1100\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4089 - accuracy: 0.8108 - val_loss: 0.4847 - val_accuracy: 0.7656\n",
            "Epoch 963/1100\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4091 - accuracy: 0.8090 - val_loss: 0.4800 - val_accuracy: 0.7604\n",
            "Epoch 964/1100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4080 - accuracy: 0.8108 - val_loss: 0.4792 - val_accuracy: 0.7604\n",
            "Epoch 965/1100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4071 - accuracy: 0.8056 - val_loss: 0.4850 - val_accuracy: 0.7656\n",
            "Epoch 966/1100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4082 - accuracy: 0.8090 - val_loss: 0.4844 - val_accuracy: 0.7656\n",
            "Epoch 967/1100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4070 - accuracy: 0.8073 - val_loss: 0.4813 - val_accuracy: 0.7656\n",
            "Epoch 968/1100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4078 - accuracy: 0.8056 - val_loss: 0.4844 - val_accuracy: 0.7708\n",
            "Epoch 969/1100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4071 - accuracy: 0.8021 - val_loss: 0.4898 - val_accuracy: 0.7656\n",
            "Epoch 970/1100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4083 - accuracy: 0.8038 - val_loss: 0.4850 - val_accuracy: 0.7604\n",
            "Epoch 971/1100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4073 - accuracy: 0.8056 - val_loss: 0.4794 - val_accuracy: 0.7708\n",
            "Epoch 972/1100\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4089 - accuracy: 0.8108 - val_loss: 0.4863 - val_accuracy: 0.7604\n",
            "Epoch 973/1100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4085 - accuracy: 0.8090 - val_loss: 0.4850 - val_accuracy: 0.7708\n",
            "Epoch 974/1100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4068 - accuracy: 0.8125 - val_loss: 0.4869 - val_accuracy: 0.7708\n",
            "Epoch 975/1100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4070 - accuracy: 0.8125 - val_loss: 0.4822 - val_accuracy: 0.7656\n",
            "Epoch 976/1100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4058 - accuracy: 0.8073 - val_loss: 0.4854 - val_accuracy: 0.7656\n",
            "Epoch 977/1100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4078 - accuracy: 0.8056 - val_loss: 0.4824 - val_accuracy: 0.7708\n",
            "Epoch 978/1100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4070 - accuracy: 0.8056 - val_loss: 0.4848 - val_accuracy: 0.7656\n",
            "Epoch 979/1100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4062 - accuracy: 0.8090 - val_loss: 0.4839 - val_accuracy: 0.7552\n",
            "Epoch 980/1100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4069 - accuracy: 0.8125 - val_loss: 0.4826 - val_accuracy: 0.7656\n",
            "Epoch 981/1100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4073 - accuracy: 0.8073 - val_loss: 0.4823 - val_accuracy: 0.7604\n",
            "Epoch 982/1100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4071 - accuracy: 0.8090 - val_loss: 0.4821 - val_accuracy: 0.7708\n",
            "Epoch 983/1100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4061 - accuracy: 0.8108 - val_loss: 0.4885 - val_accuracy: 0.7656\n",
            "Epoch 984/1100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4073 - accuracy: 0.8125 - val_loss: 0.4833 - val_accuracy: 0.7760\n",
            "Epoch 985/1100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4069 - accuracy: 0.8125 - val_loss: 0.4865 - val_accuracy: 0.7656\n",
            "Epoch 986/1100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4062 - accuracy: 0.8125 - val_loss: 0.4908 - val_accuracy: 0.7604\n",
            "Epoch 987/1100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4065 - accuracy: 0.8125 - val_loss: 0.4853 - val_accuracy: 0.7604\n",
            "Epoch 988/1100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4063 - accuracy: 0.8125 - val_loss: 0.4836 - val_accuracy: 0.7604\n",
            "Epoch 989/1100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4074 - accuracy: 0.8073 - val_loss: 0.4859 - val_accuracy: 0.7604\n",
            "Epoch 990/1100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4061 - accuracy: 0.8108 - val_loss: 0.4838 - val_accuracy: 0.7656\n",
            "Epoch 991/1100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4077 - accuracy: 0.8142 - val_loss: 0.4851 - val_accuracy: 0.7604\n",
            "Epoch 992/1100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4075 - accuracy: 0.8142 - val_loss: 0.4850 - val_accuracy: 0.7604\n",
            "Epoch 993/1100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4065 - accuracy: 0.8090 - val_loss: 0.4818 - val_accuracy: 0.7656\n",
            "Epoch 994/1100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4058 - accuracy: 0.8090 - val_loss: 0.4825 - val_accuracy: 0.7604\n",
            "Epoch 995/1100\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4062 - accuracy: 0.8090 - val_loss: 0.4822 - val_accuracy: 0.7604\n",
            "Epoch 996/1100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4055 - accuracy: 0.8108 - val_loss: 0.4865 - val_accuracy: 0.7656\n",
            "Epoch 997/1100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4065 - accuracy: 0.8108 - val_loss: 0.4833 - val_accuracy: 0.7604\n",
            "Epoch 998/1100\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4065 - accuracy: 0.8108 - val_loss: 0.4802 - val_accuracy: 0.7656\n",
            "Epoch 999/1100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4060 - accuracy: 0.8090 - val_loss: 0.4887 - val_accuracy: 0.7656\n",
            "Epoch 1000/1100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4074 - accuracy: 0.8108 - val_loss: 0.4852 - val_accuracy: 0.7656\n",
            "Epoch 1001/1100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4059 - accuracy: 0.8090 - val_loss: 0.4835 - val_accuracy: 0.7604\n",
            "Epoch 1002/1100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4064 - accuracy: 0.8056 - val_loss: 0.4829 - val_accuracy: 0.7656\n",
            "Epoch 1003/1100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4054 - accuracy: 0.8021 - val_loss: 0.4850 - val_accuracy: 0.7604\n",
            "Epoch 1004/1100\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4052 - accuracy: 0.8108 - val_loss: 0.4842 - val_accuracy: 0.7656\n",
            "Epoch 1005/1100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4049 - accuracy: 0.8090 - val_loss: 0.4883 - val_accuracy: 0.7656\n",
            "Epoch 1006/1100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4052 - accuracy: 0.8090 - val_loss: 0.4831 - val_accuracy: 0.7708\n",
            "Epoch 1007/1100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4072 - accuracy: 0.8056 - val_loss: 0.4857 - val_accuracy: 0.7604\n",
            "Epoch 1008/1100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4054 - accuracy: 0.8073 - val_loss: 0.4877 - val_accuracy: 0.7604\n",
            "Epoch 1009/1100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4053 - accuracy: 0.8090 - val_loss: 0.4840 - val_accuracy: 0.7604\n",
            "Epoch 1010/1100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4055 - accuracy: 0.8090 - val_loss: 0.4845 - val_accuracy: 0.7708\n",
            "Epoch 1011/1100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4053 - accuracy: 0.8160 - val_loss: 0.4829 - val_accuracy: 0.7656\n",
            "Epoch 1012/1100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4064 - accuracy: 0.8125 - val_loss: 0.4848 - val_accuracy: 0.7604\n",
            "Epoch 1013/1100\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4055 - accuracy: 0.8125 - val_loss: 0.4827 - val_accuracy: 0.7708\n",
            "Epoch 1014/1100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4064 - accuracy: 0.8125 - val_loss: 0.4831 - val_accuracy: 0.7708\n",
            "Epoch 1015/1100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4040 - accuracy: 0.8125 - val_loss: 0.4854 - val_accuracy: 0.7656\n",
            "Epoch 1016/1100\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4054 - accuracy: 0.8108 - val_loss: 0.4878 - val_accuracy: 0.7604\n",
            "Epoch 1017/1100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4043 - accuracy: 0.8160 - val_loss: 0.4847 - val_accuracy: 0.7604\n",
            "Epoch 1018/1100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4062 - accuracy: 0.8056 - val_loss: 0.4815 - val_accuracy: 0.7604\n",
            "Epoch 1019/1100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4051 - accuracy: 0.8160 - val_loss: 0.4856 - val_accuracy: 0.7604\n",
            "Epoch 1020/1100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4009 - accuracy: 0.8229 - val_loss: 0.4802 - val_accuracy: 0.7656\n",
            "Epoch 1021/1100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4068 - accuracy: 0.8056 - val_loss: 0.4830 - val_accuracy: 0.7656\n",
            "Epoch 1022/1100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4057 - accuracy: 0.8056 - val_loss: 0.4839 - val_accuracy: 0.7656\n",
            "Epoch 1023/1100\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4045 - accuracy: 0.8108 - val_loss: 0.4837 - val_accuracy: 0.7604\n",
            "Epoch 1024/1100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4050 - accuracy: 0.8108 - val_loss: 0.4874 - val_accuracy: 0.7604\n",
            "Epoch 1025/1100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4046 - accuracy: 0.8142 - val_loss: 0.4826 - val_accuracy: 0.7656\n",
            "Epoch 1026/1100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4045 - accuracy: 0.8090 - val_loss: 0.4826 - val_accuracy: 0.7708\n",
            "Epoch 1027/1100\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4054 - accuracy: 0.8073 - val_loss: 0.4812 - val_accuracy: 0.7656\n",
            "Epoch 1028/1100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4023 - accuracy: 0.8160 - val_loss: 0.4796 - val_accuracy: 0.7708\n",
            "Epoch 1029/1100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4053 - accuracy: 0.8073 - val_loss: 0.4840 - val_accuracy: 0.7708\n",
            "Epoch 1030/1100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4049 - accuracy: 0.8090 - val_loss: 0.4896 - val_accuracy: 0.7604\n",
            "Epoch 1031/1100\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4036 - accuracy: 0.8177 - val_loss: 0.4923 - val_accuracy: 0.7604\n",
            "Epoch 1032/1100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4057 - accuracy: 0.8090 - val_loss: 0.4835 - val_accuracy: 0.7656\n",
            "Epoch 1033/1100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4061 - accuracy: 0.8073 - val_loss: 0.4836 - val_accuracy: 0.7656\n",
            "Epoch 1034/1100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4037 - accuracy: 0.8090 - val_loss: 0.4842 - val_accuracy: 0.7708\n",
            "Epoch 1035/1100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4039 - accuracy: 0.8160 - val_loss: 0.4851 - val_accuracy: 0.7656\n",
            "Epoch 1036/1100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4040 - accuracy: 0.8125 - val_loss: 0.4861 - val_accuracy: 0.7552\n",
            "Epoch 1037/1100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4048 - accuracy: 0.8160 - val_loss: 0.4842 - val_accuracy: 0.7708\n",
            "Epoch 1038/1100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4059 - accuracy: 0.8125 - val_loss: 0.4840 - val_accuracy: 0.7656\n",
            "Epoch 1039/1100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4032 - accuracy: 0.8125 - val_loss: 0.4827 - val_accuracy: 0.7656\n",
            "Epoch 1040/1100\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4050 - accuracy: 0.8090 - val_loss: 0.4879 - val_accuracy: 0.7604\n",
            "Epoch 1041/1100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4041 - accuracy: 0.8160 - val_loss: 0.4864 - val_accuracy: 0.7552\n",
            "Epoch 1042/1100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4043 - accuracy: 0.8108 - val_loss: 0.4817 - val_accuracy: 0.7604\n",
            "Epoch 1043/1100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4036 - accuracy: 0.8177 - val_loss: 0.4861 - val_accuracy: 0.7552\n",
            "Epoch 1044/1100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4051 - accuracy: 0.8090 - val_loss: 0.4837 - val_accuracy: 0.7656\n",
            "Epoch 1045/1100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4042 - accuracy: 0.8090 - val_loss: 0.4835 - val_accuracy: 0.7604\n",
            "Epoch 1046/1100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4042 - accuracy: 0.8108 - val_loss: 0.4881 - val_accuracy: 0.7500\n",
            "Epoch 1047/1100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4038 - accuracy: 0.8108 - val_loss: 0.4811 - val_accuracy: 0.7760\n",
            "Epoch 1048/1100\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4036 - accuracy: 0.8090 - val_loss: 0.4856 - val_accuracy: 0.7552\n",
            "Epoch 1049/1100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4034 - accuracy: 0.8212 - val_loss: 0.4854 - val_accuracy: 0.7604\n",
            "Epoch 1050/1100\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4026 - accuracy: 0.8108 - val_loss: 0.4795 - val_accuracy: 0.7812\n",
            "Epoch 1051/1100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4052 - accuracy: 0.8108 - val_loss: 0.4816 - val_accuracy: 0.7760\n",
            "Epoch 1052/1100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4050 - accuracy: 0.8142 - val_loss: 0.4835 - val_accuracy: 0.7760\n",
            "Epoch 1053/1100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4020 - accuracy: 0.8090 - val_loss: 0.4904 - val_accuracy: 0.7552\n",
            "Epoch 1054/1100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4047 - accuracy: 0.8090 - val_loss: 0.4886 - val_accuracy: 0.7604\n",
            "Epoch 1055/1100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4033 - accuracy: 0.8056 - val_loss: 0.4880 - val_accuracy: 0.7552\n",
            "Epoch 1056/1100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4035 - accuracy: 0.8125 - val_loss: 0.4873 - val_accuracy: 0.7552\n",
            "Epoch 1057/1100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4024 - accuracy: 0.8142 - val_loss: 0.4854 - val_accuracy: 0.7604\n",
            "Epoch 1058/1100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4046 - accuracy: 0.8125 - val_loss: 0.4804 - val_accuracy: 0.7656\n",
            "Epoch 1059/1100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4055 - accuracy: 0.8108 - val_loss: 0.4851 - val_accuracy: 0.7604\n",
            "Epoch 1060/1100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4035 - accuracy: 0.8142 - val_loss: 0.4881 - val_accuracy: 0.7552\n",
            "Epoch 1061/1100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4053 - accuracy: 0.8073 - val_loss: 0.4835 - val_accuracy: 0.7708\n",
            "Epoch 1062/1100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4036 - accuracy: 0.8160 - val_loss: 0.4835 - val_accuracy: 0.7708\n",
            "Epoch 1063/1100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4031 - accuracy: 0.8194 - val_loss: 0.4821 - val_accuracy: 0.7760\n",
            "Epoch 1064/1100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4025 - accuracy: 0.8125 - val_loss: 0.4843 - val_accuracy: 0.7708\n",
            "Epoch 1065/1100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4029 - accuracy: 0.8073 - val_loss: 0.4850 - val_accuracy: 0.7656\n",
            "Epoch 1066/1100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4033 - accuracy: 0.8142 - val_loss: 0.4872 - val_accuracy: 0.7552\n",
            "Epoch 1067/1100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4028 - accuracy: 0.8160 - val_loss: 0.4835 - val_accuracy: 0.7760\n",
            "Epoch 1068/1100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4040 - accuracy: 0.8108 - val_loss: 0.4809 - val_accuracy: 0.7812\n",
            "Epoch 1069/1100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4033 - accuracy: 0.8125 - val_loss: 0.4837 - val_accuracy: 0.7760\n",
            "Epoch 1070/1100\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4021 - accuracy: 0.8212 - val_loss: 0.4845 - val_accuracy: 0.7656\n",
            "Epoch 1071/1100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4028 - accuracy: 0.8073 - val_loss: 0.4918 - val_accuracy: 0.7604\n",
            "Epoch 1072/1100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4003 - accuracy: 0.8125 - val_loss: 0.4817 - val_accuracy: 0.7812\n",
            "Epoch 1073/1100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4034 - accuracy: 0.8142 - val_loss: 0.4810 - val_accuracy: 0.7760\n",
            "Epoch 1074/1100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4045 - accuracy: 0.8038 - val_loss: 0.4838 - val_accuracy: 0.7604\n",
            "Epoch 1075/1100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4047 - accuracy: 0.8142 - val_loss: 0.4829 - val_accuracy: 0.7708\n",
            "Epoch 1076/1100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4027 - accuracy: 0.8142 - val_loss: 0.4857 - val_accuracy: 0.7656\n",
            "Epoch 1077/1100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4031 - accuracy: 0.8194 - val_loss: 0.4853 - val_accuracy: 0.7656\n",
            "Epoch 1078/1100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4026 - accuracy: 0.8125 - val_loss: 0.4873 - val_accuracy: 0.7552\n",
            "Epoch 1079/1100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4029 - accuracy: 0.8142 - val_loss: 0.4835 - val_accuracy: 0.7760\n",
            "Epoch 1080/1100\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4019 - accuracy: 0.8142 - val_loss: 0.4837 - val_accuracy: 0.7708\n",
            "Epoch 1081/1100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4028 - accuracy: 0.8160 - val_loss: 0.4845 - val_accuracy: 0.7708\n",
            "Epoch 1082/1100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4031 - accuracy: 0.8108 - val_loss: 0.4852 - val_accuracy: 0.7708\n",
            "Epoch 1083/1100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4020 - accuracy: 0.8125 - val_loss: 0.4838 - val_accuracy: 0.7708\n",
            "Epoch 1084/1100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4033 - accuracy: 0.8160 - val_loss: 0.4861 - val_accuracy: 0.7604\n",
            "Epoch 1085/1100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4021 - accuracy: 0.8125 - val_loss: 0.4846 - val_accuracy: 0.7656\n",
            "Epoch 1086/1100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4036 - accuracy: 0.8125 - val_loss: 0.4836 - val_accuracy: 0.7604\n",
            "Epoch 1087/1100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4021 - accuracy: 0.8125 - val_loss: 0.4815 - val_accuracy: 0.7760\n",
            "Epoch 1088/1100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4036 - accuracy: 0.8125 - val_loss: 0.4921 - val_accuracy: 0.7552\n",
            "Epoch 1089/1100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4048 - accuracy: 0.8125 - val_loss: 0.4847 - val_accuracy: 0.7656\n",
            "Epoch 1090/1100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4029 - accuracy: 0.8142 - val_loss: 0.4850 - val_accuracy: 0.7760\n",
            "Epoch 1091/1100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4018 - accuracy: 0.8142 - val_loss: 0.4851 - val_accuracy: 0.7708\n",
            "Epoch 1092/1100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4024 - accuracy: 0.8194 - val_loss: 0.4836 - val_accuracy: 0.7656\n",
            "Epoch 1093/1100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4024 - accuracy: 0.8108 - val_loss: 0.4856 - val_accuracy: 0.7760\n",
            "Epoch 1094/1100\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4003 - accuracy: 0.8125 - val_loss: 0.4905 - val_accuracy: 0.7552\n",
            "Epoch 1095/1100\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4047 - accuracy: 0.8108 - val_loss: 0.4848 - val_accuracy: 0.7708\n",
            "Epoch 1096/1100\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4019 - accuracy: 0.8160 - val_loss: 0.4882 - val_accuracy: 0.7656\n",
            "Epoch 1097/1100\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4028 - accuracy: 0.8160 - val_loss: 0.4907 - val_accuracy: 0.7604\n",
            "Epoch 1098/1100\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4022 - accuracy: 0.8125 - val_loss: 0.4852 - val_accuracy: 0.7708\n",
            "Epoch 1099/1100\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4010 - accuracy: 0.8177 - val_loss: 0.4904 - val_accuracy: 0.7604\n",
            "Epoch 1100/1100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4034 - accuracy: 0.8125 - val_loss: 0.4815 - val_accuracy: 0.7708\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot the loss and val_loss\n",
        "fig, ax = plt.subplots(figsize=(12, 6))\n",
        "ax.plot(run_hist_5.history[\"loss\"],'r', marker='.', label=\"Train Loss\")\n",
        "ax.plot(run_hist_5.history[\"val_loss\"],'b', marker='.', label=\"Validation Loss\")\n",
        "ax.legend()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 539
        },
        "id": "zWY7b7DgP_Fo",
        "outputId": "760ce4c0-9cbf-4f12-bbf3-39a9af105e91"
      },
      "id": "zWY7b7DgP_Fo",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x78b818707df0>"
            ]
          },
          "metadata": {},
          "execution_count": 54
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Interpretation:** Upon changing the network structure with a hidden layer of 4, learning_rate of 0.007 and epochs of 1100, the results shows above that the train loss is decreasing which means  that my model is gradually improving its ability to make predictions on the training data which is same as sample number 1. However, the validation loss is decreasing but suddenly it stop in approximately in epochs 390 where it remains 0.48 which it is much higher than the train loss, it indicates that the model is overfitting the training data.Even though I used a relatively low of learning_rate still the model lead to overfitting, it is because I put a high number of epochs, where the model has more opportunities to memorize the training data, which can lead to overfitting same as sample number 1."
      ],
      "metadata": {
        "id": "B83V93YaQEUB"
      },
      "id": "B83V93YaQEUB"
    },
    {
      "cell_type": "markdown",
      "source": [
        "# SAMPLE NUMBER 3."
      ],
      "metadata": {
        "id": "eFfDnBNFSTJp"
      },
      "id": "eFfDnBNFSTJp"
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import confusion_matrix, precision_recall_curve, roc_auc_score, roc_curve, accuracy_score\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "import seaborn as sns\n",
        "\n",
        "%matplotlib inline\n",
        "\n",
        "## Import Keras objects for Deep Learning\n",
        "\n",
        "from keras.models  import Sequential\n",
        "from keras.layers import Input, Dense, Flatten, Dropout, BatchNormalization\n",
        "from keras.optimizers import Adam, SGD, RMSprop\n",
        "\n",
        "# Load the dataset\n",
        "filepath = \"pima-indians-diabetes.csv\"\n",
        "names = [\"times_pregnant\", \"glucose_tolerance_test\", \"blood_pressure\", \"skin_thickness\", \"insulin\",\n",
        "         \"bmi\", \"pedigree_function\", \"age\", \"has_diabetes\"]\n",
        "diabetes_df = pd.read_csv(filepath, names=names)\n",
        "\n",
        "X = diabetes_df.iloc[:, :-1].values\n",
        "y = diabetes_df[\"has_diabetes\"].values\n",
        "\n",
        "# Split the data into 75% for train set and 25% for test set\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=11111)\n",
        "\n",
        "# Normalize the data\n",
        "normalizer = StandardScaler()\n",
        "X_train_norm = normalizer.fit_transform(X_train)\n",
        "X_test_norm = normalizer.transform(X_test)"
      ],
      "metadata": {
        "id": "Nb6tHYJRQLkP"
      },
      "id": "Nb6tHYJRQLkP",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Learning rate = 0.01\n",
        "- Epochs = 900\n",
        "- Network structure = 5 hidden layers\n"
      ],
      "metadata": {
        "id": "slmrIbDOQESZ"
      },
      "id": "slmrIbDOQESZ"
    },
    {
      "cell_type": "code",
      "source": [
        "model_supple_4 = Sequential([\n",
        "    Dense(7, input_shape=(8,), activation=\"relu\"),\n",
        "    Dense(7, activation=\"relu\"),\n",
        "    Dense(4, activation=\"relu\"),\n",
        "    Dense(2, activation=\"relu\"),\n",
        "    Dense(1, activation=\"sigmoid\")\n",
        "])"
      ],
      "metadata": {
        "id": "lWt8C_hPQVDD"
      },
      "id": "lWt8C_hPQVDD",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_supple_4.compile(SGD(lr = .001), \"binary_crossentropy\", metrics=[\"accuracy\"])\n",
        "run_hist_6 = model_supple_4.fit(X_train_norm, y_train, validation_data=(X_test_norm, y_test), epochs=100)"
      ],
      "metadata": {
        "id": "q1rjeKFrQq8o",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7e8b642a-f4db-44e3-8c42-afd558edf887"
      },
      "id": "q1rjeKFrQq8o",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.SGD.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "18/18 [==============================] - 1s 11ms/step - loss: 0.6992 - accuracy: 0.3698 - val_loss: 0.6971 - val_accuracy: 0.4479\n",
            "Epoch 2/100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6935 - accuracy: 0.4983 - val_loss: 0.6922 - val_accuracy: 0.5312\n",
            "Epoch 3/100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6884 - accuracy: 0.6198 - val_loss: 0.6878 - val_accuracy: 0.6250\n",
            "Epoch 4/100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6838 - accuracy: 0.6545 - val_loss: 0.6839 - val_accuracy: 0.6510\n",
            "Epoch 5/100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6798 - accuracy: 0.6632 - val_loss: 0.6805 - val_accuracy: 0.6458\n",
            "Epoch 6/100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6762 - accuracy: 0.6597 - val_loss: 0.6775 - val_accuracy: 0.6406\n",
            "Epoch 7/100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6730 - accuracy: 0.6562 - val_loss: 0.6748 - val_accuracy: 0.6406\n",
            "Epoch 8/100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6701 - accuracy: 0.6545 - val_loss: 0.6723 - val_accuracy: 0.6406\n",
            "Epoch 9/100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6675 - accuracy: 0.6528 - val_loss: 0.6702 - val_accuracy: 0.6406\n",
            "Epoch 10/100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6651 - accuracy: 0.6545 - val_loss: 0.6682 - val_accuracy: 0.6406\n",
            "Epoch 11/100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6630 - accuracy: 0.6545 - val_loss: 0.6664 - val_accuracy: 0.6406\n",
            "Epoch 12/100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6610 - accuracy: 0.6545 - val_loss: 0.6649 - val_accuracy: 0.6406\n",
            "Epoch 13/100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6593 - accuracy: 0.6545 - val_loss: 0.6634 - val_accuracy: 0.6406\n",
            "Epoch 14/100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6577 - accuracy: 0.6545 - val_loss: 0.6622 - val_accuracy: 0.6406\n",
            "Epoch 15/100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6563 - accuracy: 0.6545 - val_loss: 0.6610 - val_accuracy: 0.6406\n",
            "Epoch 16/100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6551 - accuracy: 0.6545 - val_loss: 0.6600 - val_accuracy: 0.6406\n",
            "Epoch 17/100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6539 - accuracy: 0.6545 - val_loss: 0.6591 - val_accuracy: 0.6406\n",
            "Epoch 18/100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6528 - accuracy: 0.6545 - val_loss: 0.6583 - val_accuracy: 0.6406\n",
            "Epoch 19/100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6519 - accuracy: 0.6545 - val_loss: 0.6576 - val_accuracy: 0.6406\n",
            "Epoch 20/100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6510 - accuracy: 0.6545 - val_loss: 0.6569 - val_accuracy: 0.6406\n",
            "Epoch 21/100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6502 - accuracy: 0.6545 - val_loss: 0.6563 - val_accuracy: 0.6406\n",
            "Epoch 22/100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6494 - accuracy: 0.6545 - val_loss: 0.6557 - val_accuracy: 0.6406\n",
            "Epoch 23/100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6487 - accuracy: 0.6545 - val_loss: 0.6552 - val_accuracy: 0.6406\n",
            "Epoch 24/100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6481 - accuracy: 0.6545 - val_loss: 0.6548 - val_accuracy: 0.6406\n",
            "Epoch 25/100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6475 - accuracy: 0.6545 - val_loss: 0.6543 - val_accuracy: 0.6406\n",
            "Epoch 26/100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6469 - accuracy: 0.6545 - val_loss: 0.6539 - val_accuracy: 0.6406\n",
            "Epoch 27/100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6464 - accuracy: 0.6545 - val_loss: 0.6535 - val_accuracy: 0.6406\n",
            "Epoch 28/100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6459 - accuracy: 0.6545 - val_loss: 0.6532 - val_accuracy: 0.6406\n",
            "Epoch 29/100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6454 - accuracy: 0.6545 - val_loss: 0.6529 - val_accuracy: 0.6406\n",
            "Epoch 30/100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6450 - accuracy: 0.6545 - val_loss: 0.6526 - val_accuracy: 0.6406\n",
            "Epoch 31/100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6445 - accuracy: 0.6545 - val_loss: 0.6523 - val_accuracy: 0.6406\n",
            "Epoch 32/100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6441 - accuracy: 0.6545 - val_loss: 0.6521 - val_accuracy: 0.6406\n",
            "Epoch 33/100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6438 - accuracy: 0.6545 - val_loss: 0.6518 - val_accuracy: 0.6406\n",
            "Epoch 34/100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6434 - accuracy: 0.6545 - val_loss: 0.6516 - val_accuracy: 0.6406\n",
            "Epoch 35/100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6431 - accuracy: 0.6545 - val_loss: 0.6514 - val_accuracy: 0.6406\n",
            "Epoch 36/100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6427 - accuracy: 0.6545 - val_loss: 0.6511 - val_accuracy: 0.6406\n",
            "Epoch 37/100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6424 - accuracy: 0.6545 - val_loss: 0.6509 - val_accuracy: 0.6406\n",
            "Epoch 38/100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6421 - accuracy: 0.6545 - val_loss: 0.6507 - val_accuracy: 0.6406\n",
            "Epoch 39/100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6418 - accuracy: 0.6545 - val_loss: 0.6505 - val_accuracy: 0.6406\n",
            "Epoch 40/100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6415 - accuracy: 0.6545 - val_loss: 0.6503 - val_accuracy: 0.6406\n",
            "Epoch 41/100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6412 - accuracy: 0.6545 - val_loss: 0.6502 - val_accuracy: 0.6406\n",
            "Epoch 42/100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6409 - accuracy: 0.6545 - val_loss: 0.6500 - val_accuracy: 0.6406\n",
            "Epoch 43/100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6405 - accuracy: 0.6545 - val_loss: 0.6498 - val_accuracy: 0.6406\n",
            "Epoch 44/100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6402 - accuracy: 0.6545 - val_loss: 0.6496 - val_accuracy: 0.6406\n",
            "Epoch 45/100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6400 - accuracy: 0.6545 - val_loss: 0.6494 - val_accuracy: 0.6406\n",
            "Epoch 46/100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6396 - accuracy: 0.6545 - val_loss: 0.6492 - val_accuracy: 0.6406\n",
            "Epoch 47/100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6393 - accuracy: 0.6545 - val_loss: 0.6490 - val_accuracy: 0.6406\n",
            "Epoch 48/100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6390 - accuracy: 0.6545 - val_loss: 0.6488 - val_accuracy: 0.6406\n",
            "Epoch 49/100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6387 - accuracy: 0.6545 - val_loss: 0.6486 - val_accuracy: 0.6406\n",
            "Epoch 50/100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6384 - accuracy: 0.6545 - val_loss: 0.6483 - val_accuracy: 0.6406\n",
            "Epoch 51/100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6380 - accuracy: 0.6545 - val_loss: 0.6481 - val_accuracy: 0.6406\n",
            "Epoch 52/100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6377 - accuracy: 0.6545 - val_loss: 0.6478 - val_accuracy: 0.6406\n",
            "Epoch 53/100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6373 - accuracy: 0.6545 - val_loss: 0.6476 - val_accuracy: 0.6406\n",
            "Epoch 54/100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6369 - accuracy: 0.6545 - val_loss: 0.6473 - val_accuracy: 0.6406\n",
            "Epoch 55/100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6366 - accuracy: 0.6545 - val_loss: 0.6470 - val_accuracy: 0.6406\n",
            "Epoch 56/100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6362 - accuracy: 0.6545 - val_loss: 0.6467 - val_accuracy: 0.6406\n",
            "Epoch 57/100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6358 - accuracy: 0.6545 - val_loss: 0.6464 - val_accuracy: 0.6406\n",
            "Epoch 58/100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6354 - accuracy: 0.6545 - val_loss: 0.6461 - val_accuracy: 0.6406\n",
            "Epoch 59/100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6350 - accuracy: 0.6545 - val_loss: 0.6458 - val_accuracy: 0.6406\n",
            "Epoch 60/100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6346 - accuracy: 0.6545 - val_loss: 0.6454 - val_accuracy: 0.6406\n",
            "Epoch 61/100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6341 - accuracy: 0.6545 - val_loss: 0.6451 - val_accuracy: 0.6406\n",
            "Epoch 62/100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6337 - accuracy: 0.6545 - val_loss: 0.6447 - val_accuracy: 0.6406\n",
            "Epoch 63/100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6333 - accuracy: 0.6562 - val_loss: 0.6443 - val_accuracy: 0.6406\n",
            "Epoch 64/100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6328 - accuracy: 0.6562 - val_loss: 0.6439 - val_accuracy: 0.6406\n",
            "Epoch 65/100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6323 - accuracy: 0.6562 - val_loss: 0.6435 - val_accuracy: 0.6406\n",
            "Epoch 66/100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6318 - accuracy: 0.6562 - val_loss: 0.6430 - val_accuracy: 0.6406\n",
            "Epoch 67/100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6313 - accuracy: 0.6562 - val_loss: 0.6425 - val_accuracy: 0.6406\n",
            "Epoch 68/100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6307 - accuracy: 0.6562 - val_loss: 0.6420 - val_accuracy: 0.6406\n",
            "Epoch 69/100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6301 - accuracy: 0.6562 - val_loss: 0.6415 - val_accuracy: 0.6406\n",
            "Epoch 70/100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6295 - accuracy: 0.6562 - val_loss: 0.6409 - val_accuracy: 0.6406\n",
            "Epoch 71/100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6289 - accuracy: 0.6597 - val_loss: 0.6404 - val_accuracy: 0.6406\n",
            "Epoch 72/100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6282 - accuracy: 0.6597 - val_loss: 0.6398 - val_accuracy: 0.6406\n",
            "Epoch 73/100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6276 - accuracy: 0.6597 - val_loss: 0.6391 - val_accuracy: 0.6406\n",
            "Epoch 74/100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6269 - accuracy: 0.6649 - val_loss: 0.6385 - val_accuracy: 0.6406\n",
            "Epoch 75/100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6261 - accuracy: 0.6649 - val_loss: 0.6378 - val_accuracy: 0.6458\n",
            "Epoch 76/100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6254 - accuracy: 0.6649 - val_loss: 0.6371 - val_accuracy: 0.6458\n",
            "Epoch 77/100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6246 - accuracy: 0.6649 - val_loss: 0.6364 - val_accuracy: 0.6458\n",
            "Epoch 78/100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6239 - accuracy: 0.6615 - val_loss: 0.6357 - val_accuracy: 0.6510\n",
            "Epoch 79/100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6231 - accuracy: 0.6615 - val_loss: 0.6349 - val_accuracy: 0.6510\n",
            "Epoch 80/100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6222 - accuracy: 0.6649 - val_loss: 0.6340 - val_accuracy: 0.6510\n",
            "Epoch 81/100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6214 - accuracy: 0.6649 - val_loss: 0.6332 - val_accuracy: 0.6510\n",
            "Epoch 82/100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6205 - accuracy: 0.6684 - val_loss: 0.6323 - val_accuracy: 0.6510\n",
            "Epoch 83/100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6196 - accuracy: 0.6719 - val_loss: 0.6313 - val_accuracy: 0.6510\n",
            "Epoch 84/100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6187 - accuracy: 0.6719 - val_loss: 0.6304 - val_accuracy: 0.6510\n",
            "Epoch 85/100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6178 - accuracy: 0.6701 - val_loss: 0.6293 - val_accuracy: 0.6510\n",
            "Epoch 86/100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6169 - accuracy: 0.6736 - val_loss: 0.6283 - val_accuracy: 0.6510\n",
            "Epoch 87/100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6158 - accuracy: 0.6736 - val_loss: 0.6271 - val_accuracy: 0.6510\n",
            "Epoch 88/100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6148 - accuracy: 0.6736 - val_loss: 0.6259 - val_accuracy: 0.6510\n",
            "Epoch 89/100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6137 - accuracy: 0.6736 - val_loss: 0.6247 - val_accuracy: 0.6510\n",
            "Epoch 90/100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6127 - accuracy: 0.6736 - val_loss: 0.6234 - val_accuracy: 0.6510\n",
            "Epoch 91/100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6116 - accuracy: 0.6753 - val_loss: 0.6221 - val_accuracy: 0.6510\n",
            "Epoch 92/100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6105 - accuracy: 0.6823 - val_loss: 0.6208 - val_accuracy: 0.6510\n",
            "Epoch 93/100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6094 - accuracy: 0.6840 - val_loss: 0.6194 - val_accuracy: 0.6510\n",
            "Epoch 94/100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6083 - accuracy: 0.6858 - val_loss: 0.6179 - val_accuracy: 0.6510\n",
            "Epoch 95/100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6070 - accuracy: 0.6858 - val_loss: 0.6164 - val_accuracy: 0.6510\n",
            "Epoch 96/100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6059 - accuracy: 0.6875 - val_loss: 0.6148 - val_accuracy: 0.6667\n",
            "Epoch 97/100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6047 - accuracy: 0.6875 - val_loss: 0.6133 - val_accuracy: 0.6667\n",
            "Epoch 98/100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6034 - accuracy: 0.6910 - val_loss: 0.6116 - val_accuracy: 0.6667\n",
            "Epoch 99/100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6021 - accuracy: 0.6944 - val_loss: 0.6100 - val_accuracy: 0.6667\n",
            "Epoch 100/100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6009 - accuracy: 0.6962 - val_loss: 0.6084 - val_accuracy: 0.6667\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot the loss and val_loss\n",
        "fig, ax = plt.subplots(figsize=(12, 6))\n",
        "ax.plot(run_hist_6.history[\"loss\"],'r', marker='.', label=\"Train Loss\")\n",
        "ax.plot(run_hist_6.history[\"val_loss\"],'b', marker='.', label=\"Validation Loss\")\n",
        "ax.legend()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 539
        },
        "id": "iNK5VJUzRxum",
        "outputId": "3790baaf-52c8-495e-849d-7c1482b8af37"
      },
      "id": "iNK5VJUzRxum",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x78b8005b81c0>"
            ]
          },
          "metadata": {},
          "execution_count": 93
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Interpretation:** Upon changing the network structure with a hidden layer of 5, learning_rate of 0.001 and epochs of 100, the results shows above that both train loss and validation loss are decreasing steadily without a significant gap, indicating that the model is improving its ability to make accurate predictions on both the training and validation datasets over the course of training. Unlike from the previous sample this model have a no signs of overfitting based on the given results.\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Q-rQ7_cZSVCI"
      },
      "id": "Q-rQ7_cZSVCI"
    },
    {
      "cell_type": "markdown",
      "id": "broad-appointment",
      "metadata": {
        "id": "broad-appointment"
      },
      "source": [
        "# Conclusion"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this activity, our objective is to demonstrate how to build and train neural networks and how to evaluate and plot the model using training and validation loss,. In the first part of the activity, I encountered no problem since we already do that part in our past activity. After running the code given in training the model, the code below have an error so I modified it to make it works. After that I learned how to plot_roc_function where it provides valuable insights into the performance of a binary classification model, particularly in terms of its ability to correctly classify positive and negative instances across different threshold settings. Also, I learned upon plotting the train loss and validation loss that having a decreasing value of train loss means that the model is improving its ability to minimize the difference between predicted outputs and actual targets during training. And having a higher value of validation loss than train loss means that the model overfitting the training data. In supplementary activity, we assign to change the network structure, learning_rate, and epochs and interpret the result based on the plot. All of my samples are having a decreasing of train loss, and having a much higher value of validation loss than train loss even though I modified the network structure, learning_rate, and epochs.\n",
        "\n",
        "In conclusion, learning how to build and train neural networks and evaluating them using train and validation loss is essential for developing effective models, preventing overfitting, and making informed decisions in various domains.\n",
        "\n"
      ],
      "metadata": {
        "id": "pxWdlVRYbCph"
      },
      "id": "pxWdlVRYbCph"
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.10"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}